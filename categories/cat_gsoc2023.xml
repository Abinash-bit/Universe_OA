<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts about gsoc2023)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/categories/cat_gsoc2023.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sat, 26 Aug 2023 00:51:55 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Benchmark Tests</title><link>http://openastronomy.org/Universe_OA/posts/2023/08/20230825_0000_1someshverma/</link><dc:creator>Somesh Verma</dc:creator><description>&lt;p&gt;I have finished the refactoring the code for vaex and also writtten test cases to compare the spectrum calculated using pandas with the dataframe calculated using vaex dataframe . Also, Various spectroscopic quantities as absorbance , emissitivity is also compared for the both the dataframams.
Also, there was many issues that was raised by the maintainers and I have resolved almost all of these , and commented on the other issues to discuss the problem and discuss some possible solution .Issues raised by the maintainers was mainly related to make changes more matainable and easy to understand and simple programming logic is preferred inplace of using some complex code without explaining that in detail.
Also , the issue was to ensure a light test suite , that is test cases which takes less resources and time . Initialy , I didn’t focused on this thing and focused on testing the code and changes more elaborately by writing the test cases that cover many areas of code .&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;But, later as told by maintainer I have refacatored the changes and made the changes more light and test cases more light .It helped to reduce the time required test the new commit as excecution time of the test cases were reduced.
After, all this another thing was to add benchmark test to compare the memory use by vaex and pandas and also compare the execution time used by both these engines.&lt;/p&gt;

&lt;p&gt;Benchmark Test added to compare time taken by code is :&lt;/p&gt;
&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;def compare_vaex_pandas_time():
"""
Compares the time performance of pandas and Vaex and generates a plot. This scripts takes several minutes to run.
This results shoud shown that vaex and pandas provide similar performances in term if speed.
Returns
-------
None.
"""
time_list, timeC_list, lines_list = [], [], []
time_list_va, timeC_list_va, lines_list_va = [], [], []
wmin = 1000
steps = 5
wmax_arr = np.geomspace(10, 1000, steps)

initial_engine = config[
"DATAFRAME_ENGINE"
]  # To make sure dataframe engine not changed after running this test
pb = ProgressBar(N=2 * steps)
for i, engine in enumerate(["vaex", "pandas"]):
config["DATAFRAME_ENGINE"] = engine
for j, w_range in enumerate(wmax_arr):
t0 = time.time()
s = calc_spectrum(
wmin,
wmin + w_range,  # cm-1
molecule="H2O",
isotope="1,2,3",
pressure=1.01325,  # bar
Tgas=1000,
mole_fraction=0.1,
databank="hitemp",  # or 'hitemp'
wstep="auto",
cutoff=1e-28,
verbose=0,
)
t1 = time.time()
if engine == "vaex":
timeC_list_va.append(s.conditions["calculation_time"])
lines_list_va.append(s.conditions["lines_calculated"])
time_list_va.append(t1 - t0)
# lines_list_va.append(s.conditions['lines_calculated']+s.conditions['lines_cutoff'])
else:
timeC_list.append(s.conditions["calculation_time"])
lines_list.append(s.conditions["lines_calculated"])
time_list.append(t1 - t0)
# lines_list.append(s.conditions['lines_calculated']+s.conditions['lines_cutoff'])
pb.update(i * steps + (j + 1))
plt.figure()
plt.plot(lines_list, time_list, "k", label="pandas total")
plt.plot(lines_list, timeC_list, "k--", label="pandas computation")
plt.plot(lines_list_va, time_list_va, "r", label="vaex total")
plt.plot(lines_list_va, timeC_list_va, "r--", label="vaex computation")
plt.ylabel("Time [s]")
plt.xlabel("Number of lines")
plt.legend()

config["DATAFRAME_ENGINE"] = initial_engine
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img alt="Vaex Comparison Time" src="https://1someshverma.github.io/images/timeComparison.png"&gt;&lt;/p&gt;

&lt;p&gt;while Graph for Memory use and code are :
&lt;img alt="Vaex Comparison" src="https://1someshverma.github.io/images/vaexcomparison.png"&gt;&lt;/p&gt;

&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;# Compare the memory performance of Pandas and Vaex
def compare_pandas_vs_vaex_memory():
"""
Compare memory usage of `engine="vaex"` and `engine="pandas"` in calc_spectrum.
Expected behavior is "vaex" using much less memory. This function takes tens of seconds to run.
Returns
-------
None.
"""

import tracemalloc

initial_engine = config[
"DATAFRAME_ENGINE"
]  # To make sure dataframe engine not changed after running this test
for engine in ["pandas", "vaex"]:
config["DATAFRAME_ENGINE"] = engine
tracemalloc.start()
s = calc_spectrum(
1000,
1500,  # cm-1
molecule="H2O",
isotope="1,2,3",
pressure=1.01325,  # bar
Tgas=1000,  # K
mole_fraction=0.1,
wstep="auto",
databank="hitemp",  # or 'hitemp', 'geisa', 'exomol'
verbose=0,
)
snapshot = tracemalloc.take_snapshot()
memory = tracemalloc.get_traced_memory()
tracemalloc.stop()

# Some raw outputs
print("\n******** Engine = {} ***********".format(engine))
print(
"Peak, current = {:.1e}, {:.1e} for {:} lines calculated".format(
*memory, s.conditions["lines_calculated"]
)
)

# More sophisticated
print("*** List of biggest objects ***")
top_stats = snapshot.statistics("lineno")
for rank, stat in enumerate(top_stats[:3]):
print("#{}".format(rank + 1))
print(stat)

# Clear for next engine in the loop
tracemalloc.clear_traces()

config["DATAFRAME_ENGINE"] = initial_engine

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2023/08/20230825_0000_1someshverma/</guid><pubDate>Thu, 24 Aug 2023 23:00:00 GMT</pubDate></item><item><title>GSoC Week 9-10</title><link>http://openastronomy.org/Universe_OA/posts/2023/08/20230813_1023_pupperemeritus/</link><dc:creator>pupper emeritus</dc:creator><description>&lt;p&gt;Big progress on the front of algorithm working. Turns out there wasn't that much of a problem in the algorithm. I just had to subtract the mean from the data before taking the fourier transform. The Lomb Scargle seems to work on data that has mean subtracted from it. Furthermore they dont seem to work that well or at all in full spectrum. &lt;br&gt;
The LSFT also is highly sensitive to the time intervals that are input to it. I have found some more clues as to how to make it even better. I will expound upon this further within 2 weeks since my final exams are going on and I have limited time.&lt;/p&gt;

&lt;!-- TEASER_END --&gt;
&lt;p&gt;Minimum Working Code Example&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;def data_func(time, freq=1.2324235252):
return  2 * np.sin(2 * np.pi * time * freq)

t0 = 0
t1 = 100
dt = 0.1

np.random.seed(43)
time_uniform = np.arange(t0, t1, dt)
time_nonuniform = np.sort(np.random.uniform(t0, t1, time_uniform.size))

npft = np.fft.fft(data_func(time_uniform))
npfreqs = np.fft.fftfreq(npft.size, dt)
npft = npft[npfreqs&amp;gt;=0]
npfreqs = npfreqs[npfreqs&amp;gt;=0]
lsfreqs = np.linspace(np.min(npfreqs), np.max(npfreqs), npfreqs.size * 8)
lsfreqs = lsfreqs[lsfreqs&amp;gt;=0]
np.random.seed(43)
lsft_slow_arr = lsft_slow(data_func(time_nonuniform), time_nonuniform, lsfreqs,sign=-1, fullspec=False)
lsft_fast_arr = lsft_fast(data_func(time_nonuniform), time_nonuniform, lsfreqs,sign=-1, fullspec=False,oversampling=10)
plt.plot(time_nonuniform,lsft_slow_inv(lsft_slow_arr,freqs=time_nonuniform, t=lsfreqs).real ,alpha=0.5,label="Slow")
plt.plot(time_nonuniform,lsft_fast_inv(lsft_fast_arr,freqs=time_nonuniform, t=lsfreqs).real,alpha=0.5,label="Fast")
plt.plot(time_nonuniform,data_func(time_nonuniform),label="Original Data")
plt.legend()
plt.xlim(0,10)
plt.ylim(-3,3)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a class="article-body-image-wrapper" href="https://res.cloudinary.com/practicaldev/image/fetch/s--v8B0QIbQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/g10l11a0u36xzhtkq5n5.png"&gt;&lt;img alt="Image description" height="418" src="https://res.cloudinary.com/practicaldev/image/fetch/s--v8B0QIbQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/g10l11a0u36xzhtkq5n5.png" width="555"&gt;&lt;/a&gt;&lt;/p&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2023/08/20230813_1023_pupperemeritus/</guid><pubDate>Sun, 13 Aug 2023 09:23:47 GMT</pubDate></item><item><title>Docs and Marty and the Moving Around of Code and Tests</title><link>http://openastronomy.org/Universe_OA/posts/2023/08/20230812_0533_exitflynn/</link><dc:creator>exitflynn</dc:creator><description>&lt;p&gt;Since the last post, I worked on the moving-the-code task. Me, Nabil and Alasdair got on a call to discuss what should go where and I ended up creating a &lt;code&gt;scraper_utils.py&lt;/code&gt; file to complement the &lt;code&gt;scraper.py&lt;/code&gt; file. The other options were moving the functions to &lt;code&gt;.util.net&lt;/code&gt; or inside the &lt;code&gt;scraper.py&lt;/code&gt; file but outside the &lt;code&gt;Scraper&lt;/code&gt; class. After I moved the tests as well, I wrote new tests, increased test coverage and renamed some functions which were previously named in the JavaScript-style CamelCase.
I also added and extended doc-strings to some functions which could use some updating and made fixes as asked in Code-Reviews.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2023/08/20230812_0533_exitflynn/</guid><pubDate>Sat, 12 Aug 2023 04:33:30 GMT</pubDate></item><item><title>Integrating OpenCL with Gnuastro</title><link>http://openastronomy.org/Universe_OA/posts/2023/08/20230812_0000_labeeb-7z/</link><dc:creator>Labib Asari</dc:creator><description>&lt;h3 id="background"&gt;Background&lt;/h3&gt;

&lt;p&gt;In the last post, I discussed what is OpenCL and why we chose to integrate it with Gnuastro. In this post, I’ll be discussing the actual implementation and the challenges I faced.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;h3 id="programming-in-opencl"&gt;Programming in OpenCL&lt;/h3&gt;

&lt;p&gt;The OpenCL 3.0 standard has done a great job of simplifying the programming model. The OpenCL 3.0 API is a header-only library that provides a modern, object-oriented interface to the OpenCL runtime. It is designed to be easy to use and provides a abstraction of the OpenCL runtime, making it easier to write portable code across different OpenCL implementations. We still have to communicate with the driver (unlike CUDA) at a low level, but this becomes a mandatory step when we want to run our code on different hardware (CUDA always expects an NVIDIA device).&lt;/p&gt;

&lt;p&gt;Here’s a general overview of steps to be followed when writing an using OpenCL :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Check for available Platforms&lt;/strong&gt; : A platform is a collection of OpenCL devices. A platform can be a CPU, GPU, or an FPGA (Remember OpenCL can work with any platform!). This is done specifically to identify which OpenCL implementation will be used during runtime. We can query the system for available platforms using the &lt;code class="language-plaintext highlighter-rouge"&gt;clGetPlatformIDs&lt;/code&gt; function. This function returns a list of platforms available on the system.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Check for available devices&lt;/strong&gt; : A device is a physical device that can execute OpenCL kernels. A device can be a CPU, GPU, or an FPGA. We can query the system for available devices using the &lt;code class="language-plaintext highlighter-rouge"&gt;clGetDeviceIDs&lt;/code&gt; function. This function returns a list of devices available on the system.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create a context&lt;/strong&gt; : A context is a container for all the OpenCL objects. It is used to manage the memory, command queues, and other OpenCL objects. It is created by passing a list of devices to the constructor. Since OpenCL can work with multiple devices, we can create a context with multiple devices. This is useful when we want to run our code on multiple devices at the same time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create a command queue&lt;/strong&gt; : A command queue is used to queue up commands for the device to execute. The command queue is used to give commands to the device. The device executes the commands in the order they are received. The commands can be kernel execution, memory transfer, or any other OpenCL command. We can also create multiple command queues. This is useful when we want to run to multiple commands. Command queues in OpenCL are asynchronous by default. This means that the commands are queued up and the control is returned to the host. The host can then continue with other tasks. We can also create a synchronous command queue. This means that the commands are queued up and the control is returned to the host only when the commands are executed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Load the Kernel&lt;/strong&gt; : A kernel is a function that is executed on the device. It is written as per the &lt;code class="language-plaintext highlighter-rouge"&gt;C99 standard&lt;/code&gt;. We can load the kernel from a file or we can write the kernel inline. To maintain portablitiy, OpenCL kernels are generally compiled at runtime using &lt;code class="language-plaintext highlighter-rouge"&gt;clBuildProgram&lt;/code&gt;. We can also compile the kernel offline. This is useful when we want to compile the kernel for a specific device.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Copy Data to device memory&lt;/strong&gt; : All the data used in kernel, must be on the device memory. So we have to copy the data from the host to the device memory. We can do this using the &lt;code class="language-plaintext highlighter-rouge"&gt;clCreateBuffer&lt;/code&gt; function. This function creates a buffer on the device memory. We can then copy the data from the host to the device using the &lt;code class="language-plaintext highlighter-rouge"&gt;clEnqueueWriteBuffer&lt;/code&gt; function. This function copies the data from the host to the device.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Launch the kernel&lt;/strong&gt; : We can launch the kernel by passing the kernel object to the command queue. We have to set the arguments for the kernel seperately, using the &lt;code class="language-plaintext highlighter-rouge"&gt;clSetKernelArg&lt;/code&gt; function. We can also set the global and local work size. The global work size is the total number of work items that will be executed. The local work size is the number of work items that will be executed in a work group. The global work size should be a multiple of the local work size. If the global work size is not a multiple of the local work size, then the global work size is rounded up to the next multiple of the local work size.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Read the output&lt;/strong&gt; : We can read the output from the device using the &lt;code class="language-plaintext highlighter-rouge"&gt;clEnqueueReadBuffer&lt;/code&gt; function. This function copies the data from the device to the host.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="implementation"&gt;Implementation&lt;/h3&gt;

&lt;p&gt;Among all the steps mentioned above, everything up till loading the kernel is common to all the programs that’ll be using OpenCL. So we defined a &lt;code class="language-plaintext highlighter-rouge"&gt;gpu_utils&lt;/code&gt; module which is responsible for querying for the available platforms and devices, creating the context and command queue, loading and compiling the kernel. The only external data it requires is the path to the kernel file. This is provided as an input.
It also provides utility functions to copy specific data types to and from device memory.&lt;/p&gt;

&lt;p&gt;There’ll be 2 types of OpenCL program in Gnuastro :&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Programs using OpenCL to speed-up existing operations inside Gnuastro.&lt;/li&gt;
&lt;li&gt;User defined OpenCL kernels, responsible for performing a custom task.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id="programs-using-opencl-to-speed-up-existing-operations-inside-gnuastro"&gt;Programs using OpenCL to speed-up existing operations inside Gnuastro&lt;/h4&gt;

&lt;p&gt;These programs will be using OpenCL to speed-up existing operations inside Gnuastro. For example, we can use OpenCL to speed-up the &lt;code class="language-plaintext highlighter-rouge"&gt;astconvolve&lt;/code&gt; operation by passing an extra &lt;code class="language-plaintext highlighter-rouge"&gt;--gpu&lt;/code&gt;. For these programs, the OpenCL kernels will be part of the Gnuastro Library.&lt;/p&gt;

&lt;p&gt;The general flow of the program then becomes :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The user passes the input data for a specific operation, and also choses the local and global work size.&lt;/li&gt;
&lt;li&gt;The program then initializes the device using &lt;code class="language-plaintext highlighter-rouge"&gt;gpu_utils&lt;/code&gt; module by providing the kernel file from the library, which does everything and returns a &lt;code class="language-plaintext highlighter-rouge"&gt;cl_kernel&lt;/code&gt; (which is essentially the compiled kernel).&lt;/li&gt;
&lt;li&gt;Data transfer from CPU to device (GPU) is done using the functions provided by &lt;code class="language-plaintext highlighter-rouge"&gt;gpu_utils&lt;/code&gt; module.&lt;/li&gt;
&lt;li&gt;The kernel is launched using with the provided global and local work size.&lt;/li&gt;
&lt;li&gt;Data is copied back to CPU memory and returned to the user.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id="user-defined-opencl-kernels-responsible-for-performing-a-custom-task"&gt;User defined OpenCL kernels, responsible for performing a custom task&lt;/h4&gt;

&lt;p&gt;These programs will be using OpenCL to perform a custom task. For example, we can use OpenCL to perform a custom convolution operation by passing a custom kernel. For these programs, the OpenCL kernels will be provided by the user. The exact design details yet to be determined for this.&lt;/p&gt;

&lt;h3 id="results"&gt;Results&lt;/h3&gt;
&lt;p&gt;Input image is 10,000 x 20,000 random image with normal distribution.
Kernel is 7 x 7 standard convolution kernel.
CPU : Intel(R) Core(TM) i5-9300HF CPU @ 2.40GHz
GPU : NVIDIA GeForce GTX 1650&lt;/p&gt;

&lt;p&gt;Convolution using existing convolution in Gnuastro :&lt;/p&gt;

&lt;p&gt;&lt;img alt="Convolution using existing convolution in Gnuastro" src="https://labeeb-7z.github.io/Blogs/img/posts/opencl-imp/conv_cpu.png"&gt;&lt;/p&gt;

&lt;p&gt;Convolution on OpenCL :&lt;/p&gt;

&lt;p&gt;&lt;img alt="Convolution on OpenCL" src="https://labeeb-7z.github.io/Blogs/img/posts/opencl-imp/conv_gpu.png"&gt;&lt;/p&gt;

&lt;p&gt;Result&lt;/p&gt;

&lt;p&gt;&lt;img alt="Result" src="https://labeeb-7z.github.io/Blogs/img/posts/opencl-imp/res.png"&gt;&lt;/p&gt;

&lt;p&gt;The speed up for convolution operation is specifically ranges from 300-500x, but for the entire operation its around 3-5x due to the overhead of copying data to and from the device. Overcoming this is a big and important challenge!&lt;/p&gt;

&lt;h3 id="challenges"&gt;Challenges&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;No &lt;code class="language-plaintext highlighter-rouge"&gt;GAL_DATA_T&lt;/code&gt; inside OpenCL kernel!&lt;/strong&gt; : Inside OpenCL, &lt;code class="language-plaintext highlighter-rouge"&gt;cl_mem&lt;/code&gt; is the primary object used to represent memory objects such as buffers and images. It is used to allocate memory on the device. Regardless of where the data is coming from on device (arrays, structs, etc), it’s all converted into a &lt;code class="language-plaintext highlighter-rouge"&gt;cl_mem&lt;/code&gt; object when copied to the device.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However inside Gnuastro, the core data structure is &lt;code class="language-plaintext highlighter-rouge"&gt;gal_data_t&lt;/code&gt; which is essentially just a C struct.&lt;/p&gt;

&lt;p&gt;Why is this a problem? Well the raw data of the input image/table is not contained inside the &lt;code class="language-plaintext highlighter-rouge"&gt;gal_data_t&lt;/code&gt;. It merely consists a pointer to that data! So wehn we copy the &lt;code class="language-plaintext highlighter-rouge"&gt;gal_data_t&lt;/code&gt; to device, the raw data(which is huge) is not copied. (It lives on the CPU memory, and hence cant use CPU pointers on GPU memory).&lt;/p&gt;

&lt;p&gt;What about copying the raw data seperately on the GPU memory, and then replacing the pointer inside &lt;code class="language-plaintext highlighter-rouge"&gt;gal_data_t&lt;/code&gt; with a pointer which has the address on the GPU memory? Well, this is not possible either. Why? See, when we are on CPU, we’ve a good &lt;code class="language-plaintext highlighter-rouge"&gt;gal_data_t&lt;/code&gt; struct which is a single big object with ‘sub-objects’(one of which is the pointer). But on GPU, we’ve a &lt;code class="language-plaintext highlighter-rouge"&gt;cl_mem&lt;/code&gt; which is an object, but unlike structs, it cant have sub-objects!&lt;/p&gt;

&lt;p&gt;How do we solve this? Currently all the required pointers inside &lt;code class="language-plaintext highlighter-rouge"&gt;gal_data_t&lt;/code&gt; are passed as seperate arguments to the kernel. After a careful study of the internal implementation of the &lt;code class="language-plaintext highlighter-rouge"&gt;cl_mem&lt;/code&gt; object, we’ll see if we can directly pass the &lt;code class="language-plaintext highlighter-rouge"&gt;gal_data_t&lt;/code&gt; to the kernel.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data Transfer Overhead&lt;/strong&gt; : As mentioned multiple times, for using GPUs, we must copy data to and from the GPU memory. Astronomical datasets are huge, and copying them for each operation is a big overhead! Infact the data transfer overhead is so huge, that the actual operation is much faster than the data transfer. Adding more to that, its not just faster, its much much faster! So much so that around 95% of the time is spent in copying data to and from the GPU memory. It reduces performance by ~100x! It can’t continue this way!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One solution we’ve figured is, when the External data is loaded for the first time in the program, we load it on the GPU memory instead of the CPU memory. This way, for each subsequent operation, we dont have to copy the data from CPU to GPU memory. After all the operations are done, we’ll copy the result back to CPU memory and save it to the disk. This will avoid almost all the Data Transfer overhead.&lt;/p&gt;

&lt;p&gt;This is about the same approach used by Machine Learning Libraries such as Tensorflow. Basically during initialization, it occupies all the GPU memory it can, and keeps it occupied. All the operations, their results and the subsequent operations are done on the GPU memory itself.&lt;/p&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2023/08/20230812_0000_labeeb-7z/</guid><pubDate>Fri, 11 Aug 2023 23:00:00 GMT</pubDate></item><item><title>Progress on Kurucz and NIST databases</title><link>http://openastronomy.org/Universe_OA/posts/2023/08/20230811_1723_menasrac/</link><dc:creator>Racim MENASRIA</dc:creator><description>&lt;p&gt;Since the last article, I received a lot of feedback and comments about the Kurucz PR.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/952/1*iyB8Ya_dKD5OIkQ8gbcovg.png"&gt;&lt;/figure&gt;&lt;p&gt;Here is and example of a Fe_I spectrum I can obtain with these conditions.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*alxgHx0L0Bg54hyUcp8h0Q.png"&gt;&lt;/figure&gt;&lt;h4&gt;The main remarks where that :&lt;/h4&gt;&lt;p&gt;I needed to adjust the code to make it more general and user friendly. I introduced a specie argument to SpectrumFactory and calc_spectrum to replace atom and molecule and gather them under a same name.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;I made sure to respect the Radis structure by mooving files where I needed to and adding a new Partfunc class for Kurucz. &lt;br&gt;Then I added a few tests and removed old tests that were not needed any longer.&lt;/p&gt;
&lt;p&gt;I also cleaned my PR : removed all the unused methods from the Kurucz API,added references, moved hardcoded arrays to proper files.&lt;/p&gt;
&lt;p&gt;We asked the Exojax team for more help about the broadening parameters. For the moment, there are some approximations and placeholders about the airbrd (air broadening which is required in the Radis format) by computing it thanks to the Kurucz parameters.&lt;br&gt;A simplified version of the broadening allows to plot spectra for now but there are still values to adjust for the various species.&lt;/p&gt;
&lt;p&gt;I also started to work on the NIST database by fixing a parsers developed last year. Though I can plot NIST spectra for some wavelength, there still are issues particularly about the FWHM to deal with.&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=e955d61c1591" width="1"&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2023/08/20230811_1723_menasrac/</guid><pubDate>Fri, 11 Aug 2023 16:23:24 GMT</pubDate></item><item><title>Writing Test Cases</title><link>http://openastronomy.org/Universe_OA/posts/2023/08/20230801_0000_1someshverma/</link><dc:creator>Somesh Verma</dc:creator><description>&lt;p&gt;For testing specturm produce using vaex and pandas for non-equilibrium calculations are same , the code similar to equilibrium calculations is used&lt;/p&gt;

&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;from radis import calc_spectrum
&lt;!-- TEASER_END --&gt;

import time
t0=time.time()

s, factory_s = calc_spectrum(1800, 1820,         # cm-1
molecule='CO',
isotope='1',
pressure=1.01325,   # bar
Tgas=700,           # K
Tvib=710,
Trot=710,
mole_fraction=0.1,
wstep='auto',
path_length=1,      # cm
databank='hitemp',  # or 'hitemp', 'geisa', 'exomol'
optimization=None,
engine='vaex',
verbose=3,
return_factory=True,
)

s.apply_slit(0.5, 'nm')       # simulate an experimental slit

t1=time.time()
print('Time taken : '+str(t1 - t0))

t0=time.time()

s1, factory_s1 = calc_spectrum(1800, 1820,         # cm-1
molecule='CO',
isotope='1',
pressure=1.01325,   # bar
Tgas=700,           # K
Tvib=710,
Trot=710,
mole_fraction=0.1,
wstep='auto',
path_length=1,      # cm
databank='hitemp',  # or 'hitemp', 'geisa', 'exomol'
engine='pandas',
verbose=3,
return_factory=True,
)

s.apply_slit(0.5, 'nm')       # simulate an experimental slit

t1=time.time()
print(s.get("absorbance"))
s.plot('radiance_noslit')
print('Time taken : '+str(t1 - t0))

import numpy as np
print(np.allclose(s.get("absorbance"), s1.get("absorbance")))

for column in factory_s1.df1.columns:
assert np.all(factory_s1.df1[column] == factory_s.df1[column].to_numpy())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I will add more test cases .&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2023/08/20230801_0000_1someshverma/</guid><pubDate>Mon, 31 Jul 2023 23:00:00 GMT</pubDate></item><item><title>GSoC Week 5-8</title><link>http://openastronomy.org/Universe_OA/posts/2023/07/20230730_0735_pupperemeritus/</link><dc:creator>pupper emeritus</dc:creator><description>&lt;h3&gt;


&lt;!-- TEASER_END --&gt;
Brief
&lt;/h3&gt;

&lt;p&gt;I have worked on creating unit tests for the Lomb Scargle Cross Spectrum class, cross verifying the algorithm by comparing with the papers and fixed typos in docstrings. Apologies for the delay. Had my exams.&lt;/p&gt;

&lt;h3&gt;


Details
&lt;/h3&gt;

&lt;p&gt;I have noticed a few faults in both the fast and the slow algorithms. I have gone back to the drawing board and tried to address those issues by following the papers as closely as possible. All the changes are visible in the following draft pull request.&lt;br&gt;
&lt;a href="https://github.com/StingraySoftware/stingray/pull/737"&gt;https://github.com/StingraySoftware/stingray/pull/737&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After the fixing, the fast and the slow algorithm have started giving very similar outputs. I am starting to suspect that the time lags might be broken in the algorithms themselves. It is starting to get a little suspicious when different methods are giving very similar results and they are still not what that is expected. Last time around the fast and slow algorithms have given different results. After cross verifying with the papers, The results from both have fast and slow algorithms converged.&lt;/p&gt;

&lt;p&gt;To keep the project sailing along while I wait for confirmation that this is an issue with the implementation or the algorithm , I have decided to work on writing unit tests for the various classes and methods. Furthermore I also worked on fixing the docstrings.&lt;/p&gt;


&lt;div class="ltag_gist-liquid-tag"&gt;

&lt;/div&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2023/07/20230730_0735_pupperemeritus/</guid><pubDate>Sun, 30 Jul 2023 06:35:19 GMT</pubDate></item><item><title>Adapting Kurucz to SpectrumFactory and what is next ?</title><link>http://openastronomy.org/Universe_OA/posts/2023/07/20230729_2343_menasrac/</link><dc:creator>Racim MENASRIA</dc:creator><description>&lt;h4&gt;&lt;strong&gt;Adapting Kurucz to SpectrumFactory and what is next ?&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;After my first pull request I received some feedback.&lt;br&gt;Optional and major changes were requested. The most important changes were that my code should &lt;strong&gt;better integrate the existing Radis code&lt;/strong&gt;. Indeed, though I added a new database with Kurucz, its API remained distinct which is something which will make Radis progress toward a common API.&lt;/p&gt;
&lt;p&gt;Another key remark was that my code didn’t take into account the &lt;strong&gt;Broadening effects&lt;/strong&gt; that modify the lineshapes.&lt;br&gt;This is why I had a Team meeeting with my mentors to discuss the physics behind the code. It helped me a lot to understand what was expected.&lt;/p&gt;
&lt;p&gt;After this I worked on adding broadening and merging the new AdB Kurucz with SpectrumFactory. In order to do so, I worked on an example which allows to plot a spectrum using the Kurucz atomic data and &lt;strong&gt;SpectrumFactory.&lt;/strong&gt; My first attempt was to use one of the existing Radis formats for databanks named &lt;strong&gt;hdf5-radisdb&lt;/strong&gt; since I worked with hdf5 files in my Class.&lt;br&gt;This attempt happened to be too difficult because the formats were made for molecules and too many columns of my dataframe were different from the expected columns.&lt;br&gt;This is why I eventually decided to add &lt;strong&gt;a new format named “kurucz” &lt;/strong&gt;to the load_databank method which allows to load the kurucz data with the proper form.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Then, I worked on the &lt;strong&gt;eq_spectrum&lt;/strong&gt; method to adjust it to this newformat.&lt;br&gt;I added some methods and adapted methods from Exojax to handle linestrength computation, broadening,convolution,pressure layers and create a Spectrum Object. It took me a lot of efforts and I modified many files as Broadening.py, Base.by,Factory.py or loader.py.&lt;br&gt;However, the results of the Spectrum I obtained were not convincing and some parameters and units didn’t fit properly.&lt;/p&gt;
&lt;p&gt;Moreover, by the time I wrote this spectrocopy code, I fell behind in my project, that’s why we organized a long meeting with one of my supervisors in order to take stock, we adjusted the objectives of the project.&lt;/p&gt;
&lt;h4&gt;We gave up the last one about adding the CIA database and agreed on the following timeline :&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;finishing with SpectrumFactory for Kurucz ASAP&lt;/li&gt;&lt;li&gt;Moving to NIST&lt;/li&gt;&lt;li&gt;Then working on the DatabaseManager Class architecture and adapting to AdB and MdB manager subclasses&lt;/li&gt;&lt;li&gt;Moving to the TheoreTS ( it will require to reach people in Reims to fix the db that I still cannot access).&lt;/li&gt;&lt;li&gt;Working on developing an example during the last week to show what applications the atomic spectra physics brings.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We also noticed that I had written my Spectrum Factory example from the beginning rather than using the existing radis methods which is why I lost time and it was unaccurate. However, the meeting brought me the right guidelines and working on this code allowed me to getting a better understanding of the architecture and adapting the example to the existing structure of the code should be easier now. We also discussed about a few existing codes which could be a could starting point for adding NIST to Kurucz.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;The next weeeks will take me a lot of time and effort to complete the objectives but in the end, I am happy that we had this meeting because it unblocked me when I was kinda stuck with Kurucz for a while.&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=d3453292daf1" width="1"&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2023/07/20230729_2343_menasrac/</guid><pubDate>Sat, 29 Jul 2023 22:43:53 GMT</pubDate></item><item><title>Across the Summer of Code</title><link>http://openastronomy.org/Universe_OA/posts/2023/07/20230729_0533_exitflynn/</link><dc:creator>exitflynn</dc:creator><description>&lt;p&gt;I spent the most part of my time since last blog-post working on the failing tests.
The most complex client to fix and the most complex client in general, the GOES Client, needed to be changed a bit. The problem that arose there was mainly because of how we earlier had the liberty of parsing out any variable given down in the pattern since that string would never be used to act as a url but since we also want it to do the job of the baseurl, we can’t have any to-be-determined value in the base parts. Since the client involved calling a helper function that returned the data for specific values of those variables, I had to modify the code to obtain those values from that part instead of extracting it again from the URL (since we put it there in the URL string in the first place).
Another issue was implementing a system for dealing with cases where there’s no numerical representation for the month in the file’s URL, i.e. in the &lt;code&gt;%B&lt;/code&gt; or &lt;code&gt;%b&lt;/code&gt; datetime formats cases.
&lt;!-- TEASER_END --&gt;
Aside from that, I added tests to cover the newer parts of the codebase that I added.
I also added documentation about writing the new patterns.&lt;/p&gt;
&lt;p&gt;I made changes as per the PR reviews and now, finally, with all tests (remote or otherwise) passing, and the documentation updated, the scraper rewrite draft PR is ready for review!&lt;/p&gt;
&lt;p&gt;I had a meeting with Nabil to discuss what I have to get done where I also showed him one of my fav pasttime activities, browsing open cameras using Shodan and also discussed about some general career advice.&lt;/p&gt;
&lt;p&gt;While everyone has a look at the changes, Nabil guided me about moving on to “moving-the-code” part of the project now, which I’ll be doing by branching off from my current branch, the scraper rewrite one, and then making a PR to it since it builds on top of those changes and it’ll take a while and some reviews for it to merge into main. This way the mentors can review the PR and suggest changes while I work on it.&lt;/p&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2023/07/20230729_0533_exitflynn/</guid><pubDate>Sat, 29 Jul 2023 04:33:30 GMT</pubDate></item><item><title>GSoC - Week 7-8</title><link>http://openastronomy.org/Universe_OA/posts/2023/07/20230728_0000_gaurav17joshi/</link><dc:creator>Gaurav Joshi</dc:creator><description>&lt;h3 id="testing-features"&gt;Testing features&lt;/h3&gt;

&lt;p&gt;This week I refined my testing features for the code, and made the completed doctests.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;In my project, I was using 4 different kinds of dependencies, and none had been previously used by stingray, so I had to make some changes to the code structure to accomodate those exceptions.&lt;/p&gt;

&lt;p&gt;I also made updated and improved a lot of docstrings and added some doctests, which was a new experience. My &lt;code class="language-plaintext highlighter-rouge"&gt;get_prior&lt;/code&gt; doctest looked like:-&lt;/p&gt;

&lt;div class="language-python highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;can_sample&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt;     &lt;span class="n"&gt;pytest&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;skip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Jaxns not installed. Cannot make jaxns specific prior."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;tfp_available&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt;     &lt;span class="n"&gt;pytest&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;skip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Tensorflow probability required to make priors."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;params_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_gp_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"RN"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"gaussian"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Make&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;prior&lt;/span&gt; &lt;span class="n"&gt;dictionary&lt;/span&gt; &lt;span class="n"&gt;using&lt;/span&gt; &lt;span class="n"&gt;tensorflow_probability&lt;/span&gt; &lt;span class="n"&gt;distributions&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;prior_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt;    &lt;span class="s"&gt;"A"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tfpd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;low&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e-1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;high&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;2e+2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt;    &lt;span class="s"&gt;"t0"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tfpd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;low&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;high&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt;    &lt;span class="s"&gt;"sig"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tfpd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;low&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;high&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt;    &lt;span class="s"&gt;"arn"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tfpd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;low&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;high&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt;    &lt;span class="s"&gt;"crn"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tfpd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;low&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;jnp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;high&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;jnp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;prior_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_prior&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params_list&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prior_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id="jax-issues"&gt;Jax Issues&lt;/h3&gt;

&lt;p&gt;This week I also made a lot of futile tries in resolving an error in jax. As good and fast a library it is (I am yet to use some mindblowing features like pytrees), it has one limitation (or design decision), is that we cannot use not fixed sized arrays inside a jit function.&lt;/p&gt;

&lt;p&gt;In my project, one important issue that we wanted to tackle was the non stationarity of pulsar timeseries. The method to take this into account was to use a window over the data, ie only in the window we will asume a qpo and get its log likelihood and outside we will assume white noise outside. The problem in it was that jax jit functions wants to before handedly know the type and size of all its arrays and data structres, hense there was no way to create a window over the time-series.&lt;/p&gt;

&lt;p&gt;This while frustrating, also is a proof that code is often used in ways very different than intended or there are issues that we not taken into account when these important design desisions were made. (Though at no fault of the Jax library as before hand knowing the array shapes is crucial for fast parallel code)&lt;/p&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2023/07/20230728_0000_gaurav17joshi/</guid><pubDate>Thu, 27 Jul 2023 23:00:00 GMT</pubDate></item></channel></rss>