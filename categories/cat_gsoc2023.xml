<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts about gsoc2023)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/categories/cat_gsoc2023.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sun, 16 Jul 2023 01:28:23 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Wild Wild Tests</title><link>http://openastronomy.org/Universe_OA/posts/2023/07/20230714_0533_exitflynn/</link><dc:creator>exitflynn</dc:creator><description>&lt;h2 id="fool-proofing-the-rewrite"&gt;Fool-Proofing the Rewrite
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#fool-proofing-the-rewrite"&gt;
&lt;!-- TEASER_END --&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;After the last post, I mostly kept working on fixing the other failing tests and rewriting the tests to go with the newer pattern.&lt;/p&gt;
&lt;h2 id="not-all-failing-tests-are-built-same"&gt;Not All Failing Tests are Built Same
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#not-all-failing-tests-are-built-same"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;I managed to take care of them in a couple of days, except the &lt;code&gt;sunpy/net/tests/test_scraper.py::testFilesRange_sameDirectory_local&lt;/code&gt; which proved to be a tough one to figure out. After discussing it a bit, I was able to figure it out, the error was caused because of a very unique flow of things which I think would be interesting to mention. I found out the test was failing because in the &lt;code&gt;_localfilelist()&lt;/code&gt; function, we update the pattern class variable, call different functions on it and then fix it back at the end. Though once I realised this, I was able to spot that I needed to update the second pattern as well in a similar way and I discussed different approaches to do this with the mentors but the flow in the function was a very fun and intuitive way to do things that stood out to me for reason and I just wanted to make a note of it to look back on :P.&lt;/p&gt;
&lt;p&gt;I also discussed my doubt relating to trying to shorten parse patterns by avoiding repetitions somehow but we came to the conclusion that we don’t really need to do that, if a pattern has repetitions in it then the user’s got to repeat stuff!&lt;/p&gt;
&lt;h2 id="was-that-it"&gt;Was that it?
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#was-that-it"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;Now once all the scraper tests were passing, I thought the PR should be ready for review. I informed my mentors for the same. The PR received some suggestions, which I discussed and implemented according to the code review.&lt;/p&gt;
&lt;h2 id="the-plot-twist"&gt;The Plot Twist
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#the-plot-twist"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;For a few days, I remained under the impression that I had mostly rewritten the Scraper in a way that it works and only have to wait for suggestions from the code review. Nabil, Alasdair and I discussed that in the meanwhile I could look into which functions I can remove and move out of the Scraper. However, a plot twist unlike any other was still awaiting me and the realisation came when Nabil asked me if I had run the remote-tests yet. I had been running the &lt;code&gt;test-scraper.py&lt;/code&gt; tests so far, even the remote ones so my response was a vehement yes. When he mentioned that some were still failing, I remembered I was still to fix the examples in the documentation and once I had fixed the doctests it’d be passing. However at this point I was beginning to see the &lt;em&gt;real&lt;/em&gt; issue, so far I had only been fixing the tests limited to the scraper and NOT the rest of the codebase.&lt;/p&gt;
&lt;h2 id="a-whole-new-world"&gt;A Whole New World
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#a-whole-new-world"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;I ran the tests to be greeted with very polite &lt;code&gt;105 failing tests&lt;/code&gt;. I informed this to my mentors and have begun working on fixing all the parts of the codebases which indirectly depend on this class. So far I’ve been encountering functions that may / may not have possibly gone redundant and am now exploring and considering which reducing functions, or removing them while fixing tests.&lt;/p&gt;
&lt;h2 id="next-steps"&gt;Next Steps
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#next-steps"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;I’ll keep on working on these new tests, while analysing both the scraper and related parts of the codebase outside for functions to rewrite, remove and/or move at the same time.
I also realised we’ll be needing new documentation about how to write the new parse-style patterns.&lt;/p&gt;
&lt;p&gt;That is all so far, until next time!&lt;/p&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2023/07/20230714_0533_exitflynn/</guid><pubDate>Fri, 14 Jul 2023 04:33:30 GMT</pubDate></item><item><title>GSoC - Week 5-6</title><link>http://openastronomy.org/Universe_OA/posts/2023/07/20230711_0000_gaurav17joshi/</link><dc:creator>Gaurav Joshi</dc:creator><description>&lt;h3 id="making-a-demo"&gt;Making a Demo&lt;/h3&gt;
&lt;p&gt;I had recently made some changes to my GP and GPResult class on the advice of my mentors and I realised that I am not making the tool keeping the user in mind.&lt;/p&gt;

&lt;!-- TEASER_END --&gt;
&lt;p&gt;See, in contemporary data analysis, Gaussian Processes GP’s are very useful to fit and extrapolate the data. If we have some data points, we can use any suitable kernel function and a 0 mean and we will get a nicely fitting GP, which will also allow us to know function values at new points with error bars. But this is not what the users need in astronomy. They do not usually need to extrapolate the data to get values at new points, rather, they want to make a compare models with different charachteristics, signals, and identify which signal is present in the time series.&lt;/p&gt;

&lt;p&gt;Thus making the demo notebook gave me an extrinsic view of the problem, and it made me change the arrangement of a lot of classes and functions in the code.&lt;/p&gt;

&lt;h3 id="new-implimenatations"&gt;New implimenatations&lt;/h3&gt;

&lt;h4 id="gpr-class"&gt;GPR class&lt;/h4&gt;
&lt;p&gt;The big new implimentation that I made, was to entirely change the feature from having a GP class for data fitting and a GPResult class for bayesian inference to just the GPResult class for inferencing and plotting.&lt;/p&gt;

&lt;p&gt;I changed the tool to just a GPResult class, that takes a suitable prior and log likelihood function samples out the posterior parameters. This also has a lot of new plotting features which are helpul to visualise the posterior parameter.&lt;/p&gt;

&lt;div class="language-python highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;GPResult&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="s"&gt;"""
Makes a GPResult object which takes in a Stingray.Lightcurve and samples parameters of a model
(Gaussian Process) based on the given prior and log_likelihood function.
"""&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Lc&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Lightcurve&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Lc&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Lc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Lc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prior_model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;likelihood_model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="s"&gt;""" Makes a Jaxns nested sampler over the Gaussian Process, given the
prior and likelihood model """&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prior_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;prior_model&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;likelihood_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;likelihood_model&lt;/span&gt;

&lt;span class="n"&gt;NSmodel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prior_model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prior_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;log_likelihood&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;likelihood_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;NSmodel&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sanity_check&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PRNGKey&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;S&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Exact_ns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ExactNestedSampler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NSmodel&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_live_points&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Termination_reason&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;State&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Exact_ns&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PRNGKey&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;term_cond&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;TerminationCondition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;live_evidence_frac&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Exact_ns&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_results&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;State&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Termination_reason&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Simulation Complete"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_evidence&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="s"&gt;""" Returns the log evidence of the model """&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;print_summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="s"&gt;""" Prints a summary table for the model parameters """&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And many other plotting functions like&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;plot_diagnostics&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;plot_cornerplot&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;get_parameters_name&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;get_max_posterior_parameters&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;get_max_likelihood_parameters&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;posterior_plot&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;weighted_posterior_plot&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;corner_plot&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id="get-prior-function"&gt;Get Prior function&lt;/h4&gt;
&lt;p&gt;Earlier the &lt;code class="language-plaintext highlighter-rouge"&gt;get_prior&lt;/code&gt; function was a big function which took in your kernel and mean type, and gave you the prior function, but I had to write a separate function for each comibination making it a gignantic function of unecessary repeated code, also the prior ranges and distribution types (uniform, cauchy etc) was fixed according to what I had hard-coded without any way to change it. If someon wanted to implement a prior with even a small change, it was not possible.&lt;/p&gt;

&lt;p&gt;So My mentor suggested making the function, such that the user inputs the tensorflow priors based on their needs, and we just make a jaxns prior for it. This led to the new code:-&lt;/p&gt;

&lt;div class="language-python highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_prior&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params_list&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prior_dict&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="s"&gt;"""
A prior generator function based on given values
"""&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;prior_model&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;span class="n"&gt;prior_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;params_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prior_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;tfpd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Distribution&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="n"&gt;parameter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;Prior&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prior_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;parameter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;prior_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;prior_list&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;parameter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;tuple&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prior_list&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;prior_model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id="get-likelihood-function"&gt;Get likelihood function:&lt;/h4&gt;
&lt;p&gt;Similarly I changed the likelihood functin so that it takes a parmeter array, and the kernel, mean type and gives us a log_likelihood function which calculates and gets the likelihood of the data being fitted for the parameters.&lt;/p&gt;

&lt;div class="language-python highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_likelihood&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params_list&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mean_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="s"&gt;"""
A likelihood generator function based on given values
"""&lt;/span&gt;
&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="n"&gt;jit&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;likelihood_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="nb"&gt;dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params_list&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;kernel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;kernel_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_params&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mean_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mean_params&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;gp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GaussianProcess&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;"Times"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;mean_value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;"Times"&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;gp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_probability&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;"counts"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;likelihood_model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id="jit-issues"&gt;Jit issues&lt;/h4&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2023/07/20230711_0000_gaurav17joshi/</guid><pubDate>Mon, 10 Jul 2023 23:00:00 GMT</pubDate></item><item><title>Improving time efficiency of Vaex Implementation</title><link>http://openastronomy.org/Universe_OA/posts/2023/07/20230706_0000_1someshverma/</link><dc:creator>Somesh Verma</dc:creator><description>&lt;p&gt;Though Vaex reduced memory use by RADIS to compute specturm but it is slow for smaller databank and in our case when the number of lines in the databank is very less . The slow performance of Vaex for smaller dataframes is due to three main reasons for our implementation of RADIS&lt;/p&gt;

&lt;ul&gt;
&lt;!-- TEASER_END --&gt;
&lt;li&gt;First vaex is optimized for larger databank and doesn’t focus that much for smaller dataframe .&lt;/li&gt;
&lt;li&gt;Vaex uses virtual columns to reduce memory and only compute the virutal column when it is required it saves memory space but in case when virtual column
is required multiple times then it is computed multiple times and it costs time . For Pandas it only compute the column only once and saves it for further calculations and in-memory compute of Pandas are faster than Vaex for smaller dataframes.&lt;/li&gt;
&lt;li&gt;Vaex is based on Apache Arrow and uses Expression class for column while for Pandas which stores column as numpy no conversion is required to use library functions of numpy but for vaex some operations require explict conversion to numpy array and it costs time.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Apart from this there was issue it the implementation of vaex which are now optimized by better alternatives.
Intially the time graph for Vaex and Pandas in terms of time comparison was as given below-&lt;/p&gt;

&lt;p&gt;Total Time  which is the sum of loading time and computation time for calculating spectrum .
Plot of Total Time vs Number of lines Graph&lt;/p&gt;

&lt;p&gt;&lt;img alt="Vaex Comparison" src="https://1someshverma.github.io/images/earlierTotal.png"&gt;&lt;/p&gt;

&lt;p&gt;Computation time , it is time required to compute the spectrum using Vaex or Implementation
Plot of Compuation Time vs Number of lines Graph&lt;/p&gt;

&lt;p&gt;&lt;img alt="Vaex Comparison" src="https://1someshverma.github.io/images/earlierCom.png"&gt;&lt;/p&gt;

&lt;p&gt;##Optimizations&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Calculating Sum&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At first we were computing the sum as&lt;/p&gt;

&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt; error = df[b].S.sum() / df.S.sum() * 100
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;but later changed it to&lt;/p&gt;
&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;error_cutoff = df[b].sum(df[b].S) / df.sum(df.S) * 100
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The time taken to calculate 25 spectra decreased from 6.0 s to 5.4 s&lt;/p&gt;

&lt;p&gt;Code used was&lt;/p&gt;

&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;from radis import calc_spectrum
import time

t0 = time.time()
for i in range(25):
s = calc_spectrum(2000, 2010,         # cm-1
molecule='CO',
isotope='1,2,3',
pressure=1.01325,   # bar
Tgas=1000,
mole_fraction=0.1,
databank='hitemp',  # or 'hitemp'
diluent = "air",
verbose = 0,
engine = "vaex"
)
t1 = time.time()
print(t1 -t0)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Not using df.extract()
After masking some of the rows, that is filtering some of the rows based on some conditions . Then I was using df.extract(), later i found it was using a lot of time .So i commented that and refactored code to work without it .
&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;df = df.extract() # later commented it .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Improvements after this was quite impressive as i found out running below codes&lt;/p&gt;

&lt;p&gt;It reduced calculation time for the code below by 10 seconds&lt;/p&gt;

&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;from radis import calc_spectrum

import time
t0=time.time()

s = calc_spectrum(1500, 2500,         # cm-1
molecule='H2O',
isotope='1,2,3',
pressure=1.01325,   # bar
Tgas=700,           # K
mole_fraction=0.1,
wstep='auto',
path_length=1,      # cm
databank='hitemp',  # or 'hitemp', 'geisa', 'exomol'
engine='vaex',
)

s.apply_slit(0.5, 'nm')       # simulate an experimental slit

t1=time.time()

print('Time taken : '+str(t1 - t0))

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And reduced 0.5 seconds calculation time for the code&lt;/p&gt;

&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;from radis import calc_spectrum
import time
t0=time.time()
s = calc_spectrum(2000, 2010,         # cm-1
molecule='CO',
isotope='1,2,3',
pressure=1.01325,   # bar
Tgas=1000,
mole_fraction=0.1,
databank='hitran',  # or 'hitemp'
diluent = "air",
verbose = 3,
engine = "vaex"
)
t1=time.time()


print('Time taken : '+str(t1-t0))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After all of this updated time graph were as below
&lt;img alt="Vaex Comparison" src="https://1someshverma.github.io/images/updatedCom.png"&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt="Vaex Comparison" src="https://1someshverma.github.io/images/updatedTotal.png"&gt;&lt;/p&gt;

&lt;p&gt;I significant improvement can be observed from it .&lt;/p&gt;

&lt;p&gt;Now to smaller time performance of smaller dataframe , I converted the vaex dataframes to pandas for smaller databases. And overall improvemets are as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Memory performance is improved for all dataframes.&lt;/li&gt;
&lt;li&gt;Time performance is same for smaller dataframes , and for larger dataframes time performance of vaex is quite better than Pandas.&lt;/li&gt;
&lt;/ul&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2023/07/20230706_0000_1someshverma/</guid><pubDate>Wed, 05 Jul 2023 23:00:00 GMT</pubDate></item><item><title>GPUs and Convolutions in Gnuastro</title><link>http://openastronomy.org/Universe_OA/posts/2023/07/20230704_0000_labeeb-7z/</link><dc:creator>Labib Asari</dc:creator><description>&lt;h3 id="background"&gt;Background&lt;/h3&gt;

&lt;p&gt;This is an overview of what I’ve been upto for the past 2 weeks. Doesn’t go into much technical details and the actual code but just walks through the general idea.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Convolution"&gt;Convolution&lt;/a&gt;  is a fundamental operation in various domains, such as image processing, signal processing, and deep learning. It is an important module in Gnuastro and is also used as a subroutine in other modules.&lt;/p&gt;

&lt;p&gt;Convolutional operations can be broken down into smaller tasks, such as applying the kernel to different portions of the input data. By utilizing multiple threads, each thread can independently process a subset of the input, reducing the overall execution time. This parallelization technique is particularly effective when dealing with large input tensors or performing multiple convolutions simultaneously.&lt;/p&gt;

&lt;p&gt;While traditional CPUs (Central Processing Units) excel at performing a wide range of tasks, they are not specifically designed for heavy parallel computations like convolutions. On the other hand, GPUs (Graphics Processing Units) are highly optimized for parallel processing, making them ideal for accelerating convolutional operations.&lt;/p&gt;

&lt;h3 id="gpus-vs-cpus-architecture"&gt;GPUs vs CPUs Architecture&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Architecture difference" src="https://labeeb-7z.github.io/Blogs/img/posts/gpus/architecture.png"&gt;&lt;/p&gt;

&lt;h4 id="cores-and-parallelism-"&gt;Cores and Parallelism :&lt;/h4&gt;
&lt;p&gt;CPUs have fewer, more powerful cores optimized for sequential processing, while GPUs have thousands of smaller cores designed for parallel processing. This parallelism allows GPUs to perform computations on multiple data elements simultaneously, leading to significant speedup in parallelizable tasks like graphics rendering and deep learning.&lt;/p&gt;

&lt;h4 id="memory-hierarchy-"&gt;Memory Hierarchy :&lt;/h4&gt;
&lt;p&gt;CPUs typically have larger caches and more advanced memory management units (MMUs), focusing on low-latency operations and complex branch prediction. GPUs, prioritize high memory bandwidth and utilize smaller caches to efficiently handle large amounts of data simultaneously, crucial for tasks like image processing and scientific simulations.&lt;/p&gt;

&lt;h4 id="emphasis-"&gt;Emphasis :&lt;/h4&gt;
&lt;p&gt;CPUs are designed with an emphasis on executing single threads - very fast. GPUs are designed with an emphasis on executing on executing multiple threads.&lt;/p&gt;

&lt;h3 id="programming-model"&gt;Programming Model&lt;/h3&gt;
&lt;p&gt;For Programming GPUs, several frameworks (high level APIs) are available&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CUDA - developed by NVIDIA for its GPUs.&lt;/li&gt;
&lt;li&gt;OpenCL - Open Source, Cross Platform parallel programming standard for diverse accelerators.&lt;/li&gt;
&lt;li&gt;HIP - developed by AMD, portable.&lt;/li&gt;
&lt;li&gt;and many more….&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="cuda"&gt;CUDA&lt;/h3&gt;

&lt;h4 id="the-cuda-platform-consists-of-a-programming-language-a-compiler-and-a-runtime-library"&gt;The CUDA platform consists of a programming language, a compiler, and a runtime library.&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code class="language-plaintext highlighter-rouge"&gt;Programming Language&lt;/code&gt; - Based on C, has extensions to write code for GPU.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-plaintext highlighter-rouge"&gt;Compiler&lt;/code&gt; - Based on clang, offloads host code to system compiler and translates device code into binary code that can be executed on the GPU.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-plaintext highlighter-rouge"&gt;Runtime Library&lt;/code&gt; - Provides the necessary functions and tools to manage the execution of the code on the GPU (interacts with the driver).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note : When we have multiple devices(GPUs, FPGAs, etc) on a single system, which can execute tasks apart from the main CPU, they’re generally referred to as &lt;code class="language-plaintext highlighter-rouge"&gt;device&lt;/code&gt; whereas the main CPU is referred to as &lt;code class="language-plaintext highlighter-rouge"&gt;host&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id="cuda-programs"&gt;CUDA Programs&lt;/h3&gt;

&lt;p&gt;CUDA programs consists of normal host code along with some &lt;code class="language-plaintext highlighter-rouge"&gt;kernels&lt;/code&gt;.
Kernels are like other functions, but when you call a kernel, they’re executed N times parallely by N different CUDA threads, as opposed to only once like normal functions. They’re defined using the &lt;code class="language-plaintext highlighter-rouge"&gt;__global__&lt;/code&gt; keyword.&lt;/p&gt;

&lt;p&gt;Eg :
&lt;img alt="kernel example" src="https://labeeb-7z.github.io/Blogs/img/posts/gpus/kernel.png"&gt;&lt;/p&gt;

&lt;p&gt;Normally, we put the above piece of code inside a loop, so all elements are covered.&lt;/p&gt;

&lt;p&gt;With GPUs, there’s no need for loops - for N elements, we launch N threads each of which add 1 element at the same time!&lt;/p&gt;

&lt;h3 id="cuda-execution-configuration"&gt;CUDA Execution Configuration&lt;/h3&gt;

&lt;p&gt;Can we launch an arbitrary large number of threads?
Technically No&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The maximum allowed threads depend on your GPUs compute capability.&lt;/li&gt;
&lt;li&gt;But generally it’s so large, it always covers all your elements&lt;/li&gt;
&lt;li&gt;For Compute Capability &amp;gt; 3.0
&lt;ul&gt;
&lt;li&gt;Max Number of threads : (2^31)&lt;em&gt;(2^16)&lt;/em&gt;(2^16)&lt;em&gt;(2&lt;/em&gt;10) = 2^42!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id="threads-and-blocks-"&gt;Threads and Blocks :&lt;/h4&gt;

&lt;p&gt;&lt;img alt="Threads and Blocks" src="https://labeeb-7z.github.io/Blogs/img/posts/gpus/config.png"&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;All threads are organized into groups called - Block.&lt;/li&gt;
&lt;li&gt;All blocks are organized into groups called - Grid.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Blocks and Grids could be a 1D, 2D or 3D structures.&lt;/p&gt;

&lt;p&gt;When calling a GPU kernel, we specify the structure of each block, number of blocks, and number of threads/block - This is called the Execution Configuration.&lt;/p&gt;

&lt;p&gt;Example :
&lt;img alt="Launching a kernel example" src="https://labeeb-7z.github.io/Blogs/img/posts/gpus/launch-kernel.png"&gt;&lt;/p&gt;

&lt;p&gt;The above code Launches
32&lt;em&gt;32&lt;/em&gt;1 = 1024 blocks
Each having 16&lt;em&gt;16 = 256 threads
Total no. of threads = 1024&lt;/em&gt;256.&lt;/p&gt;

&lt;h3 id="cuda-memory-hierarchy"&gt;CUDA Memory Hierarchy&lt;/h3&gt;

&lt;p&gt;&lt;img alt="Memory Hierarchy" src="https://labeeb-7z.github.io/Blogs/img/posts/gpus/memory.png"&gt;
CUDA threads may access data from multiple memory spaces during their execution as illustrated above.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Local memory for each thread.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shared memory b/w all threads of same block.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Global memory b/w all blocks.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="cuda-hardware-abstraction"&gt;CUDA Hardware abstraction&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Hardware Abstraction" src="https://labeeb-7z.github.io/Blogs/img/posts/gpus/hardware.png"&gt;&lt;/p&gt;

&lt;p&gt;The entire GPU is divided into several Streaming MultiProcessors (SMs). They have different architecture than a typical CPU core. Each SM has several CUDA cores, which are the actual processing units.&lt;/p&gt;

&lt;p&gt;It is designed with SIMT/SIMD philosophy, which allow execution of multiple threads concurrently on them. One Block is executed at a time on a single SM.&lt;/p&gt;

&lt;h3 id="cuda-developing-workflow"&gt;CUDA Developing Workflow&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Workflow" src="https://labeeb-7z.github.io/Blogs/img/posts/gpus/workflow.png"&gt;&lt;/p&gt;

&lt;h3 id="results-of-convolution-on-gpu-for-gnuastro"&gt;Results of Convolution on GPU for Gnuastro&lt;/h3&gt;

&lt;p&gt;All tests were performed on a system with the following specifications:&lt;/p&gt;

&lt;p&gt;CPU :&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Intel(R) Core(TM) i5-9300HF CPU @ 2.40GHz&lt;/li&gt;
&lt;li&gt;Thread(s) per core:  2&lt;/li&gt;
&lt;li&gt;Core(s) per socket:  4&lt;/li&gt;
&lt;li&gt;Socket(s):           1&lt;/li&gt;
&lt;li&gt;CPU max MHz:         4100.0000&lt;/li&gt;
&lt;li&gt;CPU min MHz:         800.0000&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GPU :&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;NVIDIA GeForce GTX 1650&lt;/li&gt;
&lt;li&gt;Turing Architecture&lt;/li&gt;
&lt;li&gt;Driver Version:      535.54.03&lt;/li&gt;
&lt;li&gt;CUDA Version:        12.2&lt;/li&gt;
&lt;li&gt;VRAM :               4GB&lt;/li&gt;
&lt;li&gt;Compute Capability : 7.5&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The input image was a 10k x 20k FITS file with 32-bit floating point values. The kernel was a 3x3 matrix with 32-bit floating point values.&lt;/p&gt;

&lt;h4 id="cpu-multi-threaded"&gt;CPU Multi-threaded&lt;/h4&gt;

&lt;p&gt;&lt;img alt="CPU" src="https://labeeb-7z.github.io/Blogs/img/posts/gpus/cpu-result.png"&gt;&lt;/p&gt;

&lt;h4 id="gpu"&gt;GPU&lt;/h4&gt;

&lt;p&gt;&lt;img alt="GPU" src="https://labeeb-7z.github.io/Blogs/img/posts/gpus/gpu-result.png"&gt;&lt;/p&gt;

&lt;p&gt;The overall speedups seems to only be 6X but this also counts the time taken to transfer the data from CPU to GPU and back. If we only consider the time taken to perform the convolution, the speedup is around ~700X!.&lt;/p&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2023/07/20230704_0000_labeeb-7z/</guid><pubDate>Mon, 03 Jul 2023 23:00:00 GMT</pubDate></item><item><title>GSoC Week 4 Update</title><link>http://openastronomy.org/Universe_OA/posts/2023/07/20230703_1917_pupperemeritus/</link><dc:creator>pupper emeritus</dc:creator><description>&lt;h2&gt;


&lt;!-- TEASER_END --&gt;
Brief
&lt;/h2&gt;

&lt;p&gt;This week I successfully finished implementing the fast algorithm. Now my &lt;code&gt;LombScargleCrossspectrum&lt;/code&gt; and &lt;code&gt;LombScarglePowerspectrum&lt;/code&gt; are that much closer to completion. Only things left to sort out/implement are time lags and phase lag functions and checking the phase of the output.&lt;/p&gt;

&lt;h2&gt;


Details
&lt;/h2&gt;

&lt;p&gt;Testing on the following synthetic data has been conducted to compare the outputs with the existing cross spectrum and power spectrum for evenly spaced data first then checking the outputs of the lomb scargle variants on unevenly sampled data&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;rand = np.random.default_rng(42)
n = 1000
t = np.linspace(0, 10, n)
y = np.sin(2 * np.pi * 3.0 * t) + 0.1 * rand.standard_normal(n)
y2 = np.sin(2 * np.pi * 3.0 * t) + 0.1 * rand.standard_normal(n)
y -= np.min(y)
y2 -= np.min(y2)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;h3&gt;


The Cross spectra for evenly sampled data
&lt;/h3&gt;

&lt;p&gt;&lt;a class="article-body-image-wrapper" href="https://res.cloudinary.com/practicaldev/image/fetch/s--HDSGExDP--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ldcxxcpq760ym5yph7jv.png"&gt;&lt;img alt="Image description" height="417" src="https://res.cloudinary.com/practicaldev/image/fetch/s--HDSGExDP--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ldcxxcpq760ym5yph7jv.png" width="558"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;


The time lags for evenly sampled data
&lt;/h3&gt;

&lt;p&gt;As it is evident the time lags need work.&lt;/p&gt;

&lt;p&gt;&lt;a class="article-body-image-wrapper" href="https://res.cloudinary.com/practicaldev/image/fetch/s--5_uNnIpc--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/sknrib3nkos5tcnojlng.png"&gt;&lt;img alt="Image description" height="413" src="https://res.cloudinary.com/practicaldev/image/fetch/s--5_uNnIpc--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/sknrib3nkos5tcnojlng.png" width="559"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;


The power spectra for evenly sampled data
&lt;/h3&gt;

&lt;p&gt;One quirk is that the power spectrum class is returning the power spectrum with a negative sign. This is a known bug. The values otherwise are within margin of error.&lt;/p&gt;

&lt;p&gt;&lt;a class="article-body-image-wrapper" href="https://res.cloudinary.com/practicaldev/image/fetch/s--njHhZDEY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vtf835ktnxo9dn83iy55.png"&gt;&lt;img alt="Image description" height="417" src="https://res.cloudinary.com/practicaldev/image/fetch/s--njHhZDEY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vtf835ktnxo9dn83iy55.png" width="559"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;


The Lomb Scargle cross spectrum and power spectrum when data is unevenly sampled
&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;t = np.sort(rand.random(n))*10&lt;/code&gt;&lt;/p&gt;
&lt;h4&gt;


The cross spectrum
&lt;/h4&gt;

&lt;p&gt;&lt;a class="article-body-image-wrapper" href="https://res.cloudinary.com/practicaldev/image/fetch/s--LeUsZL3d--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bzddaq7u9naiskry0x7i.png"&gt;&lt;img alt="Image description" height="417" src="https://res.cloudinary.com/practicaldev/image/fetch/s--LeUsZL3d--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bzddaq7u9naiskry0x7i.png" width="558"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;


The power spectrum
&lt;/h4&gt;

&lt;p&gt;&lt;a class="article-body-image-wrapper" href="https://res.cloudinary.com/practicaldev/image/fetch/s--mFs4vcWd--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/yfz6sav17mw51yas49he.png"&gt;&lt;img alt="Image description" height="417" src="https://res.cloudinary.com/practicaldev/image/fetch/s--mFs4vcWd--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/yfz6sav17mw51yas49he.png" width="559"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;


The time lags
&lt;/h4&gt;

&lt;p&gt;&lt;a class="article-body-image-wrapper" href="https://res.cloudinary.com/practicaldev/image/fetch/s--bAp6Nw-1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qkyr5to5lbkxm2s2xbi9.png"&gt;&lt;img alt="Image description" height="413" src="https://res.cloudinary.com/practicaldev/image/fetch/s--bAp6Nw-1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qkyr5to5lbkxm2s2xbi9.png" width="559"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;They are off here too. Which will be fixed in the coming week.&lt;/p&gt;

&lt;p&gt;For exhaustive testing code refer&lt;br&gt;
&lt;/p&gt;
&lt;div class="ltag_gist-liquid-tag"&gt;

&lt;/div&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2023/07/20230703_1917_pupperemeritus/</guid><pubDate>Mon, 03 Jul 2023 18:17:26 GMT</pubDate></item><item><title>Setting Up for the Kurucz PR and transitioning to the TheoReTS</title><link>http://openastronomy.org/Universe_OA/posts/2023/07/20230702_1407_menasrac/</link><dc:creator>Racim MENASRIA</dc:creator><description>&lt;p&gt;This week was not the most enjoyable phase of the project so far, as I had to exert considerable effort to fix failing tests before opening a pull request.&lt;/p&gt;
&lt;p&gt;Once I ensured that the initial tests passed, I wrote my own tests to confirm that the new AdB Kurucz class didn’t interfere with any part of the existing code. At this point, I encountered a primary issue. I hadn’t noticed that one of the methods I had adapted from ExoJAX was still reading a file which necessitated an ExoJAX package dependency. This caused the build to fail on GitHub due to one of the tests in my kurucz_test.py file failing.&lt;/p&gt;
&lt;p&gt;Since there’s a conflict related to the JAX installation on Windows, I couldn’t add it to the requirements file. Doing so would create a conflict for every Windows user installing Radis. Consequently, I had to write a program to extract the data from this package and store a copy of it in a local file called pfdat.txt. This enabled the problematic function to read from the local copy instead of the ExoJAX file. This solution successfully rectified the problem, and now my PR passes the tests and is awaiting review before merging.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;The next step is to transition to the TheoReTS as planned. According to the TheoReTS website, it is an information system for theoretical spectra based on variational predictions from molecular potential energy and dipole moment surfaces. It is jointly developed by the PMT team of GSMA (Reims), Tomsk University, and IAO Acad Sci. Russia. As a result, it provides two access points, one French and the other Russian. However, I noticed that the access to the French website (&lt;a href="http://theorets.univ-reims.fr/"&gt;http://theorets.univ-reims.fr/&lt;/a&gt;) is currently unavailable, preventing me from visualizing the data. This is an issue I should discuss with my mentors.&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=d9643c0269aa" width="1"&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2023/07/20230702_1407_menasrac/</guid><pubDate>Sun, 02 Jul 2023 13:07:42 GMT</pubDate></item><item><title>Scraper Things</title><link>http://openastronomy.org/Universe_OA/posts/2023/06/20230630_0133_exitflynn/</link><dc:creator>exitflynn</dc:creator><description>&lt;p&gt;Most of the week was spent rewriting the Scraper functions to go with the new parse-pattern and then looking for edge cases in the new implementations, fixing bugs and updating tests.&lt;/p&gt;
&lt;h2 id="catching-up"&gt;{{Catching up}}
&lt;span&gt;
&lt;!-- TEASER_END --&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#catching-up"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;In the scraper, while trying to merge &lt;code&gt;baseurl&lt;/code&gt; (an strftime formatted pattern i.e.&lt;code&gt; %Y%m&lt;/code&gt; etc) and &lt;code&gt;pattern&lt;/code&gt; (parse formatted pattern i.e. &lt;code&gt;{year:4d}{month:2d}&lt;/code&gt; etc), I faced two choices, we could either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Make the input all parse-style formatted. generate the datetime-compatible string from here wherever it is required, however the problem i was running into here is parse-stuff like &lt;code&gt;{year:2d}&lt;/code&gt; will collide with &lt;code&gt;{instrument}&lt;/code&gt; like placeholders on which we mean to call &lt;code&gt;.format(**kwargs)&lt;/code&gt; on. All the ways I could think of pulling it off included adding a large no. of lines of code in the really early part of &lt;code&gt;__init__()&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make the input all datetime formatted and generate the parse pattern from here. The problem with this is there are edge-cases when sometimes users define variables like &lt;code&gt;{Level:1d}&lt;/code&gt; which we have no way of knowing beforehand. One way to go about this could’ve been that we tell the user to define a pattern string in addition to baseurl whenever they have any new variables like that.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We ended up going with the first. My mentor, &lt;a href="https://github.com/Nabobalis"&gt;Nabil&lt;/a&gt; introduced me to how there’s a prevalence of using double-curly brackets in places where we need to escape / use them with single curly brackets, and sure enough, the &lt;code&gt;parse&lt;/code&gt; module supports that. So that took care of the problem there, I was mostly a bit concerned that I’ll have to go back to the second way even though I had started with it before pivoting to the first one.&lt;/p&gt;
&lt;h2 id="communication"&gt;Communication
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#communication"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;Nabil pointed out that we weren’t being very good at communicating and that has a negative effect on the project which lead me to change how I was approaching it.&lt;/p&gt;
&lt;p&gt;A lot of times I was debugging things by including print statements here and there, and since my project now involves changing API it had me updating tests and a lot of these times the problem would just be in my understanding on how to convert the patterns and just how the new input should look like. Previously, I would only send a message on the matrix room when I had a question. And most of the times I’d still hold out hope for solving something by myself when I have the strength to pick it up later. But it also makes sense because there’d be no way to differentiate that from me not doing anything. Also around 75% of the time I’ve drafted out questions, I found out an answer along the way. From now on I realise instead of just asking questions, I should think of it as a logging / progress-updating activity first which sounds obvious in hindsight.&lt;/p&gt;
&lt;h2 id="to-regex-or-not-to-regex"&gt;To regex or not to regex
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#to-regex-or-not-to-regex"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;The next part where I was stuck at was in converting a pattern that involved custom placeholders like &lt;code&gt;{{CAR_ROT:4d}}&lt;/code&gt; or &lt;code&gt;{{:3d}}&lt;/code&gt; to their regex counterparts like  &lt;code&gt;(\d){3}&lt;/code&gt;, &lt;code&gt;(\d){16}&lt;/code&gt; etc without using like a l o t of regex, any less complex method than using a conversion function etc. However, after a quick conversation with the mentors and I realised that I had been mistakenly assuming that strftime required regex patterns. Earlier I thought that regex would no longer be part of the end-user experience but still somehow exist in the codebase but this is when I realised that we can entirely do away with it.&lt;/p&gt;
&lt;h2 id="rewrite-then-remove-"&gt;Rewrite then Remove? 💀
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#rewrite-then-remove-"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;I also realised that the &lt;code&gt;_extractDateURL()&lt;/code&gt; function was made redundant &lt;em&gt;after&lt;/em&gt; rewriting it since I found out later that it was only called at one place and that part of the code was no longer required thanks to the existence of a parse-pattern. That’s a nice message to keep in mind for the future.&lt;/p&gt;
&lt;h2 id="modern-day-cain"&gt;Modern Day Cain
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#modern-day-cain"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;Another question I encountered was if we could assume that any {year:2d} or %y type 2-digit year xx to be interpreted to be in the 21st century like 20xx or not.&lt;/p&gt;
&lt;h2 id="issue-found"&gt;Issue found
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#issue-found"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;I also found this bug in the codebase:
In the current &lt;code&gt;scraper._check_timerange()&lt;/code&gt;, it takes the simpler way &lt;code&gt;if&lt;/code&gt; we provide it with an extractor // parse-pattern and a more complex way if we don’t, however as it is implemented right now&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0"&gt;&lt;code class="language-python"&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;&lt;span style="color: #f92672;"&gt;from&lt;/span&gt; sunpy.net.scraper &lt;span style="color: #f92672;"&gt;import&lt;/span&gt; Scraper
&lt;/span&gt;&lt;/span&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;&lt;span style="color: #f92672;"&gt;from&lt;/span&gt; sunpy.time &lt;span style="color: #f92672;"&gt;import&lt;/span&gt; TimeRange
&lt;/span&gt;&lt;/span&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;s &lt;span style="color: #f92672;"&gt;=&lt;/span&gt; Scraper(&lt;span style="color: #e6db74;"&gt;'%Y.fits'&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;s&lt;span style="color: #f92672;"&gt;.&lt;/span&gt;_check_timerange(&lt;span style="color: #e6db74;"&gt;'2014.fits'&lt;/span&gt;, TimeRange(&lt;span style="color: #e6db74;"&gt;"2015-01-01"&lt;/span&gt;, &lt;span style="color: #e6db74;"&gt;"2015-01-02"&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;would return True and it is intended that way in the tests but if we passed it an extractor // parse pattern&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0"&gt;&lt;code class="language-python"&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;s&lt;span style="color: #f92672;"&gt;.&lt;/span&gt;extractor &lt;span style="color: #f92672;"&gt;=&lt;/span&gt; &lt;span style="color: #e6db74;"&gt;"&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;{year:4d}&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;.fits"&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;s&lt;span style="color: #f92672;"&gt;.&lt;/span&gt;_check_timerange(&lt;span style="color: #e6db74;"&gt;'2014.fits'&lt;/span&gt;, TimeRange(&lt;span style="color: #e6db74;"&gt;"2015-01-01"&lt;/span&gt;, &lt;span style="color: #e6db74;"&gt;"2015-01-02"&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;it’d return False.&lt;/p&gt;
&lt;h2 id="inclusivity-is-important"&gt;Inclusivity is important
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#inclusivity-is-important"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;Failing tests required me to inqure if we want closed-intervals in the package or open, which concluded with closed. I also found other instances in the codebase where we endorse closed intervals.&lt;/p&gt;
&lt;h2 id="future-steps"&gt;Future steps
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#future-steps"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;Cover why the rest of tests are breaking and fix em.
Ask for review once everything works.
Try to come up with a way to write parse-patterns so as the length remains less by trying to minimize repeated values.
Also fix my Hugo setup before the night -_-&lt;/p&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2023/06/20230630_0133_exitflynn/</guid><pubDate>Fri, 30 Jun 2023 00:33:30 GMT</pubDate></item><item><title>GSoC Week 2-3 Update</title><link>http://openastronomy.org/Universe_OA/posts/2023/06/20230625_1615_pupperemeritus/</link><dc:creator>pupper emeritus</dc:creator><description>&lt;h2&gt;


&lt;!-- TEASER_END --&gt;
Brief
&lt;/h2&gt;

&lt;p&gt;These weeks I refactored the &lt;code&gt;LombScargleCrossspectrum&lt;/code&gt; and &lt;code&gt;LombScarglePowerspectrum&lt;/code&gt; classes to accommodate the fast algorithm which went smoothly.&lt;br&gt;
However when it comes to the fast algorithm. I had tunnel vision and unconsciously made the &lt;code&gt;lsft_fast&lt;/code&gt; function compute the power spectrum instead of the fourier transform. Right now I am working towards isolating the algorithm to compute the fourier transform using the Press and Rybicki optimizations(&lt;a href="https://ui.adsabs.harvard.edu/abs/1989ApJ...338..277P/abstract"&gt;https://ui.adsabs.harvard.edu/abs/1989ApJ...338..277P/abstract&lt;/a&gt;).&lt;/p&gt;
&lt;h2&gt;


Challenges Faced
&lt;/h2&gt;

&lt;p&gt;Integrating the optimization to the existing slow algorithm is giving me a bit of trouble. I'm still figuring out how to add the optimizations. If this is done, I can move onto making the time lag, phase lag functions and then onto testing and documentation.&lt;/p&gt;
&lt;h2&gt;


Details
&lt;/h2&gt;

&lt;p&gt;Added the following parameters to both the classes in order to accommodate choice between the fast and slow algorithm.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;method : str
The method to be used by the Lomb-Scargle Fourier Transformation function. `fast`
and `slow` are the allowed values. Default is `fast`. fast uses the optimized Press
and Rybicki O(n*log(n))

oversampling : float, optional, default: 5
Interpolation Oversampling Factor (for the fast algorithm)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;For full code refer &lt;a href="https://github.com/StingraySoftware/stingray/pull/737"&gt;https://github.com/StingraySoftware/stingray/pull/737&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Most important part of the process is the Lomb Scargle Fourier Transform.&lt;br&gt;
The wrapper class is trivial, they only wrap the fast and slow lomb scargle fourier transform functions.&lt;/p&gt;

&lt;h2&gt;


Results using the slow algorithm
&lt;/h2&gt;

&lt;h3&gt;


On synthetic data
&lt;/h3&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;rand = np.random.default_rng(42)
n = 100
t = np.sort(rand.random(n)) * n
y = np.cos(2 * np.pi * 5 * t) + 0.01 * rand.standard_normal(n)
y -= np.min(y)
lc1 = Lightcurve(t, y, err_dist="poisson")
y2 = np.cos(2 * np.pi * 5.0 * (t)) + 0.01 * rand.standard_normal(n)
y2 -= np.min(y2)
lc2 = Lightcurve(t, y2, err_dist="poisson")
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a class="article-body-image-wrapper" href="https://res.cloudinary.com/practicaldev/image/fetch/s--48Z7wHCy--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/xgf4z7yaxi81aoxj9dkx.png"&gt;&lt;img alt="Image description" height="827" src="https://res.cloudinary.com/practicaldev/image/fetch/s--48Z7wHCy--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/xgf4z7yaxi81aoxj9dkx.png" width="800"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;


On real data
&lt;/h3&gt;

&lt;h4&gt;


The lightcurve
&lt;/h4&gt;

&lt;p&gt;&lt;a href="https://heasarc.gsfc.nasa.gov/FTP/nicer/data/obs/2018_03//1200120106/xti/event_cl/ni1200120106_0mpu7_cl.evt.gz"&gt;https://heasarc.gsfc.nasa.gov/FTP/nicer/data/obs/2018_03//1200120106/xti/event_cl/ni1200120106_0mpu7_cl.evt.gz&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a class="article-body-image-wrapper" href="https://res.cloudinary.com/practicaldev/image/fetch/s--2qWoGIUP--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/w3dz8zsjk2ika71ytlkx.png"&gt;&lt;img alt="Image description" height="431" src="https://res.cloudinary.com/practicaldev/image/fetch/s--2qWoGIUP--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/w3dz8zsjk2ika71ytlkx.png" width="574"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a class="article-body-image-wrapper" href="https://res.cloudinary.com/practicaldev/image/fetch/s--F7NDO8dr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/167buf3woin2hplbo89r.png"&gt;&lt;img alt="Image description" height="417" src="https://res.cloudinary.com/practicaldev/image/fetch/s--F7NDO8dr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/167buf3woin2hplbo89r.png" width="559"&gt;&lt;/a&gt;&lt;/p&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2023/06/20230625_1615_pupperemeritus/</guid><pubDate>Sun, 25 Jun 2023 15:15:57 GMT</pubDate></item><item><title>Into the Summer of Code</title><link>http://openastronomy.org/Universe_OA/posts/2023/06/20230624_0133_exitflynn/</link><dc:creator>exitflynn</dc:creator><description>&lt;p&gt;I had my end-semester exams during the Community Bonding Period and the real-early part of the Coding Period. However, my mentors were super-accomodating.
I spent a few days on plans with friends before bidding goodbye for the summers, travelling home and relaxing a bit.&lt;/p&gt;
&lt;h3 id="the-talk"&gt;The Talk
&lt;!-- TEASER_END --&gt;
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#the-talk"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;This was also the time when IIT BHU reached out to me for a talk as part of a collab between their Astronomy and Open-Source clubs about Astronomy in tech and OSS. This was a  g r e a t  experience! I’ve always wanted to improve at public-speaking stuff and to finally pull off a satisfactory talk was a great experience. Also Prayash was a great host.&lt;/p&gt;
&lt;h3 id="beginning-with-the-project"&gt;Beginning with the Project
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#beginning-with-the-project"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;My mentor, Nabil, had asked me to start by writing tests for the scraper, even if they may not return a -ve)for all the URLs it doesn’t support now.
Looking closely though, all the issues were due to limitations of the way regex is implemented for inputting URLs, i.e. since one of the main goals of the project was to remove regex and use parse instead, these tests would have proven to be quite redundant. I asked my mentors and understandably so, Nabil said that he doesn’t want me working on code that I might have to remove soon enough and said I can proceed to the rest of the rewrite.&lt;/p&gt;
&lt;p&gt;After that, I began reading up on what Metaclasses, Abstract Base Classes (ABCs), etc are, their advantages and how they can be implemented in python to decide which would be better for the purpose of the project. However, at this point I wasn’t really maintaining good communication with my mentors. When they asked me for any updates and then inquired about why I had been reading up on ABCs and such, they clarified that I should be able to improve the scraper without going that route.&lt;/p&gt;
&lt;p&gt;Had to take a couple of days off in between for unavoidable reasons.&lt;/p&gt;
&lt;p&gt;After that I took some calls with my mentors, clarifying details and trying to work things through together as I figured out what I should do next.
All the scraper // dataretriever clients require two strings, &lt;code&gt;baseurl&lt;/code&gt; and &lt;code&gt;pattern&lt;/code&gt; and I figure out a way to merge them somehow.
I looked into just what role the two of them had and found that &lt;code&gt;pattern&lt;/code&gt; was used only to parse data.
For example, When writing scraper clients, we require a baseurl and a pattern, an example from the NOAA Client:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0"&gt;&lt;code class="language-python"&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;baseurl &lt;span style="color: #f92672;"&gt;=&lt;/span&gt; &lt;span style="color: #e6db74;"&gt;r&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;'ftp://ftp.ngdc.noaa.gov/STP/swpc_products/daily_reports/solar_region_summaries/%Y/%m/%Y%m&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;%d&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;SRS.txt'&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;pattern &lt;span style="color: #f92672;"&gt;=&lt;/span&gt; &lt;span style="color: #e6db74;"&gt;'&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;{}&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;/&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;{year:4d}&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;/&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;{month:2d}&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;/&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;{year:4d}{month:2d}{day:2d}&lt;/span&gt;&lt;span style="color: #e6db74;"&gt;SRS.txt'&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Instead of passing both, we should be able to merge them into just one since the pattern string is conveying information that is already available in the baseurl.&lt;/p&gt;
&lt;p&gt;I figured it should be possible to transform &lt;code&gt;baseurl&lt;/code&gt; to &lt;code&gt;pattern&lt;/code&gt; and generate &lt;code&gt;pattern&lt;/code&gt; that way but halfway through I realised that it’d not be possible. However we should be able to convert a full &lt;code&gt;pattern&lt;/code&gt; to it’s &lt;code&gt;baseurl&lt;/code&gt; formatted counterpart.&lt;/p&gt;
&lt;p&gt;I remember writing out loud what I thought as I approached that problem:&lt;/p&gt;
&lt;h3 id="rubber-ducky-microblogging"&gt;rubber ducky microblogging?
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#rubber-ducky-microblogging"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;now how do we include this transformation in our code?
we have mainly two places / files of concern.
&lt;code&gt;dataretriever/client.py&lt;/code&gt; and &lt;code&gt;scraper.py&lt;/code&gt;
at this point there are a couple of ways to go about it that come to my mind, all of them would however can be categorised as:
a) include the transformation in dr/client.py
b) include it in scraper.py&lt;/p&gt;
&lt;p&gt;before i get ahead of myself, it’s better to arrive at a concrete decision here, if that’s possible, to avoid having too much of overhead.&lt;/p&gt;
&lt;p&gt;case a:
pattern transforms in client and is then sent to scraper. this means the scraper still operates on strftime baseurl.
and when we want to call the parse function, instead of sending pattern as we do now, we can just send the original new format&lt;/p&gt;
&lt;p&gt;case b:
pass the new format to scraper. scraper converts it into strftime to use in all of its functions, and&lt;/p&gt;
&lt;p&gt;the second approach makes more sense, yeah.&lt;/p&gt;
&lt;p&gt;NOW
what’d be a nice way to incorporate this transform in the scraper file?&lt;/p&gt;
&lt;p&gt;So there have to be Two strings/patterns, throughout this codebase.
the strftime kind and the parse kind.
what we input is the parse kind (since we can convert this to strftime, and the other way around wasn’t possible)&lt;/p&gt;
&lt;p&gt;how to incorporate both strings? make them both private members of the Scraper class?&lt;/p&gt;
&lt;p&gt;some functions will be changed as a result of this&lt;/p&gt;
&lt;p&gt;like _URL_followsPattern&lt;/p&gt;
&lt;p&gt;okay so the plan of action is:
go add a transform function, call it in init
we’ll have a variable for the time_pattern, update pattern -&amp;gt; time_pattern wherever applicable.
rewrite using parse wherever applicable&lt;/p&gt;
&lt;p&gt;but this would take away from having a standard system and we’ll be defining our own set of names to name variables as.&lt;/p&gt;
&lt;p&gt;also a future plan can be to check for redundant functions / moving code.&lt;/p&gt;
&lt;h3 id="in-conclusion"&gt;in conclusion
&lt;span&gt;
&lt;a href="https://exitflynn.github.io/blog/tags/gsoc/index.xml#in-conclusion"&gt;
&lt;svg height="100%" viewbox="0 0 28 23" width="19" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"&gt;&lt;/path&gt;&lt;/path&gt;&lt;/svg&gt;
&lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;So as of right now, I’ve been working on &lt;a href="https://github.com/sunpy/sunpy/issues/7073"&gt;#7073&lt;/a&gt; and &lt;a href="https://github.com/sunpy/sunpy/pull/7077"&gt;PR #7077&lt;/a&gt;, more details on this issue and my proposed solution can be found in the issue description.&lt;/p&gt;
&lt;p&gt;This’ll be all for now, will be posting more in the future.&lt;/p&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2023/06/20230624_0133_exitflynn/</guid><pubDate>Sat, 24 Jun 2023 00:33:30 GMT</pubDate></item><item><title>Comparing memory performance of Vaex and Pandas</title><link>http://openastronomy.org/Universe_OA/posts/2023/06/20230624_0000_1someshverma/</link><dc:creator>Somesh Verma</dc:creator><description>&lt;p&gt;After completing all the changes to compute Spectrum using Vaex , I compared the memory used during the execution of the program . I used tracemalloc to compute memory uses to compute Spectrum .&lt;/p&gt;

&lt;h4 id="computing-the-spectrum"&gt;Computing the spectrum&lt;/h4&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Following code is used , and memory maximum memory used during the execution of this code is recorded for Vaex and Pandas&lt;/p&gt;

&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;
from radis import calc_spectrum
import tracemalloc
tracemalloc.start()

s, factory_s = calc_spectrum(1800, 2500,         # cm-1
molecule='H2O',
isotope='1,2,3',
pressure=1.01325,   # bar
Tgas=700,           # K
mole_fraction=0.1,
path_length=1,      # cm
databank='hitemp',  # or 'hitemp', 'geisa', 'exomol'
wstep='auto',
use_cached=False,
engine='pandas',
return_factory=True,
)

s.apply_slit(0.5, 'nm')       # simulate an experimental slit
s.plot('radiance')

print(tracemalloc.get_traced_memory())
tracemalloc.stop()

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id="results"&gt;Results&lt;/h4&gt;

&lt;p&gt;It can be seen from the graph below that Vaex takes very less memory space in comparison to Pandas.&lt;/p&gt;

&lt;p&gt;&lt;img alt="Vaex Comparison" src="https://1someshverma.github.io/images/vaexcomparison.png"&gt;&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2023/06/20230624_0000_1someshverma/</guid><pubDate>Fri, 23 Jun 2023 23:00:00 GMT</pubDate></item></channel></rss>