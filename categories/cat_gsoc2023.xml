<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts about gsoc2023)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/categories/cat_gsoc2023.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sat, 24 Jun 2023 01:18:21 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Creating a new Data Structure for pyGnuastro</title><link>http://openastronomy.org/Universe_OA/posts/2023/06/20230620_0000_labeeb-7z/</link><dc:creator>Labib Asari</dc:creator><description>&lt;h3 id="background"&gt;Background&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://www.gnu.org/savannah-checkouts/gnu/gnuastro/gnuastro.html"&gt;GnuAstro&lt;/a&gt; is a powerful and comprehensive library designed to handle various data formats(FITS/TIFF/TXT and more) and perform a wide range of operations, all while maintaining consistency across its entire codebase.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;This is done by representing all the data (acquired via input or created internally), regardless of its type, in a single data structure which encompasses the core data as well as metadata. This greatly assists in mainting uniformity.
Internally all the data is represented in the form of a C struct : &lt;code class="language-plaintext highlighter-rouge"&gt;gal_data_t&lt;/code&gt;
The following image describes how it keeps the core data as well as metadata :
&lt;img alt="Code-Block1" src="https://labeeb-7z.github.io/Blogs/img/posts/creating-data-structure/gal_data_t.png"&gt;&lt;/p&gt;

&lt;p&gt;Explaining each attribute of this structure will require a seperate post of itself :). Instead I’ll focus on the main topic here : Since Im creating a python package for Gnuastro, and the &lt;code class="language-plaintext highlighter-rouge"&gt;gal_data_t&lt;/code&gt; is at the heart of this library, How do I represent this complex type in Python?!&lt;/p&gt;

&lt;p&gt;Normally we use Classes to define new and complex data types in Python, but hey.. I’m wrapping a C library in Python using the Python-C API. This means I write my wrappers in C!&lt;/p&gt;

&lt;p&gt;So the question comes down to how do I create a new type in Python using C language?&lt;/p&gt;

&lt;h3 id="creating-new-data-types-in-python-without-classes-and-objects"&gt;Creating New Data Types in Python Without Classes and Objects&lt;/h3&gt;

&lt;p&gt;Before I continue, I’ve to appreciate &lt;a href="https://numpy.org/"&gt;Numpy&lt;/a&gt; for the incredible peice of software it is, the more I understand it, the more it amazes me.&lt;/p&gt;

&lt;p&gt;C is not an Object Oriented Programming Language, but Python is.&lt;/p&gt;

&lt;p&gt;In case you didn’t know the most common implementation of Python (the one you most probably have) is written in C! It’s called CPython.&lt;/p&gt;

&lt;p&gt;This raises an obvious question, how does Python implement its whole OOP paradigm in C?&lt;/p&gt;

&lt;p&gt;This question also answers our question of how to represent &lt;code class="language-plaintext highlighter-rouge"&gt;gal_data_t&lt;/code&gt; in Python, because essentially they’re looking for the same thing.&lt;/p&gt;

&lt;p&gt;&lt;code class="language-plaintext highlighter-rouge"&gt;PyObject&lt;/code&gt; is the answer! To the Python interpreter(written in C) all the data types(built in as well as user defined) are of this type!&lt;/p&gt;

&lt;p&gt;and what is this &lt;code class="language-plaintext highlighter-rouge"&gt;PyObject&lt;/code&gt;? Its a simple struct in C.&lt;/p&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2023/06/20230620_0000_labeeb-7z/</guid><pubDate>Mon, 19 Jun 2023 23:00:00 GMT</pubDate></item><item><title>Implementation of the Kurucz database to Radis</title><link>http://openastronomy.org/Universe_OA/posts/2023/06/20230617_2033_menasrac/</link><dc:creator>Racim MENASRIA</dc:creator><description>&lt;p&gt;As planed in my last article, I started my project by adding a first database to Radis : Kurucz.&lt;/p&gt;
&lt;p&gt;I based my work on a existing class developed in Exojax. I reviewed the associated methods that allowed to download the data from the database, store it in numpy arrays and extract the key information from it for further calculation.&lt;/p&gt;
&lt;p&gt;By running a few examples on Exojax, I got familiar with the structure and nature of the data and key functions.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;However, I noticed a problem in the install command of Radis’s sister code Exojax while running theses examples. After further investigation with my mentors and the Exojax team, it appeared to be a jax problem so we couldn’t fix it for the moment.&lt;br&gt;Since I could only make them work on a wsl environment, I couldn’t afford to import jax libraries used in the AdbKurucz database implemented to Exojax. This is the reason why I had to adapt the structure of the data and methods and stick to Pandas dataframes and numpy arrays.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;First try : using a DatabaseManager structure&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;As a explained it in the previous article, Radis has developed a special Class the handle the database processes. Since Kurucz is an atomic Database, I tried to implement it by making it inherit from the DatabaseManager class and setting the molecule parameter to “None”. Unfortunately, it led to many exceptions in the methods that I gave up on this idea.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;Second try : using Exojax methods without jax imports&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;This approach provided very nice results because the major part of the methods were already efficient. &lt;br&gt;Nevertheless I had some errors because of the data wasn’t loaded properly or syntax errors had broken a few parts of the code.&lt;/p&gt;
&lt;p&gt;I finally managed to load, store and use the data from Kurucz.&lt;/p&gt;
&lt;p&gt;Then I added an example to show how this new database can be used.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*oJXYNuWaqdZFCpuhYTNSjw.png"&gt;&lt;/figure&gt;&lt;p&gt;This is the first spectrum that I obtained from the Kurucz database for Fe.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;A bit more explanations:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The population of the lower energy level of a given transition is the number of atoms that are in that energy state at any given time. So if you have a large population in a certain energy state, you have a lot of atoms that are able to make the transition and therefore emit a photon. Einstein’s coefficient A for a particular transition is a measure of the probability of that transition occurring. So if A is large, then each atom has a high chance of making the transition and emitting a photon. Thus, the intensity of the spectral line (i.e. the number of photons emitted per unit time) is proportional to both the population of the lower energy level (the number of atoms capable of making the transition) and to A (the probability that each atom actually makes the transition). So the intensity can be approximately represented as A * population.&lt;/p&gt;
&lt;p&gt;The users can chose the temperature and the function then interpolates the values from the database and plots the spectrum.&lt;/p&gt;
&lt;p&gt;In order to generalize this to all the atoms and ions of the database, I had to adjust the function load_pf_Barklem2016() from Exojax and fix an error in the way the partition functions were extracted.&lt;/p&gt;
&lt;p&gt;Now I can load the data and use it properly. For Kurucz’s data, each file corresponds to a single species of atom only. For example, “gf2600.all” is dedicated to absorption lines of “neutral iron atoms”. The “26” is the atomic number of iron, followed by a “00” indicating zero ionization (=neutral; Fe I). For example, if you want to use spectral lines of singly-ionized sodium (Na II or Na+), you should download “gf1101.all”.&lt;/p&gt;
&lt;p&gt;Here is another example for Ca.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*q_748Zt_K4rqW5fWtFAdTQ.png"&gt;&lt;/figure&gt;&lt;h4&gt;&lt;strong&gt;What is next ?&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;I will end up this week by adding a few tests to ensure my code doesn’t break any part of the Radis architecture and may go for a PR in the next days.&lt;/p&gt;
&lt;p&gt;Then the next step for Week 4 will be to implement the TheoReTS database to Radis .&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=27c2724fde74" width="1"&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2023/06/20230617_2033_menasrac/</guid><pubDate>Sat, 17 Jun 2023 19:33:30 GMT</pubDate></item><item><title>GSoC - Week 1-2</title><link>http://openastronomy.org/Universe_OA/posts/2023/06/20230614_0000_gaurav17joshi/</link><dc:creator>Gaurav Joshi</dc:creator><description>&lt;h3 id="my-adventure-with-the-implementation"&gt;My adventure with the implementation&lt;/h3&gt;
&lt;p&gt;While taking on this project, the thing I was most excited was that I would be getting to write rearch code (Code to be used by researchers in their work all over). With advent of large data from multiple telescopes and computational speed , Gaussian Processes are fast becoming the go to choice for astrophichal modelling.&lt;/p&gt;

&lt;!-- TEASER_END --&gt;
&lt;p&gt;In the original Source paper, the authors had simulated 1000 lightcurves of varying intesity of QPO, and measured their evidence for QPO and RN priors to check how well this technique works, and ensure that it does not give any false positives.&lt;/p&gt;

&lt;p&gt;Hense, I set forth on my mission to calculate evidence of 1000 lightcurve on GPs with my new and beloved Macbook. Having full confidence that my computation machine is as good as they come, I set out to perform inference on my 1000 lightcurve, only for my pc to take 1 hour to without sampling a single lightcurve.&lt;/p&gt;

&lt;p&gt;On reducing the number of points from 256 to 64, the code took 4 min to complete. Considering O(N3) time complexity, it would have taken &lt;strong&gt;4 hours&lt;/strong&gt; to complete the simulation for 1 curve :scream:.&lt;/p&gt;

&lt;p&gt;Here I had made my own implementation of the kernel using tinygp. At this point my mentor advice me to use &lt;code class="language-plaintext highlighter-rouge"&gt;tinygp.quasisep.celerite&lt;/code&gt; kernels, a special kernel, implemented based on the celerite algorithm. On changing to the new kernel, the code took just &lt;strong&gt;1 min&lt;/strong&gt; to run.
This made me realise how important such specialized code was, and how important making such faster and more effective code is.&lt;/p&gt;

&lt;h3 id="the-implementation"&gt;The implementation&lt;/h3&gt;
&lt;p&gt;In the first two weeks I focussed on understanding the implementation of the project. In the source repository Celerite library was used for GP implimentation and Bilby was used for Bayesian Inferencing, while in my project my mentor and I decided to completely use a Jax based backend hense, Tinygp for GP, and Jaxns for Nested Sampling.&lt;/p&gt;

&lt;p&gt;I made a proof of Concept implimentation for the QPO kernel and gaussian mean model for a lightcurve, which is explained in breif here:-&lt;/p&gt;

&lt;h4 id="kernel"&gt;Kernel:&lt;/h4&gt;
&lt;p&gt;For making the Kernel, I used Tingp.quasisep.celerite kernels which are a fast implementation (based on the celerite kernel) of the Qpo kernel.&lt;/p&gt;

&lt;p&gt;The &lt;code class="language-plaintext highlighter-rouge"&gt;quasisep.exp&lt;/code&gt; kernel for the red noise part and the &lt;code class="language-plaintext highlighter-rouge"&gt;quasisep.celerite&lt;/code&gt; kernel for the qpo part can be implemented as:&lt;/p&gt;
&lt;div class="language-python highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="n"&gt;hqpokernel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kernels&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;quasisep&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="n"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;hqpoparams&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;"crn"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hqpoparams&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;"arn"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;kernels&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;quasisep&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Celerite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hqpoparams&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;"aqpo"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hqpoparams&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;"cqpo"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;jnp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;hqpoparams&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;"freq"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="Plot of High, low and non QPO kernel" src="https://gaurav17joshi.github.io/Blogs/img/assets/kernel1.png"&gt;&lt;/p&gt;

&lt;h4 id="mean"&gt;Mean:&lt;/h4&gt;
&lt;p&gt;We are working on Extremely powerful events in the universe which emit radiation in the Xray spectra. Many of these have some sort of flaring behaviour, and also in general, we wanted to add mean functions to our GPs as this feature will be extended to other astronomical time series.&lt;/p&gt;

&lt;p&gt;For this proof of concept implimentation, I used a simple gaussian mean to test out sampling using Jaxns
Using the tinygp library to make the gaussian process and sample out some lightcurves from it.&lt;/p&gt;

&lt;div class="language-python highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mean_params&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mean_params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;"A"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;jnp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;mean_params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;"t0"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean_params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;"sig"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="n"&gt;mean_params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="s"&gt;"A"&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="s"&gt;"t0"&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="s"&gt;"sig"&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,}&lt;/span&gt;

&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;functools&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mean_params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mean_params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Making the Gp
&lt;/span&gt;&lt;span class="n"&gt;gp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tinygp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GaussianProcess&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;diag&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;diag&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;gp_sample&lt;/span&gt;   &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;gp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;jax&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PRNGKey&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="Plot of samples" src="https://gaurav17joshi.github.io/Blogs/img/assets/samples1.png"&gt;&lt;/p&gt;

&lt;h4 id="priors-and-likelihoods"&gt;Priors and likelihoods&lt;/h4&gt;
&lt;p&gt;As we want to fit our Red noise and Qpo + Red noise model on the lightcurve, we need to make suitable prior funcitons for them. We use Jaxns.Prior to make a generator prior function, and make a corresponding likelihood function, which makes the gp and calculates the log likehood of producing the given lightcurve.&lt;/p&gt;

&lt;p&gt;We set the bounds for the prior functions based on the suggestions given in the source paper, and plot the fitted maximum posterior gp on the lightcurve.&lt;/p&gt;

&lt;div class="language-python highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="c1"&gt;# Prior Model Function
&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;RNprior_model&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Times&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Times&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;    &lt;span class="c1"&gt;# Total time
&lt;/span&gt;    &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Times&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Times&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="c1"&gt;# Sampling frequency
&lt;/span&gt;    &lt;span class="nb"&gt;min&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;jnp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lightcurve&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;jnp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lightcurve&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;

&lt;span class="c1"&gt;# Red noise kernel prior
&lt;/span&gt;    &lt;span class="n"&gt;arn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;Prior&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfpd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;'arn'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;crn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;Prior&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfpd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jnp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;jnp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;'crn'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Gaussian mean priors
&lt;/span&gt;    &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;Prior&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfpd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;'A'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;t0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;ForcedIdentifiability&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;low&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Times&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;high&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Times&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;'t0'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;Prior&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfpd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;'sig'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;arn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;crn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sig&lt;/span&gt;

&lt;span class="c1"&gt;# Log Likelihood Function
&lt;/span&gt;&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="n"&gt;jit&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;RNlog_likelihood2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;crn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sig&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="n"&gt;rnlikelihood_params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;"arn"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;arn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"crn"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;crn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="s"&gt;"aqpo"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"cqpo"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"freq"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;mean_params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="s"&gt;"A"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"t0"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;t0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"sig"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;gp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;build_gp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rnlikelihood_params&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mean_params&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Times&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"RN"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;gp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_probability&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lightcurve&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Nested Sampling using Jaxns
&lt;/span&gt;&lt;span class="n"&gt;RNmodel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prior_model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RNprior_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;log_likelihood&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;RNlog_likelihood2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;RNexact_ns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ExactNestedSampler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;RNmodel&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_live_points&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;RNtermination_reason&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;RNstate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RNexact_ns&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PRNGKey&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;term_cond&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;TerminationCondition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;live_evidence_frac&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;RNresults&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RNexact_ns&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_results&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;RNstate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;RNtermination_reason&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img alt="Plot of samples" src="https://gaurav17joshi.github.io/Blogs/img/assets/rnplot.png"&gt;&lt;/p&gt;

&lt;p&gt;But the main use is not just to fit a GP, but rather to acess whether it contains a QPO or not. For that, we compare the evidence (Bayes Factor) of the lightcurve for a QPO_RN Gp and RN GP, and as expected, for a high QPO sample, we get a high value of (-212 - (-262)) = 50.&lt;/p&gt;

&lt;p&gt;The image in the top is of the QPO model sampling.&lt;/p&gt;

&lt;p&gt;The corner plot shows the result of the sampling, and the frequency of 20Hz is captured well in it.&lt;/p&gt;

&lt;p&gt;&lt;img alt="Plot of samples" src="https://gaurav17joshi.github.io/Blogs/img/assets/qpocornerplot.png"&gt;&lt;/p&gt;

&lt;h3 id="tensor-flow-probability"&gt;Tensor flow probability&lt;/h3&gt;
&lt;p&gt;TensorFlow Probability (TFP) is a Python library built on TensorFlow that makes it easy to combine probabilistic models and deep learning on modern hardware (TPU, GPU).&lt;/p&gt;

&lt;p&gt;For this project, the jax backend requires that we also use tfpd to make our priors, and as I had to use some joint priors I explored the library.&lt;/p&gt;

&lt;p&gt;The joint priors could not be integrated with jaxns sampling, as multi-parameter priors lacked quantiles, but it was time well spent, as I was able to see a powerful library which had almost all kinds of priors and inferencing techniques under the sky, while supporting its own implementaions of NUTS and MCMC sampling.&lt;/p&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2023/06/20230614_0000_gaurav17joshi/</guid><pubDate>Tue, 13 Jun 2023 23:00:00 GMT</pubDate></item><item><title>GSoC Week 1 Progress Update</title><link>http://openastronomy.org/Universe_OA/posts/2023/06/20230608_0729_pupperemeritus/</link><dc:creator>pupper emeritus</dc:creator><description>&lt;h2&gt;


&lt;!-- TEASER_END --&gt;
Brief
&lt;/h2&gt;

&lt;p&gt;Week 1 has been quite eventful with me creating a Lomb Scargle Fourier Transform function and get a working class for Lomb Scargle Cross Spectrum and Power Spectrum.&lt;/p&gt;

&lt;p&gt;I inherited my LS cross spectrum from the regular cross spectrum class. Had to rewrite the &lt;code&gt;constructor&lt;/code&gt;, &lt;code&gt;initial_checks&lt;/code&gt; , &lt;code&gt;make_crossspectrum&lt;/code&gt;, &lt;code&gt;_make_auxil_pds&lt;/code&gt; and &lt;code&gt;_initialize_empty&lt;/code&gt;. And also wrote a new &lt;code&gt;_ls_cross&lt;/code&gt; method which just returns the frequencies and cross spectra for given light curves and it is an internal function only to be used by the class.&lt;/p&gt;

&lt;p&gt;The original slow implementation has been completed. I am still working on the fast version.&lt;/p&gt;

&lt;p&gt;As this is not a project that can be completed in a bunch of small PRs, I will push to a single PR which will be merged after completion of the project. The following draft PR is the one to which I will be pushing to. &lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/StingraySoftware/stingray/pull/737/"&gt;https://github.com/StingraySoftware/stingray/pull/737/&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;


Details
&lt;/h2&gt;

&lt;p&gt;The following are the APIs for the classes&lt;/p&gt;

&lt;h3&gt;


Cross Spectrum
&lt;/h3&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;Make a cross spectrum from an unevenly sampled light curve.
You can also make an empty :class:`Crossspectrum` object to populate with your
own Fourier-transformed data (this can sometimes be useful when making
binned power spectra).

Parameters
----------
data1: :class:`stingray.Lightcurve` or :class:`stingray.events.EventList`, optional, default ``None``
The dataset for the first channel/band of interest.

data2: :class:`stingray.Lightcurve` or :class:`stingray.events.EventList`, optional, default ``None``
The dataset for the second, or "reference", band.

norm: {``frac``, ``abs``, ``leahy``, ``none``}, default ``none``
The normalization of the (real part of the) cross spectrum.

power_type: string, optional, default ``real``
Parameter to choose among complete, real part and magnitude of the cross spectrum.

fullspec: boolean, optional, default ``False``
If False, keep only the positive frequencies, or if True, keep all of them .

Other Parameters
----------------
dt: float
The time resolution of the light curve. Only needed when constructing
light curves in the case where ``data1``, ``data2`` are
:class:`EventList` objects

skip_checks: bool
Skip initial checks, for speed or other reasons (you need to trust your
inputs!)

min_freq : float
Minimum frequency to take the Lomb-Scargle Fourier Transform

max_freq: float
Maximum frequency to take the Lomb-Scargle Fourier Transform

df : float
The time resolution of the light curve. Only needed where ``data1``, ``data2`` are

method : str
The method to be used by the Lomb-Scargle Fourier Transformation function. `fast`
and `slow` are the alloowed values. Default is `fast`. fast uses the optimized Press
and Rybicki O(n*log(n))

Attributes
----------
freq: numpy.ndarray
The array of mid-bin frequencies that the Fourier transform samples

power: numpy.ndarray
The array of cross spectra (complex numbers)

power_err: numpy.ndarray
The uncertainties of ``power``.
An approximation for each bin given by ``power_err= power/sqrt(m)``.
Where ``m`` is the number of power averaged in each bin (by frequency
binning, or averaging more than one spectra). Note that for a single
realization (``m=1``) the error is equal to the power.

df: float
The frequency resolution

m: int
The number of averaged cross-spectra amplitudes in each bin.

n: int
The number of data points/time bins in one segment of the light
curves.

k: array of int
The rebinning scheme if the object has been rebinned otherwise is set to 1.

nphots1: float
The total number of photons in light curve 1

nphots2: float
The total number of photons in light curve 2
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h3&gt;


Power Spectrum
&lt;/h3&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;Make a :class:`LombScarglePowerspectrum` (also called periodogram) from a unevenly sampled (binned)
light curve. Periodograms can be normalized by either Leahy normalization,
fractional rms normalization, absolute rms normalization, or not at all.

You can also make an empty :class:`LombScarglePowerspectrum` object to populate with
your own fourier-transformed data (this can sometimes be useful when making
binned power spectra).

Parameters
----------
data: :class:`stingray.lightcurve.Lightcurve` or :class:`stingray.events.EventList` object, optional, default ``None``
The light curve data to be Fourier-transformed.

norm: {"leahy" | "frac" | "abs" | "none" }, optional, default "frac"
The normaliation of the power spectrum to be used. Options are
"leahy", "frac", "abs" and "none", default is "frac".

Other Parameters
----------------
dt: float
The time resolution of the light curve. Only needed when constructing
light curves in the case where ``data`` is a
:class:`EventList` object

skip_checks: bool
Skip initial checks, for speed or other reasons (you need to trust your
inputs!).

min_freq : float
Minimum frequency to take the Lomb-Scargle Fourier Transform

max_freq: float
Maximum frequency to take the Lomb-Scargle Fourier Transform

df : float
The time resolution of the light curve. Only needed where ``data`` is a :class`stingray.Eventlist` object

method : str
The method to be used by the Lomb-Scargle Fourier Transformation function. `fast`
and `slow` are the alloowed values. Default is `fast`. fast uses the optimized Press
and Rybicki O(n*log(n))

Attributes
----------
norm: {"leahy" | "frac" | "abs" | "none" }
The normalization of the power spectrum.

freq: numpy.ndarray
The array of mid-bin frequencies that the Fourier transform samples.

power: numpy.ndarray
The array of normalized squared absolute values of Fourier
amplitudes.

power_err: numpy.ndarray
The uncertainties of ``power``.
An approximation for each bin given by ``power_err= power/sqrt(m)``.
Where ``m`` is the number of power averaged in each bin (by frequency
binning, or averaging power spectra of segments of a light curve).
Note that for a single realization (``m=1``) the error is equal to the
power.

df: float
The frequency resolution.

m: int
The number of averaged powers in each bin.

n: int
The number of data points in the light curve.

nphots: float
The total number of photons in the light curve.
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2023/06/20230608_0729_pupperemeritus/</guid><pubDate>Thu, 08 Jun 2023 06:29:01 GMT</pubDate></item><item><title>GSoC - its finally here</title><link>http://openastronomy.org/Universe_OA/posts/2023/06/20230605_0000_labeeb-7z/</link><dc:creator>Labib Asari</dc:creator><description>&lt;h3 id="what-is-open-source-and-gsoc"&gt;What is Open-Source and Gsoc?&lt;/h3&gt;
&lt;p&gt;Open source software is software with source code that anyone can inspect, modify, and enhance. There are many institutions and individuals who write open software, mainly for research or free deployment purposes. Mostly these softwares, have only a few maintainers, and multiple people, writing and debugging the code, helps a lot. This is where Google Summer of Code &lt;code class="language-plaintext highlighter-rouge"&gt;GSOC&lt;/code&gt; comes into the picture. It is a global, online program focused on bringing new contributors into open source software development. Many organisations float projects for the developers to take over the summer and Google mediates in the process, while also paying the contributors for their work over the summer.&lt;/p&gt;

&lt;!-- TEASER_END --&gt;
&lt;h3 id="what-is-my-project-about"&gt;What is my project about?&lt;/h3&gt;

&lt;p&gt;It has 2 main components :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a Python Library for Gnuastro
&lt;ul&gt;
&lt;li&gt;Design an error handling mechanism for Gnuastro&lt;/li&gt;
&lt;li&gt;Design corresponding data structures of Gnuastro in Python&lt;/li&gt;
&lt;li&gt;Write wrapper functions to be used in python&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Add CUDA support in Gnuastro
&lt;ul&gt;
&lt;li&gt;Integrate CUDA with Gnuastro’s build system&lt;/li&gt;
&lt;li&gt;Write GPU kernels for compute heavy and parallelizable operations.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="what-have-i-completed-till-now"&gt;What have I completed till now?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;On the Python Library Part :
&lt;ul&gt;
&lt;li&gt;Gnuastro now has an error handling mechanism!&lt;/li&gt;
&lt;li&gt;Added error handling in Python package for the 2 existing modules.&lt;/li&gt;
&lt;li&gt;Defined error types for each corresponding error type in C library.&lt;/li&gt;
&lt;li&gt;Implemented Python wrappers for 2 of the C library modules&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;On the CUDA support part :
&lt;ul&gt;
&lt;li&gt;Gnuastro can now build with cuda! this means it already supports GPU computations.&lt;/li&gt;
&lt;li&gt;Added docs for installing, configuring, and testing CUDA&lt;/li&gt;
&lt;li&gt;Added test CUDA kernels and demo programs to test them.&lt;/li&gt;
&lt;li&gt;Implementing CUDA kernel for Convolution operation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;##&lt;/p&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2023/06/20230605_0000_labeeb-7z/</guid><pubDate>Sun, 04 Jun 2023 23:00:00 GMT</pubDate></item><item><title>GSOC Week 1 : A global overview of the RADIS API.</title><link>http://openastronomy.org/Universe_OA/posts/2023/06/20230604_2227_menasrac/</link><dc:creator>Racim MENASRIA</dc:creator><description>&lt;h4&gt;GSOC Week 1 : A global overview of the RADIS API.&lt;/h4&gt;&lt;p&gt;Since the point of my project is to implement new databases in the RADIS API and to reform it in other to make it common and stand alone, it seems important to understand how this API works.&lt;/p&gt;
&lt;p&gt;Thus, I have started my 12 weeks projects by reading carefully the API documentation available at &lt;a href="https://radis.readthedocs.io/en/latest/source/radis.io.dbmanager.html"&gt;https://radis.readthedocs.io/en/latest/source/radis.io.dbmanager.html&lt;/a&gt;. I will detail in this article what I consider the key points to understand how Radis works globally and aim to answer the following question : Whats are the steps to proceed in order to include a new database as Kurucz to RADIS ?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This page is a description of the different modules available in the RADIS library except the api one which will be discussed later.&lt;/strong&gt;&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1017/1*UPlH0eBh97WoVpiEn_C7rQ.png"&gt;&lt;/figure&gt;&lt;p&gt;In particular, the radis.io package provided functionality for file management, downloading and analysis of different spectroscopic databases.&lt;/p&gt;
&lt;p&gt;To understand in detail how the RADIS API works and integrate a new database like Kurucz, here are the most important radis.io package sub-modules to explore :&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;dbmanager&lt;/strong&gt; : This submodule used to contain the DatabaseManager class, which is the heart of database management in RADIS before it was moved to the api module. Understanding how this class is used to save, download, manipulate and interact with existing databases is essential. I will also need to understand how to add a new database by implementing the appropriate methods.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;geisa, hitran or exomol : &lt;/strong&gt;I have to study how GEISA, HITRAN or Exomol files are downloaded, saved and processed. Understanding how this databases are integrated will give me an idea of the structure and workflow needed to integrate a new database.&lt;/p&gt;
&lt;h4&gt;The DatabaseManager class&lt;/h4&gt;&lt;p&gt;The DatabaseManager class aims to handle and manage files from various databases. It provides a generic framework for managing and caching files from different sources or databases.&lt;/p&gt;
&lt;pre&gt;class DatabaseManager(object):&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;add_column(df, key, value)&lt;/strong&gt;: This method allows to create a column with a key and a value specified in a DataFrame or a dictionary.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;check_deprecated_files(local_files, auto_remove=True)&lt;/strong&gt;: This method checks file metadata and removes deprecated ones. If auto_remove is set to True, deprecated files will be automatically removed. Otherwise, an error will be thrown.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;clean_download_files()&lt;/strong&gt;: This method cleans downloaded and unzipped files.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;download_and_parse(urlnames, local_files)&lt;/strong&gt;: This method downloads and parses files from the specified URLs and saves them locally.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;fetch_filenames()&lt;/strong&gt;: This method fetches the names of all files from the database, even if they haven’t been downloaded yet.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;fetch_urlnames()&lt;/strong&gt;: This method must be overridden in the DatabaseManager subclass. It should return a list of URLs corresponding to database files.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;get_columns(local_file)&lt;/strong&gt;: This method retrieves all the columns available in a database file using the get_columns function of the DataFileManager class.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;load(local_files, columns=None, lower_bound=[], upper_bound=[], within=[], output=’pandas’):&lt;/strong&gt; This method loads data from database files. You can specify which columns to load, lower and upper bounds for values in certain columns, and constraints for certain columns. You can also specify the output format, such as ‘pandas’, ‘vaex’ or ‘jax’.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;plot(local_files, isotope, wavenum_min, wavenum_max):&lt;/strong&gt; This method is a convenience function for plotting the linestrengths of the database.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;register(dict_entries):&lt;/strong&gt; This method registers dictionary entries for a specified database.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;remove_local_files(local_files)&lt;/strong&gt;: This method removes the specified local files.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;rename_columns(df, rename_dict):&lt;/strong&gt; This method renames the columns of a DataFrame using a dictionary of correspondence between the old column names and the new names.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;register_database(databank_name, dict_entries, verbose): &lt;/strong&gt;This method adds registered databases to the RADIS configuration file.&lt;/p&gt;
&lt;h4&gt;The radis.io.geisa module review : to get some ideas ?&lt;/h4&gt;&lt;p&gt;The GEISADatabaseManager class is a subclass of DatabaseManager which is specifically designed to manage GEISA databases. It adds specific functionalities to the management of GEISA files and their integration into the RADIS API. It gives us an insight of what the implemenation of other databases as Kurucz should look like. However, every database has its own specificities that is why the methods may differ on some aspects though they are built on a same basis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;fetch_urlnames(): &lt;/strong&gt;This method must be implemented to return a list of URLs corresponding to GEISA files in your database. These URLs will be used to download files from the GEISA website.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;parse_to_local_file():&lt;/strong&gt; This method is used to unpack GEISA files and save them locally. It also adds metadata to files.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;register():&lt;/strong&gt; This method registers the GEISA database in the RADIS configuration file. It ensures that the RADIS API recognizes and can access the database.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;fetch_geisa():&lt;/strong&gt; This GEISA specific method fetches GEISA files from the GEISA website, unpacks them and creates an HDF5 file containing all row data. It returns a Pandas DataFrame containing all rows.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;columns_GEISA:&lt;/strong&gt; It is a dictionary that defines the parsing order of columns in the GEISA2020 format. It specifies column names, data types, descriptions, and units.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;engine:&lt;/strong&gt; This is an optional parameter that allows to specify the memory mapping library to use for the GEISA database. By default, it uses the ‘default’ value specified in the RADIS configuration file.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;verbose, chunksize, parallel:&lt;/strong&gt; These are optional parameters to control the verbosity level of informational messages, the size of chunks for loading data and the use of parallel loading.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The fetch_geisa() &lt;/strong&gt;method is an example of using the GEISADatabaseManager class to retrieve GEISA data for a specific molecule. This method downloads GEISA files from the GEISA website, unpacks them and saves them locally. It returns a Pandas DataFrame containing all rows from the GEISA database for the specified molecule.&lt;/p&gt;
&lt;p&gt;Before exploring the Kurucz database structure more in details, let is discuss the other modules of the RADIS API.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;The db module :&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Definition of molecules:&lt;/strong&gt; The db module allows to define the molecules used in the spectroscopic calculations. You can specify isotopes, molecular weights, chemical symbols, and other relevant molecular properties.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Spectroscopic constants: &lt;/strong&gt;The db module stores the spectroscopic constants associated with each molecule, such as electronic transitions, energy levels, frequencies, absorption intensities, cross sections, etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Access&lt;/strong&gt;: The db module provides methods and data structures to easily access information about molecules and spectroscopic constants.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Database extensions:&lt;/strong&gt; The db module allows extending the functionalities of the database by adding new molecules, isotopes or spectroscopic constants. Here it is possible to add new data or integrate external databases to enrich the capabilities of RADIS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interoperability:&lt;/strong&gt; The db module facilitates interoperability with other libraries and spectroscopic data formats. It allows to import and export spectroscopic data in different formats, such as HITRAN, HITEMP, GEISA, Kurucz, etc.&lt;/p&gt;
&lt;h4&gt;What about Exojax ?&lt;/h4&gt;&lt;p&gt;Another open-source code, called EXOJAX, exchanged portions of code with RADIS until some parts of both codes became very similar. Currently, a database API is written in the RADIS code.&lt;/p&gt;
&lt;p&gt;Understanding how Radis and Exojax somehow partially merged will be useful to understand how to implement a new database.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;May 2022 &lt;/strong&gt;: an example of an Exojax-like syntax was added in the exomol.py file. This example introduces a new class called mdbExomol, which holds Jax arrays as attributes. This class is based on DataFrame loading and is designed to be a drop-in replacement for Exojax computations.&lt;/p&gt;
&lt;pre&gt;mport pathlib&lt;br&gt;&lt;br&gt;import numpy as np&lt;br&gt;&lt;br&gt;from radis.api.exomolapi import (&lt;br&gt;    MdbExomol,&lt;br&gt;    get_exomol_database_list,&lt;br&gt;    get_exomol_full_isotope_name,&lt;br&gt;)&lt;br&gt;from radis.db.classes import get_molecule_identifier&lt;br&gt;&lt;br&gt;&lt;br&gt;def fetch_exomol(&lt;br&gt;    molecule,&lt;br&gt;    database=None,&lt;br&gt;    local_databases=None,&lt;br&gt;    databank_name="EXOMOL-{molecule}",&lt;br&gt;    isotope="1",&lt;br&gt;    load_wavenum_min=None,&lt;br&gt;    load_wavenum_max=None,&lt;br&gt;    columns=None,&lt;br&gt;    cache=True,&lt;br&gt;    verbose=True,&lt;br&gt;    clean_cache_files=True,&lt;br&gt;    return_local_path=False,&lt;br&gt;    return_partition_function=False,&lt;br&gt;    engine="default",&lt;br&gt;    output="pandas",&lt;br&gt;    skip_optional_data=True,&lt;br&gt;):&lt;/pre&gt;&lt;p&gt;Here is a description of each function parameter:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;molecule&lt;/strong&gt;: The name of the molecule for which we want to retrieve data.&lt;br&gt;database: The name of the specific ExoMol database to use. If the value is None or “default”, the recommended database will be used.&lt;br&gt;local_databases: The path to the local directory where the ExoMol database files will be stored.&lt;br&gt;&lt;strong&gt;databank_name:&lt;/strong&gt; The name to give to the ExoMol database.&lt;br&gt;isotope: The number of the specific isotope of the molecule for which you want to retrieve data.&lt;br&gt;&lt;strong&gt;load_wavenum_min and load_wavenum_max:&lt;/strong&gt; The minimum and maximum wavenumbers to load.&lt;br&gt;&lt;strong&gt;columns: &lt;/strong&gt;A list of specific columns to load from ExoMol files.&lt;br&gt;&lt;strong&gt;cache:&lt;/strong&gt; A boolean indicating whether files should be cached for later use.&lt;br&gt;&lt;strong&gt;verbose:&lt;/strong&gt; A boolean indicating whether informational messages should be displayed during the process.&lt;br&gt;&lt;strong&gt;clean_cache_files:&lt;/strong&gt; A boolean indicating whether cached files should be removed after use.&lt;br&gt;&lt;strong&gt;return_local_path and return_partition_function:&lt;/strong&gt; Booleans indicate whether local path to files and partition function should be returned in addition to data.&lt;/p&gt;
&lt;p&gt;The function starts by checking the settings and determining which ExoMol database to use. Next, it creates an MdbExomol object to manage the ExoMol database, downloading files as needed. The local files are then loaded into a DataFrame, with specific columns if needed. RADIS-specific manipulations are performed on the DataFrame, such as renaming columns and adding additional data. Eventually the DataFrame is returned, possibly with other information if selected.&lt;/p&gt;
&lt;p&gt;Then &lt;a href="https://medium.com/u/1169335fca8"&gt;Erwan Pannier&lt;/a&gt; added an Example of an Exojax-like syntax, creating a ``mdbExoMol` class holding jax arrays as Attributes (based on DataFrame loading), so it can be used as a drop-in replacement&lt;/p&gt;
&lt;p&gt;The example also shows how to : Compute an Exomol CH4 spectrum with Radis Load Exomol CH4 Jax arrays ready for an Exojax computation, by downloading the files to the .database local folder Load Exomol CH4 Jax arrays ready for an Exojax computation, by loading the files from the Radis’s database of (1) For 2. and 3., a local_databases= parameter allows to easily switch in between any local folder (to save on download &amp;amp; caching times if comparing the two codes)&lt;/p&gt;
&lt;p&gt;Here is the code ( available on &lt;a href="https://github.com/radis/radis/blob/e317c994451d3afa02b1fa63d90ae0eb546f36ed/radis/io/exomol.py#L925"&gt;radis/exomol.py at e317c994451d3afa02b1fa63d90ae0eb546f36ed · radis/radis (github.com)&lt;/a&gt;)&lt;/p&gt;
&lt;pre&gt;   #%% RADIS-like Example&lt;br&gt;    # uses fetch_exomol() internally&lt;br&gt;&lt;br&gt;    from radis import calc_spectrum&lt;br&gt;&lt;br&gt;    s = calc_spectrum(&lt;br&gt;        wavelength_min=1.630e4,&lt;br&gt;        wavelength_max=1.6305e4,&lt;br&gt;        molecule="CH4",&lt;br&gt;        isotope="1",&lt;br&gt;        pressure=1.01325,  # bar&lt;br&gt;        Tgas=1000,  # K&lt;br&gt;        mole_fraction=0.1,&lt;br&gt;        path_length=1,  # cm&lt;br&gt;        # broadening_method="fft",  # @ dev: Doesn't work with 'voigt'&lt;br&gt;        databank=(&lt;br&gt;            "exomol",&lt;br&gt;            "YT10to10",&lt;br&gt;        ),  # Simply use 'exomol' for the recommended database&lt;br&gt;    )&lt;br&gt;    # s.apply_slit(1, "cm-1")  # simulate an experimental slit&lt;br&gt;    s.plot("xsection")&lt;br&gt;&lt;br&gt;    # %% Exojax like Example&lt;br&gt;&lt;br&gt;    class mdbExoMol:&lt;br&gt;&lt;br&gt;        # hardcode attribute names, to prevent typos and the declaration of unwanted parameters&lt;br&gt;        __slots__ = [&lt;br&gt;            "Sij0",&lt;br&gt;            "logsij0",&lt;br&gt;            "nu_lines",&lt;br&gt;            "A",&lt;br&gt;            "elower",&lt;br&gt;            "eupper",&lt;br&gt;            "gupper",&lt;br&gt;            "jlower",&lt;br&gt;            "jupper",&lt;br&gt;        ]&lt;br&gt;&lt;br&gt;        def __init__(&lt;br&gt;            self,&lt;br&gt;            molecule,&lt;br&gt;            path,&lt;br&gt;            nurange=[-np.inf, np.inf],&lt;br&gt;            crit=-np.inf,&lt;br&gt;            local_databases="~/exojax",&lt;br&gt;        ):&lt;br&gt;            """&lt;br&gt;            Parameters&lt;br&gt;            ----------&lt;br&gt;            molecule: molecule name&lt;br&gt;            path : local path, mirror of ExoMol path&lt;br&gt;            nurange : TYPE, optional&lt;br&gt;                DESCRIPTION. The default is [-np.inf, np.inf].&lt;br&gt;            crit : TYPE, optional&lt;br&gt;                DESCRIPTION. The default is -np.inf.&lt;br&gt;&lt;br&gt;            Returns&lt;br&gt;            -------&lt;br&gt;            DataFrame&lt;br&gt;&lt;br&gt;            Examples&lt;br&gt;            --------&lt;br&gt;            ::&lt;br&gt;&lt;br&gt;                mdbCH4 = mdbExoMol("CH4", '.database/CH4/12C-1H4/YT10to10/', nus, crit=1.e-30)&lt;br&gt;                print(len(mdbCH4.nu_lines), "lines")&lt;br&gt;                mdbCH4.elower&lt;br&gt;&lt;br&gt;            Available columns::&lt;br&gt;&lt;br&gt;                [&lt;br&gt;                    "Sij0",&lt;br&gt;                    "logsij0",&lt;br&gt;                    "nu_lines",&lt;br&gt;                    "A",&lt;br&gt;                    "elower",&lt;br&gt;                    "eupper",&lt;br&gt;                    "gupper",&lt;br&gt;                    "jlower",&lt;br&gt;                    "jupper",&lt;br&gt;                ]&lt;br&gt;&lt;br&gt;            """&lt;br&gt;&lt;br&gt;            wavenum_min, wavenum_max = np.min(nurange), np.max(nurange)&lt;br&gt;            if wavenum_min == -np.inf:&lt;br&gt;                wavenum_min = None&lt;br&gt;            if wavenum_max == np.inf:&lt;br&gt;                wavenum_max = None&lt;br&gt;&lt;br&gt;            # Set-up database, download files and set-up cache files if needed&lt;br&gt;            mdb = MdbExomol(&lt;br&gt;                path,&lt;br&gt;                molecule=molecule,&lt;br&gt;                local_databases=local_databases,&lt;br&gt;                nurange=[wavenum_min, wavenum_max],&lt;br&gt;            )&lt;br&gt;&lt;br&gt;            # Get cache files to load :&lt;br&gt;            mgr = mdb.get_dframe_manager()&lt;br&gt;            local_files = [mgr.cache_file(f) for f in mdb.trans_file]&lt;br&gt;&lt;br&gt;            # Load them:&lt;br&gt;            jdict = mdb.load(&lt;br&gt;                local_files,&lt;br&gt;                columns=[k for k in self.__slots__ if k not in ["logsij0"]],&lt;br&gt;                lower_bound=([("nu_lines", wavenum_min)] if wavenum_min else [])&lt;br&gt;                + ([("Sij0", mdb.crit)] if not np.isneginf(mdb.crit) else []),&lt;br&gt;                upper_bound=([("nu_lines", wavenum_max)] if wavenum_max else []),&lt;br&gt;                output="jax",&lt;br&gt;            )&lt;br&gt;&lt;br&gt;            # set attributes, accessible as e.g:  mdb.nu_lines&lt;br&gt;            for k in jdict.keys():&lt;br&gt;                setattr(self, k, jdict[k])&lt;br&gt;&lt;br&gt;    nus = np.linspace(1e7 / 1.630e4, 1e7 / 1.6305e4)&lt;br&gt;&lt;br&gt;    # Download new ExoMol repo (in ~/exomol)&lt;br&gt;    mdbCH4 = mdbExoMol(&lt;br&gt;        "CH4",&lt;br&gt;        ".database/CH4/12C-1H4/YT10to10/",&lt;br&gt;        nus,&lt;br&gt;        crit=1.0e-30,&lt;br&gt;        local_databases=".",  # use local folder&lt;br&gt;    )&lt;br&gt;&lt;br&gt;    print(len(mdbCH4.nu_lines), "lines")&lt;br&gt;    mdbCH4.elower&lt;br&gt;&lt;br&gt;    # Or use RADIS's folder  (# by default ~/.radisdb/exomol)&lt;br&gt;    import radis&lt;br&gt;&lt;br&gt;    mdbCH4_2 = mdbExoMol(&lt;br&gt;        "CH4",&lt;br&gt;        "CH4/12C-1H4/YT10to10/",&lt;br&gt;        nus,&lt;br&gt;        crit=1.0e-30,&lt;br&gt;        local_databases=pathlib.Path(radis.config["DEFAULT_DOWNLOAD_PATH"]) / "exomol",&lt;br&gt;    )&lt;br&gt;    # ... ready to run Jax calculations&lt;/pre&gt;&lt;p&gt;The example added in the exomol.py file of RADIS demonstrates how to create an “mdbExoMol” class similar to Exojax, which uses jax arrays as attributes. This class allows loading ExoMol data as jax arrays, making them compatible with Exojax.&lt;/p&gt;
&lt;p&gt;The example illustrates how to calculate a CH4 spectrum using RADIS by utilizing the “mdbExoMol” class. It also shows how to load the jax arrays ready for use in an Exojax computation by downloading the files into a local “.database” folder. Additionally, the example demonstrates how to load the jax arrays from the RADIS database, enabling easy switching between different local databases by specifying the “local_databases” parameter.&lt;/p&gt;
&lt;h4&gt;Toward a common API ?&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Preliminary work in Radis #465&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This preliminary work was done to prepare for a meeting between RADIS and ExoJax to discuss the implementation of a common API for database management.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The rationale behind this work is to maintain three layers of agnosticism to simplify the user experience:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Users should not have to worry about the specific format of the input database,&lt;/strong&gt; such as HITRAN 2012, HITRAN 2020, HITEMP, GEISA, ExoMol, Kuruz, NIST, etc. This allows for easy integration of new libraries and ensures that all codes can benefit from all available libraries.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Users should not have to be concerned about the format in which the data is stored on disk&lt;/strong&gt;, whether it’s Vaex’s HDF5, Pandas’s HDF5, Feather, or other formats. This flexibility enables the switch to more performant libraries when they become available, such as PyArrow.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Users should have the freedom to choose the output format used in calculations&lt;/strong&gt;, whether it’s Pandas’s DataFrame, Jax arrays, Vaex DataFrame, or others. This allows for data retrieval in the desired format for each code, such as Jax for ExoJax, Pandas for the current RADIS implementation, or Vaex for future fully-out-of-core RADIS for extreme databases.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;Radis state in May 2022&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;ExoJax &lt;/strong&gt;has MdbExomol or MdbHIt . They are similar but don’t inherit from a common base ;&lt;br&gt;&lt;strong&gt;RADIS 0.12 has a DatabaseManager&lt;/strong&gt; to handle HITEMP 2020 / HITRAN 2020; the ExoMol support is done with a MdBMol taken from Exojax with no link with the DatabaseManager.&lt;br&gt;RADIS implemented a &lt;strong&gt;DataFileManager&lt;/strong&gt; &lt;strong&gt;class&lt;/strong&gt; to handle (Vaex’s HDF5; Pandas’s HDF5, Feather) ; DatabaseManager calls DataFileManager internally &lt;br&gt;Radis Exomol api update #464 added &lt;strong&gt;3 output : ’jax/vaex/pandas’&lt;/strong&gt; to RADIS’s DatabaseManager&lt;/p&gt;
&lt;p&gt;Here Radis then suggest a code a demonstration :&lt;/p&gt;
&lt;pre&gt;# Test ExoMol&lt;br&gt;&lt;br&gt;import radis&lt;br&gt;radis.config["MEMORY_MAPPING_ENGINE"] = "vaex" # 👉👉👉  choose  "vaex", "pytables", "feather"&lt;br&gt;&lt;br&gt;from radis.io.exomol import fetch_exomol&lt;br&gt;&lt;br&gt;df = fetch_exomol("SiO", database="EBJT", isotope="1", load_wavenum_max=5000, &lt;br&gt;        output="pandas" # 👉👉👉 choose : "pandas", "vaex", "jax"&lt;br&gt;        )&lt;br&gt;print(df)&lt;br&gt;&lt;br&gt;&lt;/pre&gt;&lt;p&gt;This code allows you to fetch ExoMol data for the SiO molecule from the specified database, control the output format, and print the resulting DataFrame.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;MdbExomol class&lt;/strong&gt; is a molecular database class specifically designed for ExoMol, which is a database of molecular line lists for exoplanet and other hot atmospheres. It is a subclass of the DatabaseManager class.&lt;/p&gt;
&lt;p&gt;The MdbExomol class has the following parameters:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;path&lt;/strong&gt;: The path for the ExoMol data directory or tag.&lt;br&gt;nurange: A wavenumber range list (in cm-1) or a wavenumber array.&lt;br&gt;margin: A margin for the wavenumber range (in cm-1).&lt;br&gt;&lt;strong&gt;crit:&lt;/strong&gt; The line strength lower limit for extraction.&lt;br&gt;&lt;strong&gt;bkgdatm&lt;/strong&gt;: The background atmosphere for broadening, e.g., H2, He.&lt;br&gt;broadf: If False, the default broadening parameters in the .def file are used.&lt;br&gt;Additionally, there are other parameters such as engine and skip_optional_data that control the memory mapping engine and the loading of optional data from the ExoMol definition file, respectively.&lt;/p&gt;
&lt;p&gt;The MdbExomol class provides methods to load and manage the ExoMol data files. It converts the trans/states files to feather or HDF5 format for efficient loading. The loaded data is stored in a DataFrame with columns such as nu_lines, Sij0, A, elower, gpp, jlower, and more. These columns contain information about line centers, line strengths, Einstein A coefficients, lower state energy, statistical weight, J_lower, and other relevant parameters.&lt;/p&gt;
&lt;p&gt;The class also provides examples of how to initialize the database, download the necessary files, and load the data. It references the original publications on ExoMol for more information.&lt;/p&gt;
&lt;h5&gt;Discussion between Radis and Exojax&lt;/h5&gt;&lt;p&gt;The question of hosting the common API was addressed for the first time in discussion&lt;strong&gt; #257&lt;/strong&gt;. It is suggested to create a new directory or module within Radis for the common API. However, it is noted that this may make development difficult if specific Radis features need to be integrated into the common API. A suggestion is made to create a separate module, such as “radis.api”, which would house the common API.&lt;/p&gt;
&lt;p&gt;A proposed structure was discussed, where the DatabaseManager class is considered the core common API. Subclasses, such as HitranManager and ExomolManager, inherited from DatabaseManager to provide the specific functionalities for the Hitran and Exomol databases, respectively.&lt;/p&gt;
&lt;p&gt;A suggestion was made to create a MdbHitran class (inheriting from HitranManager) and a MdbExomol class (inheriting from ExomolManager) for the ExoJAX API. These classes would have their own ExoJAX-specific methods, allowing ExoJAX to integrate with the common API.&lt;/p&gt;
&lt;p&gt;Radis and Exojax agreed that separating the functionalities into separate folders is a good approach to avoid conflicts between Radis-specific and ExoJAX-specific features. Additionally, they suggested to add tests to ensure that ExoJAX requirements were tested within Radis without causing any issues.&lt;/p&gt;
&lt;p&gt;It starts from the “radis.api” folder for the common API, which would be included within Radis. This approach would allow for the development of the common API while maintaining a close connection with Radis. Furthermore, the possibility of creating a new directory or module for an independent API in the future is considered, to allow the common API to become independent if needed.&lt;/p&gt;
&lt;p&gt;In summary, the conversation revolves around the hosting and structure of the common API between Radis and ExoJAX. It is decided to create a separate module, “radis.api”, for the common API while keeping the possibility of independent development in the future. Specific classes are proposed for ExoJAX, enabling the integration of ExoJAX into the common API. Measures are taken to separate Radis-specific and ExoJAX-specific functionalities and to test ExoJAX requirements within Radis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;After this discussion, a series of measures was implemented to Radis in PR # 480&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The common functions shared between Exojax and Radis were moved to the &lt;strong&gt;“radis/api”&lt;/strong&gt; directory, allowing for better organization and separation of concerns.&lt;br&gt;Parts of Hitran, Hitemp, CDSD, and GEISA &lt;strong&gt;that were common to both Exojax and Radis were also moved to the “radis/api”&lt;/strong&gt; directory.&lt;br&gt;The Exomol files were combined and moved to the “radis/api” directory, and tests were fixed accordingly.&lt;br&gt;The io.tools module was moved to the “radis/api/tools” directory for better organization.&lt;br&gt;Links in the documentation and docstrings were renamed to reflect the changes in the code structure.&lt;br&gt;Some missing files were added, isort errors on CI were fixed, and unclosed HDF5 files were addressed.&lt;br&gt;The Exomol documentation was updated, and error messages were improved.&lt;br&gt;The set_broadenings function was made compatible with both vaex and pandas DataFrames.&lt;br&gt;Modifications were made to the set_broadening function, including assuming a dictionary as input for unknown DataFrames and redefining the function to store values in a DataFrame.&lt;br&gt;The MdbExomol instance now includes self.molmass.&lt;br&gt;The codebase was merged with the upstream “add/common-api” branch.&lt;br&gt;Some abspath problems were fixed, and error messages were improved.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In November 2022, the version 0.14 was released and the common API with Exojax was added to Radis.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Review of the exomolapi.py code&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This code is an API for accessing and using data from the ExoMol project. It includes a main class MdbExomol that allows downloading and accessing ExoMol files, as well as performing spectral calculations. The MdbExomol class provides methods for downloading files, creating PartFuncExoMol objects, and loading specific line data.&lt;/p&gt;
&lt;p&gt;The download function allows downloading ExoMol files from a specified URL and saving them locally. The to_partition_function_tabulator function generates a PartFuncExoMol object from the ExoMol-specific partition function data.&lt;/p&gt;
&lt;p&gt;The if __name__ == “__main__” section contains examples of using the MdbExomol class and other features of the API, including spectrum calculations using the RADIS library, and downloading and accessing ExoMol line data using the fetch_exomol function.&lt;/p&gt;
&lt;p&gt;Thus, the ExoMol API provides tools for downloading, manipulating, and utilizing spectroscopic data from the ExoMol project, including transition files, partition functions, and calculated spectra.&lt;/p&gt;
&lt;h4&gt;Conclusion : How should I proceed to add to Radis a new database as Kurucz ?&lt;/h4&gt;&lt;p&gt;Regarding implementing Kurucz, the structure of the exomolapi.py code can serve as a model for building a similar API for Kurucz data. I may create a class similar to MdbExomol that handles downloading Kurucz files, accessing the relevant data (such as atomic and molecular line data, partition functions, etc.), and provides methods for spectral calculations and other functionalities specific to Kurucz. I will have to adapt and modify the existing code to suit the data format and organization of Kurucz data.&lt;br&gt;In order to do so, I will review the structure of the Kurucz database and make a quick report in a next post before starting the implementation.&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=fc58bc4e9979" width="1"&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2023/06/20230604_2227_menasrac/</guid><pubDate>Sun, 04 Jun 2023 21:27:53 GMT</pubDate></item><item><title>GSoC - Community Bonding</title><link>http://openastronomy.org/Universe_OA/posts/2023/06/20230602_0000_gaurav17joshi/</link><dc:creator>Gaurav Joshi</dc:creator><description>&lt;h3 id="what-is-the-community-bonding-period"&gt;What is the Community Bonding Period?&lt;/h3&gt;
&lt;p&gt;The community bonding period is the 3 weeks between GSoC student acceptance and the start of coding date. This is a vital time to engage with your GSoC contributor and set them up for success. In this time, I got in touch with my two mentors as well as my fellow Gsocers. We made plans for our project with my mentor describing some important aspects of it. The feature that I am implimenting is a GP interface for QPO oscillations, but it is useful for many other astronomical timeseries anaylsis so we discussed how it should be both flexible for the user, as well as automate all the complicated stuff.&lt;/p&gt;

&lt;!-- TEASER_END --&gt;
&lt;p&gt;I studied the various python packages, that would be used, and also created a proof of concept code for the feature.&lt;/p&gt;

&lt;h3 id="packages-used"&gt;Packages used&lt;/h3&gt;
&lt;p&gt;In this project, I will be using many differnent packages, hense I worked with them to understand their features in this CB period.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Jax: Jax is an open-source Python library designed to facilitate high-performance numerical computing and automatic differentiation. It provides a combination of functional programming concepts and powerful array operations, making it well-suited for machine learning and scientific computing tasks. Jax can be understood as numpy on accelerators, with three important features, Jax.grad, Jax.jit and Jax.vamp.
Jax.grad is used to calculate automatic derivatives of complex functions.
Jax.jit is used to compile the code on XLA using the jaxpr language.
Jax.vmap is used to wrap functions for batches without explicitly doing so.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;With its strong integration with NumPy and compatibility with modern hardware accelerators, Jax has become a popular choice among researchers and practitioners in the machine learning community.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;TinyGP: TinyGP is a Python package aimed at providing a lightweight and user-friendly framework for Gaussian Processes (GPs). TinyGP offers essential functionalities for modeling and inference with GPs, including covariance functions, hyperparameter optimization, and predictive uncertainty estimation. The package is written in jax and well integrated with various optimisation libraries.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Numpyro: NumPyro is a powerful probabilistic programming library built on top of NumPy, JAX, and Pyro. It combines the ease of use and familiar syntax of NumPy with the flexibility and automatic differentiation capabilities of JAX to enable efficient and scalable Bayesian inference. NumPyro provides a wide range of probabilistic models, inference algorithms, and tools for model specification, allowing users to express complex probabilistic models and perform inference tasks such as Markov chain Monte Carlo (MCMC) and variational inference.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2023/06/20230602_0000_gaurav17joshi/</guid><pubDate>Thu, 01 Jun 2023 23:00:00 GMT</pubDate></item><item><title>Community Bonding Period</title><link>http://openastronomy.org/Universe_OA/posts/2023/06/20230601_0311_pupperemeritus/</link><dc:creator>pupper emeritus</dc:creator><description>&lt;h3&gt;


&lt;!-- TEASER_END --&gt;
Brief
&lt;/h3&gt;

&lt;p&gt;Hello everyone this is Sri Guru Datta P.(pupperemeritus). I am extremely excited to get started with my GSoC journey. It has been a dream come true for me.&lt;/p&gt;

&lt;p&gt;Most of the progress in these weeks has been done on the fronts of&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Re-adjusting the proposed schedule : Re-evaluating and taking a closer look at requirements&lt;/li&gt;
&lt;li&gt;Gathering more information required to implement : Been provided reference implementation in MATLAB by Dr. Jeff Scargle himself. And validating the plan and research done during the period of creating the project proposal.&lt;/li&gt;
&lt;li&gt;Had weekly meets to break the ice and communicate more directly through weekly meets with mentors.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;


Environment setup
&lt;/h3&gt;

&lt;p&gt;I had already completed my environment setup earlier in order to make pull requests to stingray. I just followed the documentation.&lt;br&gt;
&lt;a href="https://docs.stingray.science/install.html"&gt;https://docs.stingray.science/install.html&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;


Codebase familiarity
&lt;/h3&gt;

&lt;p&gt;I already had a bit of familiarity with powerspectrum, crossspectrum and bexvar modules as I had worked on various pull requests on them. My mentor advised me to look into multitaper, which I did. It gave me a few ideas on how I could implement this project.&lt;/p&gt;

&lt;h3&gt;


Coding
&lt;/h3&gt;

&lt;p&gt;I had already started a few days early and went ahead and implemented the Lomb-Scargle Fourier Transform which will be the backbone of the power spectrum and cross spectrum. 2 days into the coding period and I also have started coding up the wrapper classes. It turns out to be a very tangled process in order to get every small nook and cranny of the class to work. But I have seemed to get the hang of it.&lt;/p&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2023/06/20230601_0311_pupperemeritus/</guid><pubDate>Thu, 01 Jun 2023 02:11:02 GMT</pubDate></item><item><title>Utilising community bonding period Effectively!</title><link>http://openastronomy.org/Universe_OA/posts/2023/05/20230530_0000_1someshverma/</link><dc:creator>Somesh Verma</dc:creator><description>&lt;p&gt;I started to contribute to RADIS from January’23 and whenever i needed help in some issue , mentors were quite helpful in providing revelant information to resolve that issue . And this thing helped me , to develop good bonding and understanding with the mentors .&lt;/p&gt;

&lt;p&gt;So,I thought, i should use community bonding period more productively thus, i decided to work on project from 15 May .&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;In community bonding period i have done following things -&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Read the RADIS and HITRAN Paper (selected parts)&lt;/li&gt;
&lt;li&gt;Worked on Loading the dataframe in Vaex format (task of first week)&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id="loading-dataframe-in-vaex-format"&gt;Loading Dataframe in Vaex format&lt;/h6&gt;
&lt;p&gt;There are two main functions which are used load databank in RADIS
These are :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;fetch_databank()&lt;/li&gt;
&lt;li&gt;load_databank()&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;fetch_databank() : It is used to load databank from standard databank like HITRAN,HITEMP,EXOMOL,GEISA by fetching it from their respective APIs, then parsing and processing them.&lt;/p&gt;

&lt;p&gt;load_databank() : It is used to load databank from the local file or to load databank from user defined databank .&lt;/p&gt;

&lt;p&gt;Upto now, i have worked on fetch_databank() function to load dataframe in Vaex format , some of the things were already implemented while at other points i needed to write code specifically for vaex dataframe format.&lt;/p&gt;

&lt;p&gt;Similarly, for load_databank() function , the hurdle was to parse it in vaex dataframe format as virual columns which are used in vaex dataframe to reduce memory use , it was throwing error . After trying many i finally found a fix for it .&lt;/p&gt;

&lt;p&gt;Now, I have made necessary changes to these two functions to load dataframe in Vaex format. Next week i will be working on writing test cases for these.&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2023/05/20230530_0000_1someshverma/</guid><pubDate>Mon, 29 May 2023 23:00:00 GMT</pubDate></item><item><title>Getting selected for GSoC’23@RADIS!</title><link>http://openastronomy.org/Universe_OA/posts/2023/05/20230524_0000_1someshverma/</link><dc:creator>Somesh Verma</dc:creator><description>&lt;p&gt;I am Somesh Verma,a third year undergrad at National Institute of Technology Hamirpur. I have been accepted as contributor to the OpenAstronomy  RADIS.&lt;/p&gt;

&lt;h4 id="choosing-organisation"&gt;Choosing Organisation&lt;/h4&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;I  chose OpenAstronomy as i have interest in astronomy right from my childhood and RADIS also aline with my interst and skills .I have also contributed to Libre Health App for Baby Care but then i shifted my focus  only to RADIS . By the end i had four merged pull request and I was working on the fifth issue.&lt;/p&gt;

&lt;h4 id="contriutions-and-experience"&gt;Contriutions and Experience&lt;/h4&gt;
&lt;p&gt;I started to contribute to RADIS from January’23 , initially i faced problem to set up the things and run the code . After one weel or so I fixed the issues and than I spent one week on understanding the codebase ,reading documentation and try examples. By now , i had developed a rough understanding of the code .&lt;/p&gt;

&lt;p&gt;Then , I started to find issue over which i can work and started to work on the issues ,mentors have been quite helpful so far, whenever i got struck somewhere ,they helped in resolving the issue .&lt;/p&gt;

&lt;p&gt;I am looking forward to have the great Learning experience this Summer with RADIS :)&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2023/05/20230524_0000_1someshverma/</guid><pubDate>Tue, 23 May 2023 23:00:00 GMT</pubDate></item></channel></rss>