<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts by DeadSpheroid)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/authors/deadspheroid.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sun, 28 Jul 2024 01:08:58 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Exploring OpenCL memory management</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240713_2230_deadspheroid/</link><dc:creator>DeadSpheroid</dc:creator><description>&lt;p class="intro"&gt;In this post, I hope to give a high level understanding of OpenCL's Memory Mechanisms&lt;/p&gt;

&lt;h2 id="the-basics"&gt;The basics&lt;/h2&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Firstly, its important to have a basic understanding of the hardware involved. Keeping it simple, each OpenCL device represents a different set of hardware, each with its own RAM.
My own laptop has a 16GB CPU RAM, and 6GB VRAM&lt;/p&gt;

&lt;p&gt;Now, at the heart of C, we have pointers, without them well, you can’t really get much done in C. The pointers we convetionally use are pointers to CPU RAM.&lt;/p&gt;

&lt;p&gt;So what would happen if you try to pass a CPU Pointer to the GPU?
Well, of course, it wont work, the GPU simply segfaults, as it cannot understand the pointer given to it.
But we still need to use pointers, we can’t just abandon them. So how do we do this?&lt;/p&gt;

&lt;h2 id="buffers"&gt;Buffers&lt;/h2&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Map/Unmap Buffers" src="https://deadspheroid.github.io/my-blog/assets/img/opencl-map.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;At the simplest level, we have OpenCL Buffers. These buffers are chunks of memory allocated on the OpenCL device as well as on host memory.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;cl_mem clCreateBuffer(
cl_context context,
cl_mem_flags flags,
size_t size,
void *host_ptr,
cl_int *errcode_ret)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Creating a buffer is easy, its figuring out what kind of buffer you need that is important.&lt;/p&gt;

&lt;p&gt;Broadly speaking there are 3 types of buffers based on the &lt;code class="language-plaintext highlighter-rouge"&gt;flags&lt;/code&gt; passed:&lt;/p&gt;

&lt;h4 id="cl_mem_use_host_ptr"&gt;CL_MEM_USE_HOST_PTR&lt;/h4&gt;
&lt;p&gt;This tells OpenCL to use the host pointer provided as the underlying memory on host.&lt;/p&gt;

&lt;h4 id="cl_mem_copy_host_ptr"&gt;CL_MEM_COPY_HOST_PTR&lt;/h4&gt;
&lt;p&gt;This flag tells OpenCL to make a new buffer and fill it with the memory pointed to by host pointer.&lt;/p&gt;

&lt;h4 id="cl_mem_alloc_host_ptr"&gt;CL_MEM_ALLOC_HOST_PTR&lt;/h4&gt;
&lt;p&gt;This one is the same as CL_MEM_USE_HOST_PTR, but the allocation of host pointer is also done by OpenCL&lt;/p&gt;

&lt;p&gt;But which one should you use?
Well, if you desire a zero copy buffer, i.e. create a buffer without copying memory, especially memory on host, then
CL_MEM_USE_HOST_PTR(if you have the memory already initialised)
or
CL_MEM_ALLOC_HOST_PTR(if you plan to initialise the buffer afterward)
The concept of a zero copy buffer is super helpful when you are targeting the same host CPU as an OpenCL device.&lt;/p&gt;

&lt;p&gt;I mean, you already have the data in CPU RAM, why would you make another copy in CPU RAM by creating a new buffer?&lt;/p&gt;

&lt;h2 id="literacy-for-buffers"&gt;Literacy for Buffers&lt;/h2&gt;
&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Map/Unmap Buffers" src="https://deadspheroid.github.io/my-blog/assets/img/opencl-mem.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;The above is enough when you are operating on the same device, which is seldom the case with OpenCL.
But when you work with GPUs, you need to get the memory into GPU VRAM somehow.&lt;/p&gt;

&lt;p&gt;And this is impossible(maybe) without copying the data over.&lt;/p&gt;

&lt;p&gt;So how do you copy the data over to GPU VRAM?
Well, after allocating a buffer as seen before, OpenCL will try to recreate the host side buffer on the device as well.&lt;/p&gt;

&lt;p&gt;But when you update the host side buffer(like reading in input), youd want it to reflect on device as well.
Similary, when your device is done processing, you need to get the output from device memory to host memory.&lt;/p&gt;

&lt;p&gt;There are two main ways to do this:&lt;/p&gt;
&lt;h4 id="readwrite-buffer"&gt;Read/Write Buffer&lt;/h4&gt;
&lt;p&gt;You have a buffer on host memory and on device memory that mirror each other.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;cl_int clEnqueueReadBuffer(
cl_command_queue command_queue,
cl_mem buffer,
cl_bool blocking_read,
size_t offset,
size_t size,
void* ptr,
cl_uint num_events_in_wait_list,
const cl_event* event_wait_list,
cl_event* event);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;cl_int clEnqueueWriteBuffer(
cl_command_queue command_queue,
cl_mem buffer,
cl_bool blocking_write,
size_t offset,
size_t size,
const void* ptr,
cl_uint num_events_in_wait_list,
const cl_event* event_wait_list,
cl_event* event);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OpenCL provides Read/Write commands to force overwrite of one buffer over the other, and in this way, data transfer is achieved.&lt;/p&gt;

&lt;h4 id="mapunmap-buffer"&gt;Map/Unmap Buffer&lt;/h4&gt;
&lt;p&gt;There is a single buffer on device memory, that is presented to CPU when demanded
So “mapping” a buffer will bring it from device memory into host RAM.
Then any changes made will be saved in host RAM.
Finally, once done with changes, you may “unmap” the buffer, which writes all changes made back to device memory&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;void* clEnqueueMapBuffer(
cl_command_queue command_queue,
cl_mem buffer,
cl_bool blocking_map,
cl_map_flags map_flags,
size_t offset,
size_t size,
cl_uint num_events_in_wait_list,
const cl_event* event_wait_list,
cl_event* event,
cl_int* errcode_ret);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;cl_int clEnqueueUnmapMemObject(
cl_command_queue command_queue,
cl_mem memobj,
void* mapped_ptr,
cl_uint num_events_in_wait_list,
const cl_event* event_wait_list,
cl_event* event);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this way, data transfer is achieved&lt;/p&gt;

&lt;h2 id="to-map-or-not-to-map"&gt;To map or not to map?&lt;/h2&gt;
&lt;p&gt;To be honest, performance differences are very minute, atleast from my tests with the gnuastro library.
However Map and Unmapping makes a world of difference as compared to Read/Write when it comes to simplicity&lt;/p&gt;

&lt;h2 id="the-problem-with-buffers"&gt;The problem with buffers&lt;/h2&gt;
&lt;p&gt;No matter what you do, when working with buffers, you always end up copying the data
For example, you load an image into CPU RAM, but actually want to work with it on the GPU.
So, you end up copying the image into GPU RAM. In the end, you process the same data twice, once while loading and once while copying&lt;/p&gt;

&lt;p&gt;For small images(2000 x 2000) this is barely noticeable
But gnuastro, and the people using gnuastro deal with astronomical images of incredibly large sizes(i’ve heard 30GB just for one image).&lt;/p&gt;

&lt;p&gt;So, most certainly, any time you save by using parallelised processing on the GPU, is lost and maybe even worsened by the data transfer times.
Then, using the GPU is almost pointless, unless you use the same data over and over again&lt;/p&gt;

&lt;p&gt;“Well, cant I just load the data on the GPU directly?”
Thats not possible, atleast not to my knowledge. This is the tradeoff with GPUs.
On a CPU, you have 4/8/16 highly specialised and capable cores(math, I/O), while on the GPU you have 1000s of some very primitive math operations(only math, no I/O)
So you always have to load it into CPU RAM first and then go to GPU RAM.&lt;/p&gt;

&lt;p&gt;So how can we fix this problem?
Well, one of the options is to use Shared Virtual Memory(OpenCL SVM), which enables the GPU to directly access CPU RAM and play with CPU pointers.&lt;/p&gt;

&lt;p&gt;However, I still have yet to test SVM in the context of gnuastro, to see if its useful.
Besides, SVM also fixes the problem of structs containing pointers(for another post).
Documentation for OpenCL is already sparse, and to add insult to injury, documentation on OpenCL SVM is even more sparse.
But I like the challenge…&lt;/p&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240713_2230_deadspheroid/</guid><pubDate>Sat, 13 Jul 2024 21:30:00 GMT</pubDate></item><item><title>Deeper into OpenCL</title><link>http://openastronomy.org/Universe_OA/posts/2024/06/20240622_2045_deadspheroid/</link><dc:creator>DeadSpheroid</dc:creator><description>&lt;p class="intro"&gt;In this post, I hope to give a high level understanding of OpenCL and its workings&lt;/p&gt;

&lt;h2 id="setting-it-up"&gt;Setting it up&lt;/h2&gt;
&lt;!-- TEASER_END --&gt;
&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL ICD" src="https://deadspheroid.github.io/my-blog/assets/img/ocl-icd.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;
&lt;p&gt;OpenCL is relatively easy to get up and running on your system.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For users:
All you need, is the OpenCL runtime for your device!
In case of Nvidia, this comes with the Nvidia drivers, while for Intel CPUs, this has to be manually installed by a package manager.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For developers:
You will need the OpenCL library to link against, and the OpenCL headers as well, again easily available in your package manager.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="heres-a-new-perspective"&gt;Here’s a new perspective&lt;/h2&gt;
&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Platform Model" src="https://deadspheroid.github.io/my-blog/assets/img/ocl-platform.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;
&lt;p&gt;OpenCL presents a general interface to the developer, no matter what the device or the architecture.&lt;/p&gt;

&lt;p&gt;Firstly, we have the host, which is responsible for all the book-keeping, and task scheduling on the OpenCL device.&lt;/p&gt;

&lt;p&gt;Then, we have our OpenCL device, which is divided into a number of compute units.
Each Compute Unit (CU) is further divided into a number of processing elements.&lt;/p&gt;

&lt;p&gt;But what do these words actually mean?&lt;/p&gt;

&lt;p&gt;Well, a Processing Element(PE) is a single unit, that is responsible for executing a single thread(also called a work item). Think of a single function being executed.&lt;/p&gt;

&lt;p&gt;Each PE has its own private memory, not accessible by anyone, but this PE&lt;/p&gt;

&lt;p&gt;A bunch of processing elements are grouped together to form a compute unit which, at a time, executes a single work group(grouping of many work items).&lt;/p&gt;

&lt;p&gt;The CUs all share a global memory, accessible by anyone&lt;/p&gt;

&lt;p&gt;So for a CPU, the maximum number of CU s is the number of CPU cores!&lt;/p&gt;

&lt;p&gt;But why do you want work groups? Why not have work items only?&lt;/p&gt;

&lt;p&gt;Well, having this grouping of work items, allows for a greater deal of complexity, because we can synchronize across items in a work group, have a local memory only for this work group, and more…&lt;/p&gt;

&lt;h2 id="a-complete-walkthrough"&gt;A complete walkthrough&lt;/h2&gt;
&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Execution Model" src="https://deadspheroid.github.io/my-blog/assets/img/ocl-exec.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;Let’s look at a typical workflow for an OpenCL program&lt;/p&gt;

&lt;h3 id="initialisation"&gt;Initialisation&lt;/h3&gt;
&lt;p&gt;First we need to check the currently available OpenCL platforms, which are basically implementations of OpenCL available on your system&lt;/p&gt;

&lt;p&gt;For example, you can have both Intel OpenCL and POCL OpenCL for your i7 CPU.&lt;/p&gt;

&lt;p&gt;Then from these platforms, you need to choose a device to execute on. OpenCL supports CPUs, GPUs, FPGAs, and all sorts of accelerators.&lt;/p&gt;

&lt;h3 id="context"&gt;Context&lt;/h3&gt;
&lt;p&gt;Once you have the platform and device you wish to use, you need to create an OpenCL context, which will handle everything for that particular platform and device.&lt;/p&gt;

&lt;h3 id="command-queue"&gt;Command Queue&lt;/h3&gt;
&lt;p&gt;Then, you have to create a command queue, which, as the name suggests, will store any commands(kernels) you queue for execution, and dispatch them in order(or even out of order if you like!).&lt;/p&gt;

&lt;h3 id="kernel"&gt;Kernel&lt;/h3&gt;
&lt;p&gt;After the command queue, you must compile the kernel source code(the api provides functions to do this), so that it can be executed later.&lt;/p&gt;

&lt;h3 id="memory"&gt;Memory&lt;/h3&gt;
&lt;p&gt;Finally, one of the most important parts of this entire process, is passing the input to the OpenCL device.&lt;/p&gt;

&lt;p&gt;Now, initially the data is stored on your CPU RAM, which is unfortunately inaccessible to your GPU.&lt;/p&gt;

&lt;p&gt;Therefore you need to copy the data to your GPU RAM, using the &lt;code class="language-plaintext highlighter-rouge"&gt;cl_mem&lt;/code&gt; interface that OpenCL provides.&lt;/p&gt;

&lt;p&gt;However, if you know that the device being used is the same CPU, then this copy can be skipped, to save time, using the &lt;code class="language-plaintext highlighter-rouge"&gt;CL_MEM_USE_HOST_PTR&lt;/code&gt; flag while creating a &lt;code class="language-plaintext highlighter-rouge"&gt;cl_mem&lt;/code&gt; object.&lt;/p&gt;

&lt;h3 id="execution"&gt;Execution&lt;/h3&gt;
&lt;p&gt;At the end, you can use the command queue created earlier along with the &lt;code class="language-plaintext highlighter-rouge"&gt;cl_mem&lt;/code&gt; created previously to execute the compiled kernel on the device&lt;/p&gt;

&lt;p&gt;Subsequently don’t forget to copy the output data back to CPU RAM, if the execution was done on GPU.&lt;/p&gt;

&lt;p&gt;However, there’s still a ton of unexplained stuff like, “How do you save the time wasted in copying data to the device?” or “Can you pass any data to the device? Even structs?”&lt;/p&gt;

&lt;p&gt;We’ll explore OpenCL more in subsequent posts.&lt;/p&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2024/06/20240622_2045_deadspheroid/</guid><pubDate>Sat, 22 Jun 2024 19:45:00 GMT</pubDate></item><item><title>OpenCL, meet the Gnuastro Build System</title><link>http://openastronomy.org/Universe_OA/posts/2024/06/20240609_0045_deadspheroid/</link><dc:creator>DeadSpheroid</dc:creator><description>&lt;p class="intro"&gt;In this post, I hope to summarize the work done so far towards my GSoC project for integrating OpenCL with the Gnuastro library and my relatively limited understanding of OpenCL.&lt;/p&gt;

&lt;h2 id="what-is-opencl"&gt;What is OpenCL?&lt;/h2&gt;
&lt;!-- TEASER_END --&gt;
&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Logo" src="https://deadspheroid.github.io/my-blog/assets/img/opencl-logo.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.khronos.org/opencl/"&gt;Open Computing Language&lt;/a&gt;&lt;/strong&gt; is a framework for writing programs that execute across &lt;strong&gt;heterogenous&lt;/strong&gt; platforms. In simpler terms, OpenCL provides a standard interface for programmers to execute the &lt;strong&gt;same&lt;/strong&gt; code across &lt;strong&gt;multiple&lt;/strong&gt; devices, be it a CPU or a GPU or &lt;strong&gt;any&lt;/strong&gt; other accelerator.&lt;/p&gt;

&lt;p&gt;It comprises of the OpenCL standard which is maintained by &lt;a href="https://www.khronos.org/opencl/"&gt;Khronos&lt;/a&gt;, and implemented by the various hardware &lt;strong&gt;manufacturers&lt;/strong&gt; and by the &lt;strong&gt;open source community&lt;/strong&gt; across a wide variety of devices.&lt;/p&gt;

&lt;p&gt;Most modern devices all support OpenCL in some format or the other. &lt;strong&gt;Intel/Nvidia&lt;/strong&gt; for example provide their own &lt;strong&gt;propietary&lt;/strong&gt; implementations. On the other hand, &lt;strong&gt;POCL&lt;/strong&gt; an &lt;strong&gt;open source&lt;/strong&gt; project provides implementations for those that dont have actively maintained propietary ones, like &lt;strong&gt;AMD&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id="why-opencl"&gt;Why OpenCL?&lt;/h2&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL versus CUDA" src="https://deadspheroid.github.io/my-blog/assets/img/cl-cuda.jpeg" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;Unlike certain &lt;strong&gt;propietary&lt;/strong&gt; frameworks &lt;em&gt;cough&lt;/em&gt; &lt;a href="https://developer.nvidia.com/about-cuda"&gt;CUDA&lt;/a&gt; &lt;em&gt;cough&lt;/em&gt;, OpenCL is not constrained to any particular &lt;strong&gt;manufacturer&lt;/strong&gt;. You can target &lt;strong&gt;any GPU/CPU&lt;/strong&gt; as long as you get the OpenCL implementation for that device. This is made easy thanks to projects like &lt;a href="https://portablecl.org/"&gt;POCL&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The performance of &lt;strong&gt;CUDA versus OpenCL&lt;/strong&gt; is heavily debated and leans towards CUDA for Nvidia hardware, but the difference depends on the use case and isn’t too much of a concern as compared to the way they are used.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;downside&lt;/strong&gt; of OpenCL is the &lt;strong&gt;smaller&lt;/strong&gt; community and the lack of many &lt;strong&gt;modern features&lt;/strong&gt; that CUDA brings.&lt;/p&gt;

&lt;blockquote&gt;
The inner workings of OpenCL, how I managed to set it up, how the OpenCL C API works is another long story and is deserving of its own post.
&lt;/blockquote&gt;

&lt;h2 id="kickoff-with-gnuastro"&gt;Kickoff with Gnuastro&lt;/h2&gt;

&lt;p&gt;The first goal for the project was to figure out a way to &lt;strong&gt;integrate&lt;/strong&gt; OpenCL with the Gnuastro build system.&lt;/p&gt;

&lt;p&gt;Gnuastro like many other free software uses the &lt;strong&gt;GNU Build System&lt;/strong&gt; also called &lt;a href="https://www.gnu.org/software/automake/faq/autotools-faq.html"&gt;GNU Autotools&lt;/a&gt;&lt;/p&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="GNU Autotools" src="https://deadspheroid.github.io/my-blog/assets/img/gnu-logo.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;three&lt;/strong&gt; major components of Autotools are:&lt;/p&gt;

&lt;h4 id="autoconf"&gt;Autoconf&lt;/h4&gt;
&lt;p&gt;At the heart of Autotools, we have &lt;a href="https://www.gnu.org/software/autoconf/"&gt;Autoconf&lt;/a&gt;, which generates a &lt;strong&gt;single&lt;/strong&gt; &lt;code class="language-plaintext highlighter-rouge"&gt;configure&lt;/code&gt; &lt;strong&gt;script&lt;/strong&gt; from a &lt;code class="language-plaintext highlighter-rouge"&gt;configure.ac&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;This &lt;code class="language-plaintext highlighter-rouge"&gt;configure&lt;/code&gt; script scans the &lt;strong&gt;environment&lt;/strong&gt; for various files and &lt;strong&gt;libraries&lt;/strong&gt;, specific versions of them, the &lt;strong&gt;hardware&lt;/strong&gt; being used, and more. Then, it &lt;strong&gt;configures&lt;/strong&gt; the build of the project in certain ways enabling/disabling certain parts depending on what was found and what wasnt.&lt;/p&gt;

&lt;p&gt;In this way, the &lt;strong&gt;portability&lt;/strong&gt; of any project can be ensured by simply distributing the &lt;strong&gt;configure&lt;/strong&gt; script, along with the &lt;code class="language-plaintext highlighter-rouge"&gt;Makefile.in&lt;/code&gt;s.&lt;/p&gt;

&lt;h4 id="automake"&gt;Automake&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://www.gnu.org/software/automake/"&gt;Automake&lt;/a&gt; makes use of information found by &lt;code class="language-plaintext highlighter-rouge"&gt;configure&lt;/code&gt; and &lt;strong&gt;generates&lt;/strong&gt; the &lt;code class="language-plaintext highlighter-rouge"&gt;Makefile&lt;/code&gt;s necessary to &lt;strong&gt;build&lt;/strong&gt; the project.&lt;/p&gt;

&lt;p&gt;To be more precise, it &lt;strong&gt;parses&lt;/strong&gt; &lt;code class="language-plaintext highlighter-rouge"&gt;Makefile.am&lt;/code&gt;s into &lt;code class="language-plaintext highlighter-rouge"&gt;Makefile.in&lt;/code&gt;s which are in turn &lt;strong&gt;parsed&lt;/strong&gt; by &lt;code class="language-plaintext highlighter-rouge"&gt;configure&lt;/code&gt; to produce the final &lt;code class="language-plaintext highlighter-rouge"&gt;Makefile&lt;/code&gt;s. Automake also performs &lt;strong&gt;automatic dependency tracking&lt;/strong&gt;, so that recompilling isn’t done unless &lt;strong&gt;required&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;All you have to do, is specify the &lt;strong&gt;name&lt;/strong&gt; and each of the &lt;strong&gt;sources&lt;/strong&gt; involved in the library/binary, and Automake does the rest.&lt;/p&gt;

&lt;h4 id="libtool"&gt;Libtool&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://www.gnu.org/software/libtool/"&gt;Libtool&lt;/a&gt; is responsible for abstracting the &lt;strong&gt;library&lt;/strong&gt; creation process, since different platforms handle static/dynamic libraries &lt;strong&gt;differently&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
I mainly worked with Automake and Autoconf during integration and didn't really touch Libtool.
&lt;/blockquote&gt;

&lt;h2 id="stepping-into-integration"&gt;Stepping into Integration&lt;/h2&gt;

&lt;h4 id="inside-configureac"&gt;Inside &lt;code class="language-plaintext highlighter-rouge"&gt;configure.ac&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Without getting into detail, when checking for the &lt;strong&gt;presence&lt;/strong&gt; of OpenCL, it suffices to check for &lt;code class="language-plaintext highlighter-rouge"&gt;libOpenCL.so&lt;/code&gt; and the &lt;code class="language-plaintext highlighter-rouge"&gt;CL.h&lt;/code&gt; header file.&lt;/p&gt;

&lt;p&gt;That is, Gnuastro should be able to &lt;strong&gt;include&lt;/strong&gt; the OpenCL header file to use its C API, and then later &lt;strong&gt;link&lt;/strong&gt; against the OpenCL library.&lt;/p&gt;

&lt;p&gt;Luckily for us, &lt;a href="https://www.gnu.org/software/gnulib/"&gt;Gnulib&lt;/a&gt; provides a simple &lt;code class="language-plaintext highlighter-rouge"&gt;AC_LIB_HAVE_LINKFLAGS&lt;/code&gt; &lt;a href="https://www.gnu.org/software/gnulib/manual/html_node/Searching-for-Libraries.html"&gt;macro&lt;/a&gt; which takes as input, a library &lt;strong&gt;name&lt;/strong&gt; and a &lt;strong&gt;test code&lt;/strong&gt; and tries to find the &lt;strong&gt;library&lt;/strong&gt; and &lt;strong&gt;compile/link&lt;/strong&gt; the test code.&lt;/p&gt;

&lt;p&gt;Upon successfully executing, it &lt;strong&gt;sets certain variables&lt;/strong&gt;, so we can modify further building on the basis of &lt;strong&gt;finding OpenCL&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="language-bash highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;AC_LIB_HAVE_LINKFLAGS&lt;span class="o"&gt;([&lt;/span&gt;OpenCL], &lt;span class="o"&gt;[]&lt;/span&gt;, &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="c"&gt;#include &amp;lt;CL/cl.h&amp;gt;])&lt;/span&gt;
AS_IF&lt;span class="o"&gt;([&lt;/span&gt;&lt;span class="nb"&gt;test&lt;/span&gt; &lt;span class="s2"&gt;"x&lt;/span&gt;&lt;span class="nv"&gt;$LIBOPENCL&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; x],
&lt;span class="o"&gt;[&lt;/span&gt;
&lt;span class="k"&gt;if &lt;/span&gt;successfull ...
&lt;span class="o"&gt;]&lt;/span&gt;,
&lt;span class="o"&gt;[&lt;/span&gt;
&lt;span class="nv"&gt;LIBS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$LIBOPENCL&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="nv"&gt;$LIBS&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;span class="nv"&gt;has_ocl&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;if &lt;/span&gt;unsuccessfull ...
&lt;span class="o"&gt;])&lt;/span&gt;
AM_CONDITIONAL&lt;span class="o"&gt;([&lt;/span&gt;COND_HASOPENCL], &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;test&lt;/span&gt; &lt;span class="s2"&gt;"x&lt;/span&gt;&lt;span class="nv"&gt;$has_ocl&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"x1"&lt;/span&gt;&lt;span class="o"&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;After making these modifications to &lt;code class="language-plaintext highlighter-rouge"&gt;configure.ac&lt;/code&gt;, we can now &lt;strong&gt;test&lt;/strong&gt; whether OpenCL was found inside the various &lt;code class="language-plaintext highlighter-rouge"&gt;Makefile.am&lt;/code&gt;s and accordingly change the &lt;strong&gt;build&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 id="inside-makefileam"&gt;Inside &lt;code class="language-plaintext highlighter-rouge"&gt;Makefile.am&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Now, we can use the &lt;strong&gt;variable&lt;/strong&gt; we set previously in &lt;code class="language-plaintext highlighter-rouge"&gt;configure.ac&lt;/code&gt; and either include or exclude the OpenCL modules from being compiled and included in the &lt;strong&gt;library&lt;/strong&gt;.&lt;/p&gt;

&lt;div class="language-bash highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="k"&gt;if &lt;/span&gt;COND_HASOPENCL
&lt;span class="si"&gt;$(&lt;/span&gt;info &lt;span class="s2"&gt;"Found OpenCL"&lt;/span&gt;&lt;span class="si"&gt;)&lt;/span&gt;
MAYBE_CL &lt;span class="o"&gt;=&lt;/span&gt; cl_utils.c
MAYBE_CL_H &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="si"&gt;$(&lt;/span&gt;headersdir&lt;span class="si"&gt;)&lt;/span&gt;/cl_utils.h
MAYBE_CONVOLVE_CL &lt;span class="o"&gt;=&lt;/span&gt; cl_convolve.c
&lt;span class="k"&gt;else&lt;/span&gt;
&lt;span class="si"&gt;$(&lt;/span&gt;info &lt;span class="s2"&gt;"What is Opencl?"&lt;/span&gt;&lt;span class="si"&gt;)&lt;/span&gt;
endif
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class="language-bash highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;libgnuastro_la_SOURCES &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="si"&gt;$(&lt;/span&gt;MAYBE_NUMPY_C&lt;span class="si"&gt;)&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="si"&gt;$(&lt;/span&gt;MAYBE_WCSDISTORTION&lt;span class="si"&gt;)&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="si"&gt;$(&lt;/span&gt;MAYBE_CL&lt;span class="si"&gt;)&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="si"&gt;$(&lt;/span&gt;MAYBE_CONVOLVE_CL&lt;span class="si"&gt;)&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
arithmetic.c &lt;span class="se"&gt;\&lt;/span&gt;
arithmetic-and.c &lt;span class="se"&gt;\&lt;/span&gt;
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Additionally, we need to &lt;strong&gt;save&lt;/strong&gt; this variable in Gnuastro’s &lt;code class="language-plaintext highlighter-rouge"&gt;config.h&lt;/code&gt; file for later use to &lt;strong&gt;prevent&lt;/strong&gt; other modules from mistakenly including the OpenCL ones incase OpenCL was &lt;strong&gt;not compiled&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id="checking-for-build-system-yes"&gt;checking for build system… yes&lt;/h2&gt;
&lt;p&gt;Now when someone builds Gnuastro, if OpenCL is &lt;strong&gt;present&lt;/strong&gt; on their system, then the OpenCL relevant files are &lt;strong&gt;compiled and included in the library&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;On the other hand, if OpenCL is &lt;strong&gt;absent&lt;/strong&gt;, then the library is &lt;strong&gt;built as normal&lt;/strong&gt;, as if OpenCL never existed.&lt;/p&gt;

&lt;p&gt;Finally, we can get started with the &lt;strong&gt;actual&lt;/strong&gt; OpenCl part and we’ll have a look at Image Convolution(astconvolve) in the next post…&lt;/p&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2024/06/20240609_0045_deadspheroid/</guid><pubDate>Sat, 08 Jun 2024 23:45:00 GMT</pubDate></item><item><title>OpenCL, meet the Gnuastro Build System</title><link>http://openastronomy.org/Universe_OA/posts/2024/06/20240609_0000_deadspheroid/</link><dc:creator>DeadSpheroid</dc:creator><description>&lt;p class="intro"&gt;&lt;span class="dropcap"&gt;I&lt;/span&gt;n this post, I hope to summarize the work done so far towards my GSoC project in integrating OpenCL with the Gnuastro library and my relatively limited understanding of OpenCL.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2024/06/20240609_0000_deadspheroid/</guid><pubDate>Sat, 08 Jun 2024 23:00:00 GMT</pubDate></item></channel></rss>