<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts about gsoc2024)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/categories/cat_gsoc2024.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Tue, 13 Aug 2024 01:06:49 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Implementing the NIST database</title><link>http://openastronomy.org/Universe_OA/posts/2024/08/20240812_0000_code29563/</link><dc:creator>code29563</dc:creator><description>&lt;ul&gt;
&lt;li&gt;The Einstein A coefficient is now used directly for calculating the non-equilibrium linestrength, given that it is calculated anyway for non-equilibrium spectra where it isn’t already present, rather than removing the temperature-dependent component of the reference linestrength, which was found to result in some atomic spectra not appearing. This also removes the need to calculate the reference linestrength for databanks where it’s not already present.&lt;/li&gt;
&lt;li&gt;Removed some redundnant code and miscellaneous fixes and improvements.&lt;/li&gt;
&lt;!-- TEASER_END --&gt;
&lt;li&gt;Fixed the documentation for many parts of the new code for atomic spectra so the formatting appears correct on Read the Docs.&lt;/li&gt;
&lt;li&gt;The pull request for the implementation of the Kurucz database has been merged&lt;/li&gt;
&lt;li&gt;Work has started on adding support for the NIST atomic database and it is currently at a stage where it produces working spectra.&lt;/li&gt;
&lt;/ul&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2024/08/20240812_0000_code29563/</guid><pubDate>Sun, 11 Aug 2024 23:00:00 GMT</pubDate></item><item><title>Bidirectional Recurrent Neural Networks</title><link>http://openastronomy.org/Universe_OA/posts/2024/08/20240811_1127_lucasmg18/</link><dc:creator>Lucas Martin Garcia</dc:creator><description>&lt;h5&gt;Introduction&lt;/h5&gt;&lt;p&gt;In our ongoing objective to enhance the accuracy of Active Galactic Nuclei (AGN) light curve interpolation, we've previously explored various traditional and machine learning methods. Building on this foundation, this post introduces a sophisticated approach involving a Bidirectional Recurrent Neural Network (BRNN) coupled with an interpretative neural network layer, aimed at capturing the dynamics of AGN light curves more effectively.&lt;/p&gt;
&lt;h5&gt;Understanding Bidirectional Recurrent Neural Networks (BRNNs)&lt;/h5&gt;&lt;p&gt;BRNNs are an extension of traditional Recurrent Neural Networks (RNNs), designed to improve model performance by processing data in both forward and reverse directions. This dual-path architecture allows the network to retain information from both past and future contexts simultaneously, which is particularly beneficial for predicting sequences with complex dependencies, like those found in AGN light curves.&lt;/p&gt;
&lt;h5&gt;Implementing an Interpretative Neural Network Layer&lt;/h5&gt;&lt;p&gt;To make the outputs of the BRNN more comprehensible and useful, we integrate an additional neural network layer specifically for filling missing gaps. This layer translates the complex, non-linear relationships learned by the BRNN into clearer, more interpretable patterns. &lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;h5&gt;Results and Insights&lt;/h5&gt;&lt;p&gt;While the results are improving with the training of the model, there is still room for further improvement and refinement.&lt;/p&gt;
&lt;h5&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgS03-X5BldVm_XayVKUn4pPgNXMjlqocqkNVwbjWLA80Idcmpd5LGJX4ordaG2I02c2-bxQfbfVRusO5g7TArKHyJd6MmeWsVDZn0h9tF-rRZPrgrgUm85yGANSbZLpiIn7vPe3Xgs2Bi0XiwLLWy2V0vZGAsh1hB3Rh_ARZbGBt0IBC6ZGd3lZ5B8-pjS/s1400/Test_Set_Prediction%20(2).png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="659" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgS03-X5BldVm_XayVKUn4pPgNXMjlqocqkNVwbjWLA80Idcmpd5LGJX4ordaG2I02c2-bxQfbfVRusO5g7TArKHyJd6MmeWsVDZn0h9tF-rRZPrgrgUm85yGANSbZLpiIn7vPe3Xgs2Bi0XiwLLWy2V0vZGAsh1hB3Rh_ARZbGBt0IBC6ZGd3lZ5B8-pjS/w920-h659/Test_Set_Prediction%20(2).png" width="920"&gt;&lt;/a&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;br&gt;&lt;/div&gt;Future Directions&lt;br&gt;&lt;/h5&gt;&lt;p&gt;While the current model represents a significant advancement, there is room for further enhancement. Future work will explore the integration of additional data types and testing more complex neural network architectures to refine the predictions further.&lt;/p&gt;
&lt;h5&gt;Conclusion&lt;/h5&gt;&lt;p&gt;The integration of BRNNs with an interpretative neural network layer marks a significant leap forward in our ability to interpolate AGN light curve data accurately. The idea of using both future time sequences and past data could improve the understanding of the ML models and predict the missing gaps better.&lt;/p&gt;</description><category>irsa-fornax</category><guid>http://openastronomy.org/Universe_OA/posts/2024/08/20240811_1127_lucasmg18/</guid><pubDate>Sun, 11 Aug 2024 10:27:00 GMT</pubDate></item><item><title>Changing the plotting methods</title><link>http://openastronomy.org/Universe_OA/posts/2024/08/20240805_1605_kartikmandar/</link><dc:creator>Kartik Mandar</dc:creator><description>&lt;p&gt; So the recoding and redesign is done. But we were discussing about how we are plotting things in dashboard and wanted to have floatpanels for doing so.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2024/08/20240805_1605_kartikmandar/</guid><pubDate>Mon, 05 Aug 2024 15:05:00 GMT</pubDate></item><item><title>Implementing non-equilibrium spectra</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240729_0000_code29563/</link><dc:creator>code29563</dc:creator><description>&lt;ul&gt;
&lt;li&gt;Support has been added for non-equilibrium spectra. Comparisons with SpectraPlot are still showing discrepancies, the source of which is not yet resolved.&lt;/li&gt;
&lt;li&gt;References have been added for the Kurucz databank&lt;/li&gt;
&lt;!-- TEASER_END --&gt;
&lt;li&gt;Miscellaneous minor improvements and fixes in the code and docs&lt;/li&gt;
&lt;/ul&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240729_0000_code29563/</guid><pubDate>Sun, 28 Jul 2024 23:00:00 GMT</pubDate></item><item><title>Towards New Speeds</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240728_2230_deadspheroid/</link><dc:creator>DeadSpheroid</dc:creator><description>&lt;p class="intro"&gt;In this post, I hope to illustrate how GPU's actually accelerate parallel operations&lt;/p&gt;

&lt;h2 id="lets-get-started"&gt;Let’s get started&lt;/h2&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Firstly, how do GPU’s really work? Well, at a lower level, the architecture looks something like this…&lt;/p&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="GPU Architecture" src="https://deadspheroid.github.io/my-blog/assets/img/gpu-arch.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;Focus on the differences between the two, CPUs have few, very highly specialised and refined cores.
GPUs on the other hand have hundreds of more primitive, yet powerful cores.&lt;/p&gt;

&lt;p&gt;This is the reason why GPUs can’t do I/O and stuff, its because they are meant solely for mathematical operations.&lt;/p&gt;

&lt;h2 id="but-whats-the-point-of-so-many-cores"&gt;But what’s the point of so many cores??&lt;/h2&gt;
&lt;p&gt;This is where SIMD or Single Instruction Multiple Data processing comes in handy. See, many operations(image and volume ones notoriously) are extremely taxing for the CPU to perform.
Imagine being part of a team of 8/16 people, stamping a sheet of paper, except you have 10^6 sheets to stamp.
Even if you took 1 ms/sheet, it would still take you insanely long to finish your jobs. And I mean, you have better things to do right?&lt;/p&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Map/Unmap Buffers" src="https://deadspheroid.github.io/my-blog/assets/img/simd.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;Well what if you could hire 10^3 people for cheap and give each of them a sheet of paper to stamp? Wouldn’t that greatly speed things up?
This is the core idea behind SIMD processing, you have an operation that is to be done thousands of times, over and over again, just on different data.&lt;/p&gt;

&lt;p&gt;So you give each GPU core a part of the data and let it do the job, since the GPU has so many cores, it’s not really a problem.&lt;/p&gt;

&lt;h2 id="so-whats-the-catch"&gt;So whats the catch?&lt;/h2&gt;
&lt;p&gt;Continuing the stamping sheet analogy, giving the sheets to 10^3 workers is challenging and time-consuming. In other words, data transfer is a problem, since GPU VRAM is separate from CPU RAM&lt;/p&gt;

&lt;p&gt;Additionally, parallel programming forces you to think in an additional dimension, because your code is being executed 100s of times at the same time. This makes writing efficient kernels difficult, since branching is frowned on at the GPU, and you need some way of preventing data races.&lt;/p&gt;

&lt;p&gt;That is to say nothing of the increased power consumption and high cost of hardware.&lt;/p&gt;

&lt;p&gt;Despite all of this however, GPUs are still heavily favoured, because the speed-up they offer greatly outweights the rest.&lt;/p&gt;

&lt;h2 id="well-how-do-i-use-my-gpu"&gt;Well, how do I use my GPU?&lt;/h2&gt;
&lt;p&gt;Let’s take an example, hopefully youre already familiar with image convolution. If not, the image below explains it well&lt;/p&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Map/Unmap Buffers" src="https://deadspheroid.github.io/my-blog/assets/img/convol.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;For each iteration, we center the kernel over a pixel, multiply the overlapping values, add them up and then (optionally)divide by sum of kernel values.
On CPU? For an m x n image and a k x k kernel, this is an O(mn * k^2) operation, meaning the time taken for convolution for a given data size increases tremendously.&lt;/p&gt;

&lt;p&gt;This can be greatly lessened using a GPU.&lt;/p&gt;

&lt;p&gt;But for that, we need to first identify the stamping task here, the tedious computation which is easy to do, but time consuming.&lt;/p&gt;

&lt;h2 id="image-convolution"&gt;Image Convolution&lt;/h2&gt;
&lt;p&gt;If you thought of the matmul operation happening at each pixel, you’d be correct!
This is one of the easiest ways to parallelise convolution. We’re repeatedly performing matrix multiplication, with different pixels at the center each time&lt;/p&gt;

&lt;p&gt;Therefore SIMD can be applied here, the instruction being matmul and the data being all the pixels.&lt;/p&gt;

&lt;p&gt;On a lower level, this is represented by the diffferent &lt;code class="language-plaintext highlighter-rouge"&gt;thread_id&lt;/code&gt; given to each thread on the GPU. This id represents a one to one mapping of an integer to input data elements.
Incase of Images, it is the pixel number that is at the center.&lt;/p&gt;

&lt;p&gt;Here’s an example of how convolution can be parallelized, note that this is not the most efficient and is nowhere near perfect, but it is simple enough to understand.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;__kernel void
convolution(
__global float *image_array, __global size_t *image_dsize,
__global float *kernell_array, __global size_t *kernell_dsize,

__global float *output) {

/* get the image and kernel size */
int image_height = image_dsize[0];
int image_width = image_dsize[1];
int kernell_height = kernell_dsize[0];
int kernell_width = kernell_dsize[1];

/* get the local group id */
int id = get_global_id(0);
int row = id / image_width;
int col = id % image_width;

if (row &amp;lt; image_height &amp;amp;&amp;amp; col &amp;lt; image_width) {

float sum = 0;
/* matmul operation as normal*/
for (int y = -kernell_height / 2; y &amp;lt;= kernell_height / 2; y++) {
for (int x = -kernell_width / 2; x &amp;lt;= kernell_width / 2; x++) {
if (row + y &amp;gt;= 0 &amp;amp;&amp;amp; row + y &amp;lt; image_height &amp;amp;&amp;amp; col + x &amp;gt;= 0 &amp;amp;&amp;amp;
col + x &amp;lt; image_width) {
sum += (image_array[(row + y) * image_width + col + x] *
kernell_array[(y + kernell_height / 2) * kernell_width + x +
kernell_width / 2]);
}
}
}
output[row * image_width + col] = sum;
}
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="a-new-outlook"&gt;A new outlook&lt;/h2&gt;
&lt;p&gt;Of course, the world would be a lovely place if everything could be parallelised as easily as this. Realistically, parallelizing these operations is hard, but you have tools like local groups, barriers, etc to help you out!&lt;/p&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240728_2230_deadspheroid/</guid><pubDate>Sun, 28 Jul 2024 21:30:00 GMT</pubDate></item><item><title>GSoC [Week 06-07] Progress</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240728_1014_viciouseagle03/</link><dc:creator>ViciousEagle03</dc:creator><description>&lt;p&gt;&lt;img alt="img" src="https://viciouseagle03.github.io/images/mid_term.png"&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This blog post covers all the work done in the sixth week of Google Summer of Code.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;/blockquote&gt;
&lt;p&gt;After having developed the serialization logic for NDCube with wcs as &lt;code&gt;gWCS&lt;/code&gt;, the next step was to extend this support to handle the serialization of NDCube where the wcs attribute is &lt;code&gt;astropy.wcs.WCS&lt;/code&gt;. This week my primary focus has been on enabling the serialization of &lt;code&gt;astropy.wcs.WCS&lt;/code&gt; objects to ASDF. This task involves adding the necessary serialization logic to the asdf-astropy repository.&lt;/p&gt;
&lt;h4 id="discussions-on-wcs-serialization"&gt;Discussions on WCS Serialization&lt;/h4&gt;
&lt;p&gt;We had a discussion about the process of serializing WCS objects and covered the following points:&lt;/p&gt;
&lt;h5 id="complex-wcs-types"&gt;Complex WCS Types:&lt;/h5&gt;
&lt;p&gt;WCS types like tabular and distortion ones are tricky because they involve data tables. Handling these types requires a more sophisticated approach.&lt;/p&gt;
&lt;h5 id="approach-discussion"&gt;Approach Discussion:&lt;/h5&gt;
&lt;p&gt;We discussed serializing a HDUList object or using &lt;code&gt;WCS.to_hdu&lt;/code&gt; for the complex WCS types but that seems pretty complex for a first attempt. We agreed on initially not supporting these complex WCS types and just using &lt;code&gt;WCS.to_header()&lt;/code&gt; for now for supporting the serialization of the basic WCS objects.&lt;/p&gt;
&lt;h4 id="whats-new"&gt;What’s new&lt;/h4&gt;
&lt;p&gt;So after my PR gets merged asdf-astropy would support the serialization of the &lt;code&gt;astropy.wcs.WCS&lt;/code&gt; objects to ASDF.
Ideally we would want to detect tabular and distortion WCS types and throw an error if they come up. This way, we’re clear about what’s supported and we agreed on revisiting this part and in the future and to extend this to support the serialization of the complex WCS objects.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Serialized simple &lt;code&gt;astropy.wcs.WCS&lt;/code&gt; object to ASDF&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;#ASDF 1.0.0
#ASDF_STANDARD 1.5.0
%YAML 1.1
%TAG ! tag:stsci.edu:asdf/
--- !core/asdf-1.1.0
asdf_library: !core/software-1.0.0 {author: The ASDF Developers, homepage: 'http://github.com/asdf-format/asdf',
name: asdf, version: 3.0.1}
history:
extensions:
- !core/extension_metadata-1.0.0
extension_class: asdf.extension._manifest.ManifestExtension
extension_uri: asdf://asdf-format.org/core/extensions/core-1.5.0
software: !core/software-1.0.0 {name: asdf, version: 3.0.1}
- !core/extension_metadata-1.0.0
extension_class: asdf.extension._manifest.ManifestExtension
extension_uri: asdf://astropy.org/astropy/extensions/astropy-1.0.0
software: !core/software-1.0.0 {name: asdf-astropy, version: 0.6.1.dev10+gdab5b4d.d20240723}
fits: !&amp;lt;tag:astropy.org:astropy/fits/fitswcs-1.0.0&amp;gt;
header: {CDELT1: 0.4, CDELT2: 2.0e-11, CDELT3: 0.0055555555555556, CDELT4: 0.0013888888888889,
CRPIX1: 0.0, CRPIX2: 0.0, CRPIX3: 0.0, CRPIX4: 5.0, CRVAL1: 0.0, CRVAL2: 0.0,
CRVAL3: 0.0, CRVAL4: 0.0, CTYPE1: TIME, CTYPE2: WAVE, CTYPE3: HPLT-TAN, CTYPE4: HPLN-TAN,
CUNIT1: min, CUNIT2: m, CUNIT3: deg, CUNIT4: deg, DATEREF: '2020-01-01T00:00:00',
LATPOLE: 0.0, LONPOLE: 180.0, MJDREF: 58849.0, WCSAXES: 4}
...
&lt;/code&gt;&lt;/pre&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240728_1014_viciouseagle03/</guid><pubDate>Sun, 28 Jul 2024 09:14:09 GMT</pubDate></item><item><title>Issue resolved</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240725_1809_kartikmandar/</link><dc:creator>Kartik Mandar</dc:creator><description>&lt;p&gt; The problem with classes was resolved by making factory functions to encase them in, and then they were not conflicting with each other. &lt;/p&gt;
&lt;!-- TEASER_END --&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240725_1809_kartikmandar/</guid><pubDate>Thu, 25 Jul 2024 17:09:00 GMT</pubDate></item><item><title>Enhancing SOAR Queries: Improved Error Handling and Support for Distance-Based Filtering</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240723_1650_nucleongodx/</link><dc:creator>Manit Singh</dc:creator><description>&lt;h4&gt;Improved Error Handling and Support for Distance-Based Filtering&lt;/h4&gt;&lt;h4&gt;Introduction&lt;/h4&gt;&lt;p&gt;Over the past few weeks, I’ve been working on addressing and enhancing certain functionalities within the sunpy-soar package. This post delves into the two main improvements I’ve implemented: better error handling for server downtime and the introduction of support for distance-based query filtering.&lt;/p&gt;
&lt;h4&gt;Improved Error Handling for Server Downtime&lt;/h4&gt;&lt;p&gt;Previously, when the SOAR server was down, a generic JSONDecodeError would be raised. This was less than ideal as it did not provide a clear indication of what the actual issue was. To improve this, I worked on implementing a more descriptive error message that would be raised in such scenarios.&lt;/p&gt;
&lt;pre&gt;r = requests.get(f"{tap_endpoint}/sync", params=payload)&lt;br&gt;try:&lt;br&gt;    response_json = r.json()&lt;br&gt;except JSONDecodeError:&lt;br&gt;    msg = "Server returned an invalid JSON response. The SOAR server may be down or not functioning correctly."&lt;br&gt;    raise RuntimeError(msg)&lt;/pre&gt;&lt;p&gt;With this change, users will now see a RuntimeError with a clear message indicating that the server may be down or not functioning correctly, which makes troubleshooting much easier.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;h4&gt;Implementing Support for Different REQUEST Types&lt;/h4&gt;&lt;p&gt;After resolving the error handling issue, I moved on to implementing support for different REQUEST types. Sunpy-soar initially only supported the doQuery REQUEST type. However, there was a need to expand this to support the doQueryFilteredByDistance REQUEST type as well.&lt;/p&gt;
&lt;h4&gt;What is doQueryFilteredByDistance?&lt;/h4&gt;&lt;p&gt;The doQueryFilteredByDistance REQUEST type allows for filtering the query results based on a specified distance range. The main change here is setting the REQUEST parameter to doQueryFilteredByDistance and appending &amp;amp;DISTANCE(distancemin,distancemax) to the query.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example Query:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;SELECT * FROM soar.v_sc_data_item WHERE instrument='MAG' AND level='LL02'&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;With Distance Filtering:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;SELECT * FROM soar.v_sc_data_item WHERE instrument='MAG' AND level='LL02' AND DISTANCE(0.28,0.49)&lt;/pre&gt;&lt;h4&gt;Conclusion&lt;/h4&gt;&lt;p&gt;These enhancements significantly improve the functionality and user experience of the sunpy-soar package. The improved error handling provides clearer feedback to users when the SOAR server is down, and the support for doQueryFilteredByDistance allows for more refined queries based on distance, opening up new possibilities for data analysis.&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=79c57af30ffc" width="1"&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240723_1650_nucleongodx/</guid><pubDate>Tue, 23 Jul 2024 15:50:13 GMT</pubDate></item><item><title>Blog 4: Testing the New Coalignment with a Catch</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240722_1859_deus1704/</link><dc:creator>Deus1704</dc:creator><description>&lt;p&gt;Now that we’ve agreed on the structure of the co-alignment API and also laid down its foundation, all that’s left is to validate it through actual tests and generate some gallery examples.&lt;/p&gt;
&lt;h3 id="first-try-with-coaligning-eis-raster-with-aia-map"&gt;First try with coaligning EIS raster with AIA map&lt;/h3&gt;
&lt;p&gt;Let’s take a closer look at the EIS raster first. I found an AIA image close to the &lt;code&gt;date_average&lt;/code&gt; of the raster.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="EIS raster" src="https://deus1704.vercel.app/images/original_eis.jpeg"&gt;&lt;/th&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="AIA Full-disc image" src="https://deus1704.vercel.app/images/aia_near_raster_avg.jpeg"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;EIS raster&lt;/td&gt;
&lt;td style="text-align: center;"&gt;AIA Full-disc image&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="Updated EIS" src="https://deus1704.vercel.app/images/updated_eis.png"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;Updated EIS&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;At first glance, the results seemed promising, but a more detailed analysis revealed some discrepancies.&lt;/p&gt;
&lt;p&gt;The updated WCS metadata looked fine at first, but on closer inspection, it wasn’t entirely correct. We’ll dive into the specifics later in this blog. For now, let’s discuss why it might look correct at a glance. How does a common user check if the maps are aligned? By overlaying them and checking the overlaps!&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="EIS overlaid on AIA" src="https://deus1704.vercel.app/images/eis_overlaid_aia.png"&gt;&lt;/th&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="Zoomed" src="https://deus1704.vercel.app/images/eis_overlaid_aia_zoomed.png"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;EIS overlaid on AIA&lt;/td&gt;
&lt;td style="text-align: center;"&gt;Zoomed&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This visual inspection might convince some that the method works, but it’s far from accurate. We proved this by highlighting the bright regions and focusing on the actual overlaps.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="EIS contours overlaid on AIA" src="https://deus1704.vercel.app/images/old_contours.png"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;EIS contours overlaid on AIA&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This showed us that something was wrong with either the way we were updating the metadata or the co-alignment method. While discussing this, we realized that an assumption in the match_template method was that the maps should have the same type of WCS.&lt;/p&gt;
&lt;h3 id="the-celestial-fix"&gt;The Celestial Fix&lt;/h3&gt;
&lt;p&gt;In our initial approach, we focused on adjusting the CRPIX values instead of the CRVAL values. CRPIX specifies the position of the reference pixel in the image, shifting the image in pixel space without correcting the world coordinates directly. This method led to apparent alignment issues because it didn’t address the celestial coordinate system. After consultation, we realized that adjusting CRVAL, which defines the world coordinates of the reference pixel, is essential. This adjustment ensures that the reference points align correctly in world coordinate space, maintaining consistent mapping between pixel and celestial coordinates.&lt;/p&gt;
&lt;p&gt;Furthermore, for accurate co-alignment, the observers (instruments) should be within a tolerable angular separation to minimize parallax effects. When observers are too far apart, solar features can appear differently due to relative positions, complicating alignment. By correcting CRVAL values and considering angular separation, we achieved precise co-alignment, as evidenced by the corrected overlay of EIS contours on the AIA image, allowing for reliable scientific analysis.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="EIS contours overlaid on AIA (corrected)" src="https://deus1704.vercel.app/images/fixed_eis.jpeg"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;EIS contours overlaid on AIA (corrected)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240722_1859_deus1704/</guid><pubDate>Mon, 22 Jul 2024 17:59:31 GMT</pubDate></item><item><title>New issue propped up</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240718_1634_kartikmandar/</link><dc:creator>Kartik Mandar</dc:creator><description>&lt;p&gt; When changing the whole architecture, a new issue has propped. An initialised object of the class can not be initialised again. So I am not able to revert back the home UI back dynamically. &lt;/p&gt;
&lt;!-- TEASER_END --&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240718_1634_kartikmandar/</guid><pubDate>Thu, 18 Jul 2024 15:34:00 GMT</pubDate></item></channel></rss>