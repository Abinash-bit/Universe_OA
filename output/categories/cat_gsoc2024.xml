<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts about gsoc2024)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/categories/cat_gsoc2024.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sat, 10 Aug 2024 01:05:56 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Changing the plotting methods</title><link>http://openastronomy.org/Universe_OA/posts/2024/08/20240805_1605_kartikmandar/</link><dc:creator>Kartik Mandar</dc:creator><description>&lt;p&gt; So the recoding and redesign is done. But we were discussing about how we are plotting things in dashboard and wanted to have floatpanels for doing so.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2024/08/20240805_1605_kartikmandar/</guid><pubDate>Mon, 05 Aug 2024 15:05:00 GMT</pubDate></item><item><title>Implementing non-equilibrium spectra</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240729_0000_code29563/</link><dc:creator>code29563</dc:creator><description>&lt;ul&gt;
&lt;li&gt;Support has been added for non-equilibrium spectra. Comparisons with SpectraPlot are still showing discrepancies, the source of which is not yet resolved.&lt;/li&gt;
&lt;li&gt;References have been added for the Kurucz databank&lt;/li&gt;
&lt;!-- TEASER_END --&gt;
&lt;li&gt;Miscellaneous minor improvements and fixes in the code and docs&lt;/li&gt;
&lt;/ul&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240729_0000_code29563/</guid><pubDate>Sun, 28 Jul 2024 23:00:00 GMT</pubDate></item><item><title>Towards New Speeds</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240728_2230_deadspheroid/</link><dc:creator>DeadSpheroid</dc:creator><description>&lt;p class="intro"&gt;In this post, I hope to illustrate how GPU's actually accelerate parallel operations&lt;/p&gt;

&lt;h2 id="lets-get-started"&gt;Let’s get started&lt;/h2&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Firstly, how do GPU’s really work? Well, at a lower level, the architecture looks something like this…&lt;/p&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="GPU Architecture" src="https://deadspheroid.github.io/my-blog/assets/img/gpu-arch.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;Focus on the differences between the two, CPUs have few, very highly specialised and refined cores.
GPUs on the other hand have hundreds of more primitive, yet powerful cores.&lt;/p&gt;

&lt;p&gt;This is the reason why GPUs can’t do I/O and stuff, its because they are meant solely for mathematical operations.&lt;/p&gt;

&lt;h2 id="but-whats-the-point-of-so-many-cores"&gt;But what’s the point of so many cores??&lt;/h2&gt;
&lt;p&gt;This is where SIMD or Single Instruction Multiple Data processing comes in handy. See, many operations(image and volume ones notoriously) are extremely taxing for the CPU to perform.
Imagine being part of a team of 8/16 people, stamping a sheet of paper, except you have 10^6 sheets to stamp.
Even if you took 1 ms/sheet, it would still take you insanely long to finish your jobs. And I mean, you have better things to do right?&lt;/p&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Map/Unmap Buffers" src="https://deadspheroid.github.io/my-blog/assets/img/simd.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;Well what if you could hire 10^3 people for cheap and give each of them a sheet of paper to stamp? Wouldn’t that greatly speed things up?
This is the core idea behind SIMD processing, you have an operation that is to be done thousands of times, over and over again, just on different data.&lt;/p&gt;

&lt;p&gt;So you give each GPU core a part of the data and let it do the job, since the GPU has so many cores, it’s not really a problem.&lt;/p&gt;

&lt;h2 id="so-whats-the-catch"&gt;So whats the catch?&lt;/h2&gt;
&lt;p&gt;Continuing the stamping sheet analogy, giving the sheets to 10^3 workers is challenging and time-consuming. In other words, data transfer is a problem, since GPU VRAM is separate from CPU RAM&lt;/p&gt;

&lt;p&gt;Additionally, parallel programming forces you to think in an additional dimension, because your code is being executed 100s of times at the same time. This makes writing efficient kernels difficult, since branching is frowned on at the GPU, and you need some way of preventing data races.&lt;/p&gt;

&lt;p&gt;That is to say nothing of the increased power consumption and high cost of hardware.&lt;/p&gt;

&lt;p&gt;Despite all of this however, GPUs are still heavily favoured, because the speed-up they offer greatly outweights the rest.&lt;/p&gt;

&lt;h2 id="well-how-do-i-use-my-gpu"&gt;Well, how do I use my GPU?&lt;/h2&gt;
&lt;p&gt;Let’s take an example, hopefully youre already familiar with image convolution. If not, the image below explains it well&lt;/p&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Map/Unmap Buffers" src="https://deadspheroid.github.io/my-blog/assets/img/convol.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;For each iteration, we center the kernel over a pixel, multiply the overlapping values, add them up and then (optionally)divide by sum of kernel values.
On CPU? For an m x n image and a k x k kernel, this is an O(mn * k^2) operation, meaning the time taken for convolution for a given data size increases tremendously.&lt;/p&gt;

&lt;p&gt;This can be greatly lessened using a GPU.&lt;/p&gt;

&lt;p&gt;But for that, we need to first identify the stamping task here, the tedious computation which is easy to do, but time consuming.&lt;/p&gt;

&lt;h2 id="image-convolution"&gt;Image Convolution&lt;/h2&gt;
&lt;p&gt;If you thought of the matmul operation happening at each pixel, you’d be correct!
This is one of the easiest ways to parallelise convolution. We’re repeatedly performing matrix multiplication, with different pixels at the center each time&lt;/p&gt;

&lt;p&gt;Therefore SIMD can be applied here, the instruction being matmul and the data being all the pixels.&lt;/p&gt;

&lt;p&gt;On a lower level, this is represented by the diffferent &lt;code class="language-plaintext highlighter-rouge"&gt;thread_id&lt;/code&gt; given to each thread on the GPU. This id represents a one to one mapping of an integer to input data elements.
Incase of Images, it is the pixel number that is at the center.&lt;/p&gt;

&lt;p&gt;Here’s an example of how convolution can be parallelized, note that this is not the most efficient and is nowhere near perfect, but it is simple enough to understand.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;__kernel void
convolution(
__global float *image_array, __global size_t *image_dsize,
__global float *kernell_array, __global size_t *kernell_dsize,

__global float *output) {

/* get the image and kernel size */
int image_height = image_dsize[0];
int image_width = image_dsize[1];
int kernell_height = kernell_dsize[0];
int kernell_width = kernell_dsize[1];

/* get the local group id */
int id = get_global_id(0);
int row = id / image_width;
int col = id % image_width;

if (row &amp;lt; image_height &amp;amp;&amp;amp; col &amp;lt; image_width) {

float sum = 0;
/* matmul operation as normal*/
for (int y = -kernell_height / 2; y &amp;lt;= kernell_height / 2; y++) {
for (int x = -kernell_width / 2; x &amp;lt;= kernell_width / 2; x++) {
if (row + y &amp;gt;= 0 &amp;amp;&amp;amp; row + y &amp;lt; image_height &amp;amp;&amp;amp; col + x &amp;gt;= 0 &amp;amp;&amp;amp;
col + x &amp;lt; image_width) {
sum += (image_array[(row + y) * image_width + col + x] *
kernell_array[(y + kernell_height / 2) * kernell_width + x +
kernell_width / 2]);
}
}
}
output[row * image_width + col] = sum;
}
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="a-new-outlook"&gt;A new outlook&lt;/h2&gt;
&lt;p&gt;Of course, the world would be a lovely place if everything could be parallelised as easily as this. Realistically, parallelizing these operations is hard, but you have tools like local groups, barriers, etc to help you out!&lt;/p&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240728_2230_deadspheroid/</guid><pubDate>Sun, 28 Jul 2024 21:30:00 GMT</pubDate></item><item><title>GSoC [Week 06-07] Progress</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240728_1014_viciouseagle03/</link><dc:creator>ViciousEagle03</dc:creator><description>&lt;p&gt;&lt;img alt="img" src="https://viciouseagle03.github.io/images/mid_term.png"&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This blog post covers all the work done in the sixth week of Google Summer of Code.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;/blockquote&gt;
&lt;p&gt;After having developed the serialization logic for NDCube with wcs as &lt;code&gt;gWCS&lt;/code&gt;, the next step was to extend this support to handle the serialization of NDCube where the wcs attribute is &lt;code&gt;astropy.wcs.WCS&lt;/code&gt;. This week my primary focus has been on enabling the serialization of &lt;code&gt;astropy.wcs.WCS&lt;/code&gt; objects to ASDF. This task involves adding the necessary serialization logic to the asdf-astropy repository.&lt;/p&gt;
&lt;h4 id="discussions-on-wcs-serialization"&gt;Discussions on WCS Serialization&lt;/h4&gt;
&lt;p&gt;We had a discussion about the process of serializing WCS objects and covered the following points:&lt;/p&gt;
&lt;h5 id="complex-wcs-types"&gt;Complex WCS Types:&lt;/h5&gt;
&lt;p&gt;WCS types like tabular and distortion ones are tricky because they involve data tables. Handling these types requires a more sophisticated approach.&lt;/p&gt;
&lt;h5 id="approach-discussion"&gt;Approach Discussion:&lt;/h5&gt;
&lt;p&gt;We discussed serializing a HDUList object or using &lt;code&gt;WCS.to_hdu&lt;/code&gt; for the complex WCS types but that seems pretty complex for a first attempt. We agreed on initially not supporting these complex WCS types and just using &lt;code&gt;WCS.to_header()&lt;/code&gt; for now for supporting the serialization of the basic WCS objects.&lt;/p&gt;
&lt;h4 id="whats-new"&gt;What’s new&lt;/h4&gt;
&lt;p&gt;So after my PR gets merged asdf-astropy would support the serialization of the &lt;code&gt;astropy.wcs.WCS&lt;/code&gt; objects to ASDF.
Ideally we would want to detect tabular and distortion WCS types and throw an error if they come up. This way, we’re clear about what’s supported and we agreed on revisiting this part and in the future and to extend this to support the serialization of the complex WCS objects.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Serialized simple &lt;code&gt;astropy.wcs.WCS&lt;/code&gt; object to ASDF&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;#ASDF 1.0.0
#ASDF_STANDARD 1.5.0
%YAML 1.1
%TAG ! tag:stsci.edu:asdf/
--- !core/asdf-1.1.0
asdf_library: !core/software-1.0.0 {author: The ASDF Developers, homepage: 'http://github.com/asdf-format/asdf',
name: asdf, version: 3.0.1}
history:
extensions:
- !core/extension_metadata-1.0.0
extension_class: asdf.extension._manifest.ManifestExtension
extension_uri: asdf://asdf-format.org/core/extensions/core-1.5.0
software: !core/software-1.0.0 {name: asdf, version: 3.0.1}
- !core/extension_metadata-1.0.0
extension_class: asdf.extension._manifest.ManifestExtension
extension_uri: asdf://astropy.org/astropy/extensions/astropy-1.0.0
software: !core/software-1.0.0 {name: asdf-astropy, version: 0.6.1.dev10+gdab5b4d.d20240723}
fits: !&amp;lt;tag:astropy.org:astropy/fits/fitswcs-1.0.0&amp;gt;
header: {CDELT1: 0.4, CDELT2: 2.0e-11, CDELT3: 0.0055555555555556, CDELT4: 0.0013888888888889,
CRPIX1: 0.0, CRPIX2: 0.0, CRPIX3: 0.0, CRPIX4: 5.0, CRVAL1: 0.0, CRVAL2: 0.0,
CRVAL3: 0.0, CRVAL4: 0.0, CTYPE1: TIME, CTYPE2: WAVE, CTYPE3: HPLT-TAN, CTYPE4: HPLN-TAN,
CUNIT1: min, CUNIT2: m, CUNIT3: deg, CUNIT4: deg, DATEREF: '2020-01-01T00:00:00',
LATPOLE: 0.0, LONPOLE: 180.0, MJDREF: 58849.0, WCSAXES: 4}
...
&lt;/code&gt;&lt;/pre&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240728_1014_viciouseagle03/</guid><pubDate>Sun, 28 Jul 2024 09:14:09 GMT</pubDate></item><item><title>Issue resolved</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240725_1809_kartikmandar/</link><dc:creator>Kartik Mandar</dc:creator><description>&lt;p&gt; The problem with classes was resolved by making factory functions to encase them in, and then they were not conflicting with each other. &lt;/p&gt;
&lt;!-- TEASER_END --&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240725_1809_kartikmandar/</guid><pubDate>Thu, 25 Jul 2024 17:09:00 GMT</pubDate></item><item><title>Enhancing SOAR Queries: Improved Error Handling and Support for Distance-Based Filtering</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240723_1650_nucleongodx/</link><dc:creator>Manit Singh</dc:creator><description>&lt;h4&gt;Improved Error Handling and Support for Distance-Based Filtering&lt;/h4&gt;&lt;h4&gt;Introduction&lt;/h4&gt;&lt;p&gt;Over the past few weeks, I’ve been working on addressing and enhancing certain functionalities within the sunpy-soar package. This post delves into the two main improvements I’ve implemented: better error handling for server downtime and the introduction of support for distance-based query filtering.&lt;/p&gt;
&lt;h4&gt;Improved Error Handling for Server Downtime&lt;/h4&gt;&lt;p&gt;Previously, when the SOAR server was down, a generic JSONDecodeError would be raised. This was less than ideal as it did not provide a clear indication of what the actual issue was. To improve this, I worked on implementing a more descriptive error message that would be raised in such scenarios.&lt;/p&gt;
&lt;pre&gt;r = requests.get(f"{tap_endpoint}/sync", params=payload)&lt;br&gt;try:&lt;br&gt;    response_json = r.json()&lt;br&gt;except JSONDecodeError:&lt;br&gt;    msg = "Server returned an invalid JSON response. The SOAR server may be down or not functioning correctly."&lt;br&gt;    raise RuntimeError(msg)&lt;/pre&gt;&lt;p&gt;With this change, users will now see a RuntimeError with a clear message indicating that the server may be down or not functioning correctly, which makes troubleshooting much easier.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;h4&gt;Implementing Support for Different REQUEST Types&lt;/h4&gt;&lt;p&gt;After resolving the error handling issue, I moved on to implementing support for different REQUEST types. Sunpy-soar initially only supported the doQuery REQUEST type. However, there was a need to expand this to support the doQueryFilteredByDistance REQUEST type as well.&lt;/p&gt;
&lt;h4&gt;What is doQueryFilteredByDistance?&lt;/h4&gt;&lt;p&gt;The doQueryFilteredByDistance REQUEST type allows for filtering the query results based on a specified distance range. The main change here is setting the REQUEST parameter to doQueryFilteredByDistance and appending &amp;amp;DISTANCE(distancemin,distancemax) to the query.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example Query:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;SELECT * FROM soar.v_sc_data_item WHERE instrument='MAG' AND level='LL02'&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;With Distance Filtering:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;SELECT * FROM soar.v_sc_data_item WHERE instrument='MAG' AND level='LL02' AND DISTANCE(0.28,0.49)&lt;/pre&gt;&lt;h4&gt;Conclusion&lt;/h4&gt;&lt;p&gt;These enhancements significantly improve the functionality and user experience of the sunpy-soar package. The improved error handling provides clearer feedback to users when the SOAR server is down, and the support for doQueryFilteredByDistance allows for more refined queries based on distance, opening up new possibilities for data analysis.&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=79c57af30ffc" width="1"&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240723_1650_nucleongodx/</guid><pubDate>Tue, 23 Jul 2024 15:50:13 GMT</pubDate></item><item><title>Blog 4: Testing the New Coalignment with a Catch</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240722_1859_deus1704/</link><dc:creator>Deus1704</dc:creator><description>&lt;p&gt;Now that we’ve agreed on the structure of the co-alignment API and also laid down its foundation, all that’s left is to validate it through actual tests and generate some gallery examples.&lt;/p&gt;
&lt;h3 id="first-try-with-coaligning-eis-raster-with-aia-map"&gt;First try with coaligning EIS raster with AIA map&lt;/h3&gt;
&lt;p&gt;Let’s take a closer look at the EIS raster first. I found an AIA image close to the &lt;code&gt;date_average&lt;/code&gt; of the raster.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="EIS raster" src="https://deus1704.vercel.app/images/original_eis.jpeg"&gt;&lt;/th&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="AIA Full-disc image" src="https://deus1704.vercel.app/images/aia_near_raster_avg.jpeg"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;EIS raster&lt;/td&gt;
&lt;td style="text-align: center;"&gt;AIA Full-disc image&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="Updated EIS" src="https://deus1704.vercel.app/images/updated_eis.png"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;Updated EIS&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;At first glance, the results seemed promising, but a more detailed analysis revealed some discrepancies.&lt;/p&gt;
&lt;p&gt;The updated WCS metadata looked fine at first, but on closer inspection, it wasn’t entirely correct. We’ll dive into the specifics later in this blog. For now, let’s discuss why it might look correct at a glance. How does a common user check if the maps are aligned? By overlaying them and checking the overlaps!&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="EIS overlaid on AIA" src="https://deus1704.vercel.app/images/eis_overlaid_aia.png"&gt;&lt;/th&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="Zoomed" src="https://deus1704.vercel.app/images/eis_overlaid_aia_zoomed.png"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;EIS overlaid on AIA&lt;/td&gt;
&lt;td style="text-align: center;"&gt;Zoomed&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This visual inspection might convince some that the method works, but it’s far from accurate. We proved this by highlighting the bright regions and focusing on the actual overlaps.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="EIS contours overlaid on AIA" src="https://deus1704.vercel.app/images/old_contours.png"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;EIS contours overlaid on AIA&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This showed us that something was wrong with either the way we were updating the metadata or the co-alignment method. While discussing this, we realized that an assumption in the match_template method was that the maps should have the same type of WCS.&lt;/p&gt;
&lt;h3 id="the-celestial-fix"&gt;The Celestial Fix&lt;/h3&gt;
&lt;p&gt;In our initial approach, we focused on adjusting the CRPIX values instead of the CRVAL values. CRPIX specifies the position of the reference pixel in the image, shifting the image in pixel space without correcting the world coordinates directly. This method led to apparent alignment issues because it didn’t address the celestial coordinate system. After consultation, we realized that adjusting CRVAL, which defines the world coordinates of the reference pixel, is essential. This adjustment ensures that the reference points align correctly in world coordinate space, maintaining consistent mapping between pixel and celestial coordinates.&lt;/p&gt;
&lt;p&gt;Furthermore, for accurate co-alignment, the observers (instruments) should be within a tolerable angular separation to minimize parallax effects. When observers are too far apart, solar features can appear differently due to relative positions, complicating alignment. By correcting CRVAL values and considering angular separation, we achieved precise co-alignment, as evidenced by the corrected overlay of EIS contours on the AIA image, allowing for reliable scientific analysis.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="EIS contours overlaid on AIA (corrected)" src="https://deus1704.vercel.app/images/fixed_eis.jpeg"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;EIS contours overlaid on AIA (corrected)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240722_1859_deus1704/</guid><pubDate>Mon, 22 Jul 2024 17:59:31 GMT</pubDate></item><item><title>New issue propped up</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240718_1634_kartikmandar/</link><dc:creator>Kartik Mandar</dc:creator><description>&lt;p&gt; When changing the whole architecture, a new issue has propped. An initialised object of the class can not be initialised again. So I am not able to revert back the home UI back dynamically. &lt;/p&gt;
&lt;!-- TEASER_END --&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240718_1634_kartikmandar/</guid><pubDate>Thu, 18 Jul 2024 15:34:00 GMT</pubDate></item><item><title>Taking on the Gaps: First Approaches of the Temporal Interpolation</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240715_1957_lucasmg18/</link><dc:creator>Lucas Martin Garcia</dc:creator><description>&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;Introduction&lt;/h4&gt;&lt;p&gt;In the study of Active Galactic Nuclei (AGNs), accurately interpolating light curve data is crucial for overcoming the challenge of observational gaps. This post elaborates on the implementation of both basic and advanced interpolation methods to enhance data continuity in AGN light curves.&lt;/p&gt;
&lt;h4&gt;Maximizing Coverage Across AGN Light Curves&lt;/h4&gt;&lt;p&gt;An essential step in our analysis of AGN light curves was to establish a benchmark for maximum coverage in each observational band. This process involves determining the most comprehensive temporal span for which we have data, ensuring that our interpolation methods are aligned with these time frames.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiyrZXIYNXT9iYEV7hyphenhyphen2ZGi7FZGjhdF6e-BlLF55vq6ZT3ZhdBPzV_wrIDOo3JoKtKSB9aA4hJxObLoQPPMLyqwIkTBWH54LODEXvr3b3pnnaT-1nMzVUncr-x1zo34KxFoWBw1xP396HpKl33myVTbBecGoaOMzZ2c94ilp_gFt-JZ6cRsv9nwIzECw8bI/s1381/Maximum%20Coverage%20with%20Flux.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="551" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiyrZXIYNXT9iYEV7hyphenhyphen2ZGi7FZGjhdF6e-BlLF55vq6ZT3ZhdBPzV_wrIDOo3JoKtKSB9aA4hJxObLoQPPMLyqwIkTBWH54LODEXvr3b3pnnaT-1nMzVUncr-x1zo34KxFoWBw1xP396HpKl33myVTbBecGoaOMzZ2c94ilp_gFt-JZ6cRsv9nwIzECw8bI/w768-h551/Maximum%20Coverage%20with%20Flux.png" width="768"&gt;&lt;/a&gt;&lt;/div&gt;&lt;br&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h4&gt;Traditional Interpolation Methods&lt;/h4&gt;&lt;p&gt;Initially, simple interpolation techniques were employed to address short gaps in the data:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Linear Interpolation&lt;/strong&gt;: This method assumes a linear progression between adjacent data points, making it suitable for intervals where changes are minor and gradual.&lt;/p&gt;
&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;ul&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhVWFOY4rFxnxAVKn3xky3KA_vZXolBRcEBSv9c6PZHoSwlr4uUIEY1SGYd1z1LH5zgvBGacxIT5AsS-aUAUMi0kFl56SuQPuZhJvih0x_ebehtvOVjV4rvV_Em3C9v1tKwbEEAXIXGoRwjyL_5UPat5-4aBjZW-v-HnHa9sgTlAWgZMIElzVccNRdErLqM/s1389/linear%20interpolation.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="508" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhVWFOY4rFxnxAVKn3xky3KA_vZXolBRcEBSv9c6PZHoSwlr4uUIEY1SGYd1z1LH5zgvBGacxIT5AsS-aUAUMi0kFl56SuQPuZhJvih0x_ebehtvOVjV4rvV_Em3C9v1tKwbEEAXIXGoRwjyL_5UPat5-4aBjZW-v-HnHa9sgTlAWgZMIElzVccNRdErLqM/w713-h508/linear%20interpolation.png" width="713"&gt;&lt;/a&gt;&lt;/div&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Polynomial Interpolation&lt;/strong&gt;: More complex than linear interpolation, this technique provides a flexible curve that fits various data points, better accommodating the non-linear variability in AGN light emissions.&lt;/p&gt;
&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;/p&gt;
&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvi-Pw-rN95X4yeI5YH0HKiX4gIsK50TWNUHKQrmcsa7PrxciFHT5nzrrLoqFPo1DRDltdmOULCAxkD2voXUaIgbZMF5l3j6zmwGgZBIx5wqdmiBKSJyE-wKEytufBLaQ3R-iWn32awAOcXqi6NHtdkoGjeP4nBu4hO2hGmZX0KehfjV6YHX0UAS0yGiNi/s1389/polynom%20inter.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="511" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvi-Pw-rN95X4yeI5YH0HKiX4gIsK50TWNUHKQrmcsa7PrxciFHT5nzrrLoqFPo1DRDltdmOULCAxkD2voXUaIgbZMF5l3j6zmwGgZBIx5wqdmiBKSJyE-wKEytufBLaQ3R-iWn32awAOcXqi6NHtdkoGjeP4nBu4hO2hGmZX0KehfjV6YHX0UAS0yGiNi/w717-h511/polynom%20inter.png" width="717"&gt;&lt;/a&gt;&lt;/div&gt;&lt;strong&gt;K-Nearest Neighbors (KNN)&lt;/strong&gt;: This method predicts missing values by averaging the values of the nearest neighbors, thus incorporating local data similarities into the interpolation process.&lt;p&gt;&lt;/p&gt;
&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;h4&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj6_qYC9Ke0BCVrbAUFxdKgNI_TFYfL9TJhtNDGJk-ddP4XIEaN13VOpHnibepFkIVPbMKIpOIiYN4Lt3GGn7i-5swnfzz6d7Jmr4d149NJIwEa0vU8aUX-Nn9olQo-JO9DUDsS5uihFp9lPDhlg-kEkqVRsHB9rwt0odSZS3obANEX0WA7WRzgrnBBYL3k/s1389/KNN%20inter.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="536" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj6_qYC9Ke0BCVrbAUFxdKgNI_TFYfL9TJhtNDGJk-ddP4XIEaN13VOpHnibepFkIVPbMKIpOIiYN4Lt3GGn7i-5swnfzz6d7Jmr4d149NJIwEa0vU8aUX-Nn9olQo-JO9DUDsS5uihFp9lPDhlg-kEkqVRsHB9rwt0odSZS3obANEX0WA7WRzgrnBBYL3k/w750-h536/KNN%20inter.png" width="750"&gt;&lt;/a&gt;&lt;/div&gt;Machine Learning Techniques&lt;/h4&gt;&lt;p&gt;To handle larger data gaps and preserve the intricate dynamics of AGN light curves, advanced machine learning algorithms were applied:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Recurrent Neural Networks (RNNs)&lt;/strong&gt;: RNNs are highly effective for sequential data prediction. They process time-series data by learning from past observations, making them particularly adept at modeling complex dependencies across time steps.&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;h4&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjTKtAJp5vpjxfVfxOm58PlFyIecLLevLWez3TwGuer5Gjs5sW7Elmw9EYezL7C8lUbQXJMQin3XYwnpIuKh-mYtNelhQ6fdnzKDQJ242yape7FL1JbVAqc7rSgp1BSSTJtk-UdQ1yirdkPOX72xUkfflGm1lwxKYfKMLHx8erF7rHeKdqdLN_54dBuhwpb/s1389/RNN%20inter.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="499" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjTKtAJp5vpjxfVfxOm58PlFyIecLLevLWez3TwGuer5Gjs5sW7Elmw9EYezL7C8lUbQXJMQin3XYwnpIuKh-mYtNelhQ6fdnzKDQJ242yape7FL1JbVAqc7rSgp1BSSTJtk-UdQ1yirdkPOX72xUkfflGm1lwxKYfKMLHx8erF7rHeKdqdLN_54dBuhwpb/w700-h499/RNN%20inter.png" width="700"&gt;&lt;/a&gt;&lt;/div&gt;Future Directions&lt;/h4&gt;&lt;p&gt;The main goals of these approaches are to improve the quality and continuity of AGN light curve data. Evaluation methods are required to compare the models when more advanced models are utilized.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;&lt;p&gt;The interpolation of AGN light curve data, although challenging, is essential for advancing our understanding of these celestial objects. The methodologies discussed here are not only applicable to astrophysics but also have implications for other scientific fields where data completeness affects research outcomes.&lt;/p&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;</description><category>irsa-fornax</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240715_1957_lucasmg18/</guid><pubDate>Mon, 15 Jul 2024 18:57:00 GMT</pubDate></item><item><title>Finally the issue resolves</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240715_1528_kartikmandar/</link><dc:creator>Kartik Mandar</dc:creator><description>&lt;p&gt; Damn, those 2 weeks were stressful, finally the issue is resolved. I am able to render HoloViews and thus Bokeh plots inside my program and in the process my codebase is much better than before. &lt;/p&gt;
&lt;!-- TEASER_END --&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240715_1528_kartikmandar/</guid><pubDate>Mon, 15 Jul 2024 14:28:00 GMT</pubDate></item></channel></rss>