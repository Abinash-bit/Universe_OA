<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts about gsoc2024)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/categories/cat_gsoc2024.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Thu, 01 Aug 2024 01:09:54 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Implementing non-equilibrium spectra</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240729_0000_code29563/</link><dc:creator>code29563</dc:creator><description>&lt;ul&gt;
&lt;li&gt;Support has been added for non-equilibrium spectra. Comparisons with SpectraPlot are still showing discrepancies, the source of which is not yet resolved.&lt;/li&gt;
&lt;li&gt;References have been added for the Kurucz databank&lt;/li&gt;
&lt;!-- TEASER_END --&gt;
&lt;li&gt;Miscellaneous minor improvements and fixes in the code and docs&lt;/li&gt;
&lt;/ul&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240729_0000_code29563/</guid><pubDate>Sun, 28 Jul 2024 23:00:00 GMT</pubDate></item><item><title>Towards New Speeds</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240728_2230_deadspheroid/</link><dc:creator>DeadSpheroid</dc:creator><description>&lt;p class="intro"&gt;In this post, I hope to illustrate how GPU's actually accelerate parallel operations&lt;/p&gt;

&lt;h2 id="lets-get-started"&gt;Let’s get started&lt;/h2&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Firstly, how do GPU’s really work? Well, at a lower level, the architecture looks something like this…&lt;/p&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="GPU Architecture" src="https://deadspheroid.github.io/my-blog/assets/img/gpu-arch.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;Focus on the differences between the two, CPUs have few, very highly specialised and refined cores.
GPUs on the other hand have hundreds of more primitive, yet powerful cores.&lt;/p&gt;

&lt;p&gt;This is the reason why GPUs can’t do I/O and stuff, its because they are meant solely for mathematical operations.&lt;/p&gt;

&lt;h2 id="but-whats-the-point-of-so-many-cores"&gt;But what’s the point of so many cores??&lt;/h2&gt;
&lt;p&gt;This is where SIMD or Single Instruction Multiple Data processing comes in handy. See, many operations(image and volume ones notoriously) are extremely taxing for the CPU to perform.
Imagine being part of a team of 8/16 people, stamping a sheet of paper, except you have 10^6 sheets to stamp.
Even if you took 1 ms/sheet, it would still take you insanely long to finish your jobs. And I mean, you have better things to do right?&lt;/p&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Map/Unmap Buffers" src="https://deadspheroid.github.io/my-blog/assets/img/simd.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;Well what if you could hire 10^3 people for cheap and give each of them a sheet of paper to stamp? Wouldn’t that greatly speed things up?
This is the core idea behind SIMD processing, you have an operation that is to be done thousands of times, over and over again, just on different data.&lt;/p&gt;

&lt;p&gt;So you give each GPU core a part of the data and let it do the job, since the GPU has so many cores, it’s not really a problem.&lt;/p&gt;

&lt;h2 id="so-whats-the-catch"&gt;So whats the catch?&lt;/h2&gt;
&lt;p&gt;Continuing the stamping sheet analogy, giving the sheets to 10^3 workers is challenging and time-consuming. In other words, data transfer is a problem, since GPU VRAM is separate from CPU RAM&lt;/p&gt;

&lt;p&gt;Additionally, parallel programming forces you to think in an additional dimension, because your code is being executed 100s of times at the same time. This makes writing efficient kernels difficult, since branching is frowned on at the GPU, and you need some way of preventing data races.&lt;/p&gt;

&lt;p&gt;That is to say nothing of the increased power consumption and high cost of hardware.&lt;/p&gt;

&lt;p&gt;Despite all of this however, GPUs are still heavily favoured, because the speed-up they offer greatly outweights the rest.&lt;/p&gt;

&lt;h2 id="well-how-do-i-use-my-gpu"&gt;Well, how do I use my GPU?&lt;/h2&gt;
&lt;p&gt;Let’s take an example, hopefully youre already familiar with image convolution. If not, the image below explains it well&lt;/p&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Map/Unmap Buffers" src="https://deadspheroid.github.io/my-blog/assets/img/convol.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;For each iteration, we center the kernel over a pixel, multiply the overlapping values, add them up and then (optionally)divide by sum of kernel values.
On CPU? For an m x n image and a k x k kernel, this is an O(mn * k^2) operation, meaning the time taken for convolution for a given data size increases tremendously.&lt;/p&gt;

&lt;p&gt;This can be greatly lessened using a GPU.&lt;/p&gt;

&lt;p&gt;But for that, we need to first identify the stamping task here, the tedious computation which is easy to do, but time consuming.&lt;/p&gt;

&lt;h2 id="image-convolution"&gt;Image Convolution&lt;/h2&gt;
&lt;p&gt;If you thought of the matmul operation happening at each pixel, you’d be correct!
This is one of the easiest ways to parallelise convolution. We’re repeatedly performing matrix multiplication, with different pixels at the center each time&lt;/p&gt;

&lt;p&gt;Therefore SIMD can be applied here, the instruction being matmul and the data being all the pixels.&lt;/p&gt;

&lt;p&gt;On a lower level, this is represented by the diffferent &lt;code class="language-plaintext highlighter-rouge"&gt;thread_id&lt;/code&gt; given to each thread on the GPU. This id represents a one to one mapping of an integer to input data elements.
Incase of Images, it is the pixel number that is at the center.&lt;/p&gt;

&lt;p&gt;Here’s an example of how convolution can be parallelized, note that this is not the most efficient and is nowhere near perfect, but it is simple enough to understand.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;__kernel void
convolution(
__global float *image_array, __global size_t *image_dsize,
__global float *kernell_array, __global size_t *kernell_dsize,

__global float *output) {

/* get the image and kernel size */
int image_height = image_dsize[0];
int image_width = image_dsize[1];
int kernell_height = kernell_dsize[0];
int kernell_width = kernell_dsize[1];

/* get the local group id */
int id = get_global_id(0);
int row = id / image_width;
int col = id % image_width;

if (row &amp;lt; image_height &amp;amp;&amp;amp; col &amp;lt; image_width) {

float sum = 0;
/* matmul operation as normal*/
for (int y = -kernell_height / 2; y &amp;lt;= kernell_height / 2; y++) {
for (int x = -kernell_width / 2; x &amp;lt;= kernell_width / 2; x++) {
if (row + y &amp;gt;= 0 &amp;amp;&amp;amp; row + y &amp;lt; image_height &amp;amp;&amp;amp; col + x &amp;gt;= 0 &amp;amp;&amp;amp;
col + x &amp;lt; image_width) {
sum += (image_array[(row + y) * image_width + col + x] *
kernell_array[(y + kernell_height / 2) * kernell_width + x +
kernell_width / 2]);
}
}
}
output[row * image_width + col] = sum;
}
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="a-new-outlook"&gt;A new outlook&lt;/h2&gt;
&lt;p&gt;Of course, the world would be a lovely place if everything could be parallelised as easily as this. Realistically, parallelizing these operations is hard, but you have tools like local groups, barriers, etc to help you out!&lt;/p&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240728_2230_deadspheroid/</guid><pubDate>Sun, 28 Jul 2024 21:30:00 GMT</pubDate></item><item><title>Issue resolved</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240725_1809_kartikmandar/</link><dc:creator>Kartik Mandar</dc:creator><description>&lt;p&gt; The problem with classes was resolved by making factory functions to encase them in, and then they were not conflicting with each other. &lt;/p&gt;
&lt;!-- TEASER_END --&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240725_1809_kartikmandar/</guid><pubDate>Thu, 25 Jul 2024 17:09:00 GMT</pubDate></item><item><title>Enhancing SOAR Queries: Improved Error Handling and Support for Distance-Based Filtering</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240723_1650_nucleongodx/</link><dc:creator>Manit Singh</dc:creator><description>&lt;h4&gt;Improved Error Handling and Support for Distance-Based Filtering&lt;/h4&gt;&lt;h4&gt;Introduction&lt;/h4&gt;&lt;p&gt;Over the past few weeks, I’ve been working on addressing and enhancing certain functionalities within the sunpy-soar package. This post delves into the two main improvements I’ve implemented: better error handling for server downtime and the introduction of support for distance-based query filtering.&lt;/p&gt;
&lt;h4&gt;Improved Error Handling for Server Downtime&lt;/h4&gt;&lt;p&gt;Previously, when the SOAR server was down, a generic JSONDecodeError would be raised. This was less than ideal as it did not provide a clear indication of what the actual issue was. To improve this, I worked on implementing a more descriptive error message that would be raised in such scenarios.&lt;/p&gt;
&lt;pre&gt;r = requests.get(f"{tap_endpoint}/sync", params=payload)&lt;br&gt;try:&lt;br&gt;    response_json = r.json()&lt;br&gt;except JSONDecodeError:&lt;br&gt;    msg = "Server returned an invalid JSON response. The SOAR server may be down or not functioning correctly."&lt;br&gt;    raise RuntimeError(msg)&lt;/pre&gt;&lt;p&gt;With this change, users will now see a RuntimeError with a clear message indicating that the server may be down or not functioning correctly, which makes troubleshooting much easier.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;h4&gt;Implementing Support for Different REQUEST Types&lt;/h4&gt;&lt;p&gt;After resolving the error handling issue, I moved on to implementing support for different REQUEST types. Sunpy-soar initially only supported the doQuery REQUEST type. However, there was a need to expand this to support the doQueryFilteredByDistance REQUEST type as well.&lt;/p&gt;
&lt;h4&gt;What is doQueryFilteredByDistance?&lt;/h4&gt;&lt;p&gt;The doQueryFilteredByDistance REQUEST type allows for filtering the query results based on a specified distance range. The main change here is setting the REQUEST parameter to doQueryFilteredByDistance and appending &amp;amp;DISTANCE(distancemin,distancemax) to the query.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example Query:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;SELECT * FROM soar.v_sc_data_item WHERE instrument='MAG' AND level='LL02'&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;With Distance Filtering:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;SELECT * FROM soar.v_sc_data_item WHERE instrument='MAG' AND level='LL02' AND DISTANCE(0.28,0.49)&lt;/pre&gt;&lt;h4&gt;Conclusion&lt;/h4&gt;&lt;p&gt;These enhancements significantly improve the functionality and user experience of the sunpy-soar package. The improved error handling provides clearer feedback to users when the SOAR server is down, and the support for doQueryFilteredByDistance allows for more refined queries based on distance, opening up new possibilities for data analysis.&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=79c57af30ffc" width="1"&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240723_1650_nucleongodx/</guid><pubDate>Tue, 23 Jul 2024 15:50:13 GMT</pubDate></item><item><title>Blog 4: Testing the New Coalignment with a Catch</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240722_1859_deus1704/</link><dc:creator>Deus1704</dc:creator><description>&lt;p&gt;Now that we’ve agreed on the structure of the co-alignment API and also laid down its foundation, all that’s left is to validate it through actual tests and generate some gallery examples.&lt;/p&gt;
&lt;h3 id="first-try-with-coaligning-eis-raster-with-aia-map"&gt;First try with coaligning EIS raster with AIA map&lt;/h3&gt;
&lt;p&gt;Let’s take a closer look at the EIS raster first. I found an AIA image close to the &lt;code&gt;date_average&lt;/code&gt; of the raster.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="EIS raster" src="https://deus1704.vercel.app/images/original_eis.jpeg"&gt;&lt;/th&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="AIA Full-disc image" src="https://deus1704.vercel.app/images/aia_near_raster_avg.jpeg"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;EIS raster&lt;/td&gt;
&lt;td style="text-align: center;"&gt;AIA Full-disc image&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="Updated EIS" src="https://deus1704.vercel.app/images/updated_eis.png"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;Updated EIS&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;At first glance, the results seemed promising, but a more detailed analysis revealed some discrepancies.&lt;/p&gt;
&lt;p&gt;The updated WCS metadata looked fine at first, but on closer inspection, it wasn’t entirely correct. We’ll dive into the specifics later in this blog. For now, let’s discuss why it might look correct at a glance. How does a common user check if the maps are aligned? By overlaying them and checking the overlaps!&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="EIS overlaid on AIA" src="https://deus1704.vercel.app/images/eis_overlaid_aia.png"&gt;&lt;/th&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="Zoomed" src="https://deus1704.vercel.app/images/eis_overlaid_aia_zoomed.png"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;EIS overlaid on AIA&lt;/td&gt;
&lt;td style="text-align: center;"&gt;Zoomed&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This visual inspection might convince some that the method works, but it’s far from accurate. We proved this by highlighting the bright regions and focusing on the actual overlaps.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="EIS contours overlaid on AIA" src="https://deus1704.vercel.app/images/old_contours.png"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;EIS contours overlaid on AIA&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This showed us that something was wrong with either the way we were updating the metadata or the co-alignment method. While discussing this, we realized that an assumption in the match_template method was that the maps should have the same type of WCS.&lt;/p&gt;
&lt;h3 id="the-celestial-fix"&gt;The Celestial Fix&lt;/h3&gt;
&lt;p&gt;In our initial approach, we focused on adjusting the CRPIX values instead of the CRVAL values. CRPIX specifies the position of the reference pixel in the image, shifting the image in pixel space without correcting the world coordinates directly. This method led to apparent alignment issues because it didn’t address the celestial coordinate system. After consultation, we realized that adjusting CRVAL, which defines the world coordinates of the reference pixel, is essential. This adjustment ensures that the reference points align correctly in world coordinate space, maintaining consistent mapping between pixel and celestial coordinates.&lt;/p&gt;
&lt;p&gt;Furthermore, for accurate co-alignment, the observers (instruments) should be within a tolerable angular separation to minimize parallax effects. When observers are too far apart, solar features can appear differently due to relative positions, complicating alignment. By correcting CRVAL values and considering angular separation, we achieved precise co-alignment, as evidenced by the corrected overlay of EIS contours on the AIA image, allowing for reliable scientific analysis.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;&lt;img alt="EIS contours overlaid on AIA (corrected)" src="https://deus1704.vercel.app/images/fixed_eis.jpeg"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;EIS contours overlaid on AIA (corrected)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240722_1859_deus1704/</guid><pubDate>Mon, 22 Jul 2024 17:59:31 GMT</pubDate></item><item><title>New issue propped up</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240718_1634_kartikmandar/</link><dc:creator>Kartik Mandar</dc:creator><description>&lt;p&gt; When changing the whole architecture, a new issue has propped. An initialised object of the class can not be initialised again. So I am not able to revert back the home UI back dynamically. &lt;/p&gt;
&lt;!-- TEASER_END --&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240718_1634_kartikmandar/</guid><pubDate>Thu, 18 Jul 2024 15:34:00 GMT</pubDate></item><item><title>Taking on the Gaps: First Approaches of the Temporal Interpolation</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240715_1957_lucasmg18/</link><dc:creator>Lucas Martin Garcia</dc:creator><description>&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;Introduction&lt;/h4&gt;&lt;p&gt;In the study of Active Galactic Nuclei (AGNs), accurately interpolating light curve data is crucial for overcoming the challenge of observational gaps. This post elaborates on the implementation of both basic and advanced interpolation methods to enhance data continuity in AGN light curves.&lt;/p&gt;
&lt;h4&gt;Maximizing Coverage Across AGN Light Curves&lt;/h4&gt;&lt;p&gt;An essential step in our analysis of AGN light curves was to establish a benchmark for maximum coverage in each observational band. This process involves determining the most comprehensive temporal span for which we have data, ensuring that our interpolation methods are aligned with these time frames.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiyrZXIYNXT9iYEV7hyphenhyphen2ZGi7FZGjhdF6e-BlLF55vq6ZT3ZhdBPzV_wrIDOo3JoKtKSB9aA4hJxObLoQPPMLyqwIkTBWH54LODEXvr3b3pnnaT-1nMzVUncr-x1zo34KxFoWBw1xP396HpKl33myVTbBecGoaOMzZ2c94ilp_gFt-JZ6cRsv9nwIzECw8bI/s1381/Maximum%20Coverage%20with%20Flux.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="551" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiyrZXIYNXT9iYEV7hyphenhyphen2ZGi7FZGjhdF6e-BlLF55vq6ZT3ZhdBPzV_wrIDOo3JoKtKSB9aA4hJxObLoQPPMLyqwIkTBWH54LODEXvr3b3pnnaT-1nMzVUncr-x1zo34KxFoWBw1xP396HpKl33myVTbBecGoaOMzZ2c94ilp_gFt-JZ6cRsv9nwIzECw8bI/w768-h551/Maximum%20Coverage%20with%20Flux.png" width="768"&gt;&lt;/a&gt;&lt;/div&gt;&lt;br&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h4&gt;Traditional Interpolation Methods&lt;/h4&gt;&lt;p&gt;Initially, simple interpolation techniques were employed to address short gaps in the data:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Linear Interpolation&lt;/strong&gt;: This method assumes a linear progression between adjacent data points, making it suitable for intervals where changes are minor and gradual.&lt;/p&gt;
&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;ul&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhVWFOY4rFxnxAVKn3xky3KA_vZXolBRcEBSv9c6PZHoSwlr4uUIEY1SGYd1z1LH5zgvBGacxIT5AsS-aUAUMi0kFl56SuQPuZhJvih0x_ebehtvOVjV4rvV_Em3C9v1tKwbEEAXIXGoRwjyL_5UPat5-4aBjZW-v-HnHa9sgTlAWgZMIElzVccNRdErLqM/s1389/linear%20interpolation.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="508" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhVWFOY4rFxnxAVKn3xky3KA_vZXolBRcEBSv9c6PZHoSwlr4uUIEY1SGYd1z1LH5zgvBGacxIT5AsS-aUAUMi0kFl56SuQPuZhJvih0x_ebehtvOVjV4rvV_Em3C9v1tKwbEEAXIXGoRwjyL_5UPat5-4aBjZW-v-HnHa9sgTlAWgZMIElzVccNRdErLqM/w713-h508/linear%20interpolation.png" width="713"&gt;&lt;/a&gt;&lt;/div&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Polynomial Interpolation&lt;/strong&gt;: More complex than linear interpolation, this technique provides a flexible curve that fits various data points, better accommodating the non-linear variability in AGN light emissions.&lt;/p&gt;
&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;/p&gt;
&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvi-Pw-rN95X4yeI5YH0HKiX4gIsK50TWNUHKQrmcsa7PrxciFHT5nzrrLoqFPo1DRDltdmOULCAxkD2voXUaIgbZMF5l3j6zmwGgZBIx5wqdmiBKSJyE-wKEytufBLaQ3R-iWn32awAOcXqi6NHtdkoGjeP4nBu4hO2hGmZX0KehfjV6YHX0UAS0yGiNi/s1389/polynom%20inter.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="511" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvi-Pw-rN95X4yeI5YH0HKiX4gIsK50TWNUHKQrmcsa7PrxciFHT5nzrrLoqFPo1DRDltdmOULCAxkD2voXUaIgbZMF5l3j6zmwGgZBIx5wqdmiBKSJyE-wKEytufBLaQ3R-iWn32awAOcXqi6NHtdkoGjeP4nBu4hO2hGmZX0KehfjV6YHX0UAS0yGiNi/w717-h511/polynom%20inter.png" width="717"&gt;&lt;/a&gt;&lt;/div&gt;&lt;strong&gt;K-Nearest Neighbors (KNN)&lt;/strong&gt;: This method predicts missing values by averaging the values of the nearest neighbors, thus incorporating local data similarities into the interpolation process.&lt;p&gt;&lt;/p&gt;
&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;h4&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj6_qYC9Ke0BCVrbAUFxdKgNI_TFYfL9TJhtNDGJk-ddP4XIEaN13VOpHnibepFkIVPbMKIpOIiYN4Lt3GGn7i-5swnfzz6d7Jmr4d149NJIwEa0vU8aUX-Nn9olQo-JO9DUDsS5uihFp9lPDhlg-kEkqVRsHB9rwt0odSZS3obANEX0WA7WRzgrnBBYL3k/s1389/KNN%20inter.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="536" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj6_qYC9Ke0BCVrbAUFxdKgNI_TFYfL9TJhtNDGJk-ddP4XIEaN13VOpHnibepFkIVPbMKIpOIiYN4Lt3GGn7i-5swnfzz6d7Jmr4d149NJIwEa0vU8aUX-Nn9olQo-JO9DUDsS5uihFp9lPDhlg-kEkqVRsHB9rwt0odSZS3obANEX0WA7WRzgrnBBYL3k/w750-h536/KNN%20inter.png" width="750"&gt;&lt;/a&gt;&lt;/div&gt;Machine Learning Techniques&lt;/h4&gt;&lt;p&gt;To handle larger data gaps and preserve the intricate dynamics of AGN light curves, advanced machine learning algorithms were applied:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Recurrent Neural Networks (RNNs)&lt;/strong&gt;: RNNs are highly effective for sequential data prediction. They process time-series data by learning from past observations, making them particularly adept at modeling complex dependencies across time steps.&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;h4&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjTKtAJp5vpjxfVfxOm58PlFyIecLLevLWez3TwGuer5Gjs5sW7Elmw9EYezL7C8lUbQXJMQin3XYwnpIuKh-mYtNelhQ6fdnzKDQJ242yape7FL1JbVAqc7rSgp1BSSTJtk-UdQ1yirdkPOX72xUkfflGm1lwxKYfKMLHx8erF7rHeKdqdLN_54dBuhwpb/s1389/RNN%20inter.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="499" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjTKtAJp5vpjxfVfxOm58PlFyIecLLevLWez3TwGuer5Gjs5sW7Elmw9EYezL7C8lUbQXJMQin3XYwnpIuKh-mYtNelhQ6fdnzKDQJ242yape7FL1JbVAqc7rSgp1BSSTJtk-UdQ1yirdkPOX72xUkfflGm1lwxKYfKMLHx8erF7rHeKdqdLN_54dBuhwpb/w700-h499/RNN%20inter.png" width="700"&gt;&lt;/a&gt;&lt;/div&gt;Future Directions&lt;/h4&gt;&lt;p&gt;The main goals of these approaches are to improve the quality and continuity of AGN light curve data. Evaluation methods are required to compare the models when more advanced models are utilized.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;&lt;p&gt;The interpolation of AGN light curve data, although challenging, is essential for advancing our understanding of these celestial objects. The methodologies discussed here are not only applicable to astrophysics but also have implications for other scientific fields where data completeness affects research outcomes.&lt;/p&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;</description><category>irsa-fornax</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240715_1957_lucasmg18/</guid><pubDate>Mon, 15 Jul 2024 18:57:00 GMT</pubDate></item><item><title>Finally the issue resolves</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240715_1528_kartikmandar/</link><dc:creator>Kartik Mandar</dc:creator><description>&lt;p&gt; Damn, those 2 weeks were stressful, finally the issue is resolved. I am able to render HoloViews and thus Bokeh plots inside my program and in the process my codebase is much better than before. &lt;/p&gt;
&lt;!-- TEASER_END --&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240715_1528_kartikmandar/</guid><pubDate>Mon, 15 Jul 2024 14:28:00 GMT</pubDate></item><item><title>Finishing up equilibrium spectra</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240714_0000_code29563/</link><dc:creator>code29563</dc:creator><description>&lt;ul&gt;
&lt;li&gt;Tests have been added for the implementation of the Kurucz database and associated parts of the code&lt;/li&gt;
&lt;li&gt;Examples have been added relating to the Lorentzian broadening of atomic lines and partition functions.&lt;/li&gt;
&lt;!-- TEASER_END --&gt;
&lt;li&gt;The function to parse Kurucz linelists has been re-written based on Pandas.&lt;/li&gt;
&lt;li&gt;The precision of some parts of the code has been improved by using &lt;code class="language-plaintext highlighter-rouge"&gt;numpy.expm1&lt;/code&gt; rather than &lt;code class="language-plaintext highlighter-rouge"&gt;numpy.exp&lt;/code&gt;, thereby showing weaker spectra that otherwise weren’t being seen&lt;/li&gt;
&lt;li&gt;Support has been added for loading existing databanks of atomic species without specifying the species initially.&lt;/li&gt;
&lt;li&gt;A greater range of formats are now accepted as input to specify the species for which to calculate a spectrum.&lt;/li&gt;
&lt;li&gt;Documentation for atomic spectra and the Kurucz database has been updated further&lt;/li&gt;
&lt;/ul&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240714_0000_code29563/</guid><pubDate>Sat, 13 Jul 2024 23:00:00 GMT</pubDate></item><item><title>Exploring OpenCL memory management</title><link>http://openastronomy.org/Universe_OA/posts/2024/07/20240713_2230_deadspheroid/</link><dc:creator>DeadSpheroid</dc:creator><description>&lt;p class="intro"&gt;In this post, I hope to give a high level understanding of OpenCL's Memory Mechanisms&lt;/p&gt;

&lt;h2 id="the-basics"&gt;The basics&lt;/h2&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Firstly, its important to have a basic understanding of the hardware involved. Keeping it simple, each OpenCL device represents a different set of hardware, each with its own RAM.
My own laptop has a 16GB CPU RAM, and 6GB VRAM&lt;/p&gt;

&lt;p&gt;Now, at the heart of C, we have pointers, without them well, you can’t really get much done in C. The pointers we convetionally use are pointers to CPU RAM.&lt;/p&gt;

&lt;p&gt;So what would happen if you try to pass a CPU Pointer to the GPU?
Well, of course, it wont work, the GPU simply segfaults, as it cannot understand the pointer given to it.
But we still need to use pointers, we can’t just abandon them. So how do we do this?&lt;/p&gt;

&lt;h2 id="buffers"&gt;Buffers&lt;/h2&gt;

&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Map/Unmap Buffers" src="https://deadspheroid.github.io/my-blog/assets/img/opencl-map.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;At the simplest level, we have OpenCL Buffers. These buffers are chunks of memory allocated on the OpenCL device as well as on host memory.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;cl_mem clCreateBuffer(
cl_context context,
cl_mem_flags flags,
size_t size,
void *host_ptr,
cl_int *errcode_ret)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Creating a buffer is easy, its figuring out what kind of buffer you need that is important.&lt;/p&gt;

&lt;p&gt;Broadly speaking there are 3 types of buffers based on the &lt;code class="language-plaintext highlighter-rouge"&gt;flags&lt;/code&gt; passed:&lt;/p&gt;

&lt;h4 id="cl_mem_use_host_ptr"&gt;CL_MEM_USE_HOST_PTR&lt;/h4&gt;
&lt;p&gt;This tells OpenCL to use the host pointer provided as the underlying memory on host.&lt;/p&gt;

&lt;h4 id="cl_mem_copy_host_ptr"&gt;CL_MEM_COPY_HOST_PTR&lt;/h4&gt;
&lt;p&gt;This flag tells OpenCL to make a new buffer and fill it with the memory pointed to by host pointer.&lt;/p&gt;

&lt;h4 id="cl_mem_alloc_host_ptr"&gt;CL_MEM_ALLOC_HOST_PTR&lt;/h4&gt;
&lt;p&gt;This one is the same as CL_MEM_USE_HOST_PTR, but the allocation of host pointer is also done by OpenCL&lt;/p&gt;

&lt;p&gt;But which one should you use?
Well, if you desire a zero copy buffer, i.e. create a buffer without copying memory, especially memory on host, then
CL_MEM_USE_HOST_PTR(if you have the memory already initialised)
or
CL_MEM_ALLOC_HOST_PTR(if you plan to initialise the buffer afterward)
The concept of a zero copy buffer is super helpful when you are targeting the same host CPU as an OpenCL device.&lt;/p&gt;

&lt;p&gt;I mean, you already have the data in CPU RAM, why would you make another copy in CPU RAM by creating a new buffer?&lt;/p&gt;

&lt;h2 id="literacy-for-buffers"&gt;Literacy for Buffers&lt;/h2&gt;
&lt;p align="center" width="100%"&gt;
&lt;img alt="OpenCL Map/Unmap Buffers" src="https://deadspheroid.github.io/my-blog/assets/img/opencl-mem.png" style="margin-bottom: 0; margin-top: 24px;"&gt;
&lt;/p&gt;

&lt;p&gt;The above is enough when you are operating on the same device, which is seldom the case with OpenCL.
But when you work with GPUs, you need to get the memory into GPU VRAM somehow.&lt;/p&gt;

&lt;p&gt;And this is impossible(maybe) without copying the data over.&lt;/p&gt;

&lt;p&gt;So how do you copy the data over to GPU VRAM?
Well, after allocating a buffer as seen before, OpenCL will try to recreate the host side buffer on the device as well.&lt;/p&gt;

&lt;p&gt;But when you update the host side buffer(like reading in input), youd want it to reflect on device as well.
Similary, when your device is done processing, you need to get the output from device memory to host memory.&lt;/p&gt;

&lt;p&gt;There are two main ways to do this:&lt;/p&gt;
&lt;h4 id="readwrite-buffer"&gt;Read/Write Buffer&lt;/h4&gt;
&lt;p&gt;You have a buffer on host memory and on device memory that mirror each other.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;cl_int clEnqueueReadBuffer(
cl_command_queue command_queue,
cl_mem buffer,
cl_bool blocking_read,
size_t offset,
size_t size,
void* ptr,
cl_uint num_events_in_wait_list,
const cl_event* event_wait_list,
cl_event* event);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;cl_int clEnqueueWriteBuffer(
cl_command_queue command_queue,
cl_mem buffer,
cl_bool blocking_write,
size_t offset,
size_t size,
const void* ptr,
cl_uint num_events_in_wait_list,
const cl_event* event_wait_list,
cl_event* event);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OpenCL provides Read/Write commands to force overwrite of one buffer over the other, and in this way, data transfer is achieved.&lt;/p&gt;

&lt;h4 id="mapunmap-buffer"&gt;Map/Unmap Buffer&lt;/h4&gt;
&lt;p&gt;There is a single buffer on device memory, that is presented to CPU when demanded
So “mapping” a buffer will bring it from device memory into host RAM.
Then any changes made will be saved in host RAM.
Finally, once done with changes, you may “unmap” the buffer, which writes all changes made back to device memory&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;void* clEnqueueMapBuffer(
cl_command_queue command_queue,
cl_mem buffer,
cl_bool blocking_map,
cl_map_flags map_flags,
size_t offset,
size_t size,
cl_uint num_events_in_wait_list,
const cl_event* event_wait_list,
cl_event* event,
cl_int* errcode_ret);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="language-C"&gt;cl_int clEnqueueUnmapMemObject(
cl_command_queue command_queue,
cl_mem memobj,
void* mapped_ptr,
cl_uint num_events_in_wait_list,
const cl_event* event_wait_list,
cl_event* event);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this way, data transfer is achieved&lt;/p&gt;

&lt;h2 id="to-map-or-not-to-map"&gt;To map or not to map?&lt;/h2&gt;
&lt;p&gt;To be honest, performance differences are very minute, atleast from my tests with the gnuastro library.
However Map and Unmapping makes a world of difference as compared to Read/Write when it comes to simplicity&lt;/p&gt;

&lt;h2 id="the-problem-with-buffers"&gt;The problem with buffers&lt;/h2&gt;
&lt;p&gt;No matter what you do, when working with buffers, you always end up copying the data
For example, you load an image into CPU RAM, but actually want to work with it on the GPU.
So, you end up copying the image into GPU RAM. In the end, you process the same data twice, once while loading and once while copying&lt;/p&gt;

&lt;p&gt;For small images(2000 x 2000) this is barely noticeable
But gnuastro, and the people using gnuastro deal with astronomical images of incredibly large sizes(i’ve heard 30GB just for one image).&lt;/p&gt;

&lt;p&gt;So, most certainly, any time you save by using parallelised processing on the GPU, is lost and maybe even worsened by the data transfer times.
Then, using the GPU is almost pointless, unless you use the same data over and over again&lt;/p&gt;

&lt;p&gt;“Well, cant I just load the data on the GPU directly?”
Thats not possible, atleast not to my knowledge. This is the tradeoff with GPUs.
On a CPU, you have 4/8/16 highly specialised and capable cores(math, I/O), while on the GPU you have 1000s of some very primitive math operations(only math, no I/O)
So you always have to load it into CPU RAM first and then go to GPU RAM.&lt;/p&gt;

&lt;p&gt;So how can we fix this problem?
Well, one of the options is to use Shared Virtual Memory(OpenCL SVM), which enables the GPU to directly access CPU RAM and play with CPU pointers.&lt;/p&gt;

&lt;p&gt;However, I still have yet to test SVM in the context of gnuastro, to see if its useful.
Besides, SVM also fixes the problem of structs containing pointers(for another post).
Documentation for OpenCL is already sparse, and to add insult to injury, documentation on OpenCL SVM is even more sparse.
But I like the challenge…&lt;/p&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2024/07/20240713_2230_deadspheroid/</guid><pubDate>Sat, 13 Jul 2024 21:30:00 GMT</pubDate></item></channel></rss>